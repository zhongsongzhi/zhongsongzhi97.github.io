{"meta":{"title":"Dylan Zhong`s Blog","subtitle":"对对对","description":"","author":"Dylan Zhong","url":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io","root":"/zhongsongzhi97.github.io/"},"pages":[{"title":"","date":"2021-11-05T10:05:06.974Z","updated":"2021-11-02T06:19:58.001Z","comments":true,"path":"assets/grpc实现全双工.html","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/assets/grpc%E5%AE%9E%E7%8E%B0%E5%85%A8%E5%8F%8C%E5%B7%A5.html","excerpt":"","text":"grpc实现全双工 定义.proto 12345678910111213syntax = &quot;proto3&quot;;option csharp_namespace = &quot;DulpexGrpcDemo&quot;;package DulpexGrpcDemo;service userService &#123;rpc GetUser (HelloRequest) returns (stream HelloReply);rpc GetTest (HelloRequest) returns (HelloReply);&#125;message HelloReply&#123;string msg=1;&#125;message HelloRequest&#123;string msg=1;&#125; 服务端实现 123456789101112131415161718public class UserServiceImpl : userService.userServiceBase&#123;public override async Task GetUser(HelloRequest request, IServerStreamWriter&lt;HelloReply&gt; responseStream, ServerCallContext context)&#123;await DoSomeThing(request.Msg, (msg) =&gt; &#123; responseStream.WriteAsync(new HelloReply &#123; Msg = $&quot;&#123;msg&#125;:hello&quot; &#125;); &#125;);&#125;//处理回调逻辑private async Task DoSomeThing(string msg, Action&lt;string&gt; action)&#123;Console.WriteLine(msg);action?.Invoke(msg);&#125;public override Task&lt;HelloReply&gt; GetTest(HelloRequest request, ServerCallContext context)&#123;Console.WriteLine(request.Msg);return Task.FromResult(new HelloReply &#123; Msg = $&quot;&#123;request.Msg&#125;:hello&quot; &#125;);&#125;&#125; 客户端实现 1234567891011public interface HelloCallback&#123;void SayHelloworld(string msg);&#125;public class HelloCallbackImpl : HelloCallback&#123;public void SayHelloworld(string msg)&#123;Console.Write(msg);&#125; 用户服务方法实现: 12345678910111213141516171819202122public class UserServiceImpl&#123;private userService.userServiceClient userServiceClient;private readonly HelloCallback _helloCallback;public UserServiceImpl(userService.userServiceClient serviceClient, HelloCallback helloCallback)&#123;userServiceClient = serviceClient;_helloCallback = helloCallback;&#125;public async Task GetUser()&#123;AsyncServerStreamingCall&lt;HelloReply&gt; stream = userServiceClient.GetUser(new HelloRequest &#123; Msg = &quot;张三&quot; &#125;);await Helloworld(stream.ResponseStream);&#125;async Task Helloworld(IAsyncStreamReader&lt;HelloReply&gt; stream)&#123;await foreach (var update in stream.ReadAllAsync())&#123;_helloCallback.SayHelloworld(update.Msg);&#125;&#125;&#125; 客户端程序入口 12345678910111213141516171819class Program&#123;static async Task Main(string[] args)&#123;IServiceCollection servicesCollection = new ServiceCollection();IConfiguration configuration = new ConfigurationBuilder().SetBasePath(Directory.GetCurrentDirectory()).AddJsonFile(&quot;appsettings.json&quot;, true, false).Build();servicesCollection.AddGrpcClient&lt;userService.userServiceClient&gt;(o =&gt;&#123;o.Address = new Uri(&quot;https://localhost:5001&quot;);&#125;);servicesCollection.AddSingleton&lt;UserServiceImpl&gt;();servicesCollection.AddSingleton&lt;HelloCallback, HelloCallbackImpl&gt;();var userServiceImpl = servicesCollection.BuildServiceProvider().GetService&lt;UserServiceImpl&gt;();await userServiceImpl.GetUser();Console.ReadLine();&#125;&#125; 原因:单向流，客户端无需等待服务端方法执行完，而是由服务端完成后续流程后，再"},{"title":"tags","date":"2022-01-11T07:56:56.000Z","updated":"2022-01-11T07:58:08.451Z","comments":true,"path":"tags/index.html","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2022-01-11T07:56:39.000Z","updated":"2022-01-11T07:57:46.313Z","comments":true,"path":"categories/index.html","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"MQ小结","slug":"MQ小结","date":"2022-02-28T12:50:39.000Z","updated":"2022-02-28T09:43:00.496Z","comments":true,"path":"2022/02/28/MQ小结/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/02/28/MQ%E5%B0%8F%E7%BB%93/","excerpt":"","text":"MQ(RocketMQ)消费模型 队列模型 发布-订阅模型：消息的发送者，消息的接受者，服务端存放消息的容器(Topic)。发布者将消息发送到主题中，订阅者在接收消息前需要先订阅”Topic“，每份订阅，订阅者可以收到主题的所有消息。 区别：发布-订阅模型中，一个消息可以被多次消费。 RocketMQ结构 角色: Producer: 消息生产者，可集群部署。Producer随机与NameServer集群中的一个节点建立长连接，定期从NameServer集群中的一个节点建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master建立长连接，且定期向Master发送心跳。 Consumer: 消息消费者，可集群部署。建立连接方式和生产者一样。支持push（长轮询的拉）和pull两种消费方式。支持集群（同一个Topic的同一条消息只会被一个消费者实例消费）和广播模式（广播给所有订阅了该Topic的消费实例）的消费。 NameServer: 类似Zookeeper的作用（但是无状态节点），支持Broker的动态注册和发现（路由注册中心），为何所有的Broker和Topic的路由信息。Broker启动需要向所有的NameServer实现注册，并定期发送心跳信息。每个NameServer都维护了所有的Broker和Topic路由信息。 Broker：Broker主要负责消息的存储，投递，查询以及服务高可用。 Broker的部署：1. 单主 2. 多主 3. 多主多从 - 异步复制 4。 多主多从 - 同步双写 执行流程： 先启动NameServer（注册中心）服务，监控端口等待Broker，Producer，Consumer。 启动Broker跟所有的NameServer保存长连接并且定期发送心跳。 创建Topic并直到保存在哪些Broker Producer向主Broker发送消息并且给消息打tag进行分组 Consumer监听所有Broker的消息 存储的结构： CommitLog:存储所有消息主体和元数据，消息顺序写入CommitLog，一个写满就新建一个。 ConsumeQueue: 消费队列，目的是提供消费性能。保存了指定Topic下消息队列消息在CommitLog的起始偏移量，消息大小和消息Tag的hashcode IndexFile: 提供了一种可以通过key或时间区间来查询消息的方法 RocketMQ的存储以Broker为单位，Broker(ConsumerLog消息文件&amp;N*ConsumerQueue索引文件)， 写入消息：Broker上所有Topic，队列的消息都按照自然顺序追加写入到同一个消息文件中 查找消息：根据队列的消息序号，计算索引的全局位置(索引序号 x 索引固定长度20)，直接读取这条索引，然后根据索引查找到消息的位置 存储方式mmap: 一般的数据拷贝需要4次操作，RocketMQ使用了零拷贝技术，只需要2次 同步刷盘和异步刷盘：异步刷盘：当消息累计到一定量后统一磁盘写入。同步刷盘：返回写成功就写入磁盘。 可靠性使用”请求-确认“机制确保消息不会丢失 生成端： 生产者先将消息发送给服务端(Broker)，Broker收到消息后将消息写入Topic后再给生产者发送确认响应。如果没有收到响应则会重复发送消息。 消费端： 消费者在收到消息并完成消费业务逻辑后，也会向服务端发送消费成功的确认。（注：应该在完成消费业务逻辑以后再进行确认） 存储阶段： 如果Broker是多个节点组成的集群，需要将Broker集群配置成：至少将消息发送到2个以上的节点在回复确认。 由于”请求-确认“机制，为了确保消息的有序性，一条消息被成功消费前，下一条消息是不能被消费的。所有扩容Consumer时需要扩容Consumer Queue 事务消息2PC解决 -&gt; 在分布式系统中保持一致性 成员：协调者，参与者 投票阶段：协调者向参与者询问是否可以指向操作，参与者执行完(agreement/abort)并且记录redo/undo日志。当所有参与者都执行完进行提交阶段。 提交阶段：如果都同意，则协调者发送commit，否则rollback。参与者完成操作后返回消息，如果协调者收到所有的返回消息则结束事务，否则回滚。 EG： 订单系统创建订单后，发消息给购物车系统，将已下单的商品从购物车删除（使用消息队列异步清理购物车）。需要保证本地事务和发消息这两步要么都成功，要么都失败。 订单系统在消息队列上开启一个事务。然后订单系统给消息服务器发送一个“半消息”，这个半消息不是说消息内容不完整，它包含的内容就是完整的消息内容，半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的。 半消息发送成功后，订单系统就可以执行本地事务了，在订单库中创建一条订单记录，并提交订单库的数据库事务。然后根据本地事务的执行结果决定提交或者回滚事务消息。如果订单创建成功，那就提交事务消息，购物车系统就可以消费到这条消息继续后续的流程。如果订单创建失败，那就回滚事务消息，购物车系统就不会收到这条消息。 消息的处理 如何保证消息不被重复消费或者保证其幂等？ 在业务层实现，通过业务id，可以使用数据库和redis来保存当前业务id是否已经被消费 如何保证消息的可靠性？预防消息丢失 Producer: 使用请求-Ack机制 Broker: 通过同步刷盘或者异步刷盘的方式将其持久化到CommitLog Consumer: 消费者为何一个MessageQueue队列，保存消费进度的Offset，失败就定时重试，成功就更新Offset 如何保证消息的顺序性? 全局消息：需要在生产端只保留一个读写队列，消费端只有一个消费队列。但是会降低使用性。 分区消息：生产者将同一订单的消息发到同一个MessageQueu，消费端保证从同一个MessageQueue取出消息并且不并发处理 如何解决消息的延时和过期失效问题？ 当消费端宕机或者消费速度很慢导致 Broker 中消息大量积压，如有积压时长超过阈值就会被清理掉导致数据丢失。可以使用一段程序功能先将丢失的丢失的消息存储起来，等系统负载较低时将这部分消息重新发送给Broker。 消息队列满了或者堆积过多怎么办？ 新建Topic把积压的消息的Topic分发到新建的Topic中 停掉旧的消费端，将新建的Topic都启动对应的消费端实例 通过更强的消费能力把积压消息处理完 高性能读写数据 MMAP技术: 就是进行文件映射和内存映射，把磁盘里面的文件映射到用户态的虚拟内存，还有将 PageCache 映射到用户态的虚拟内存，从而减少内核态到用户态的 CPU 拷贝 PageCache技术：为了优化磁盘中数据文件的读写性能，PageCache 技术对数据文件进行了缓存。“对磁盘中数据文件的顺序读写性能接近于对内存的读写性能”，其主要原因就是 PageCache 对磁盘中数据文件的读写进行了优化。 PageCache 对数据文件的读优化：由于读数据文件的时候会先从 PageCache 加载数据，如果 PageCache 没有数据的话，会从磁盘的数据文件中加载数据并且顺序把相邻的数据文件页面预加载到 PageCache 中，这样子如果之后读取的数据文件在 PageCache 中能找到的话就省去了去磁盘加载数据的操作相当于直接读内存。 PageCache 对数据文件的写优化：往数据文件中写数据的时候同样先写到 PageCache 中，然后操作系统会定期刷盘把 PageCache 中的数据持久化到磁盘中。 RocketMQ是怎么使用的？ 将磁盘中的CommitLog数据文件映射到虚拟内存中。 生产端将消息顺序写到PageCache中，然后OS定期进行异步刷盘，将PageCache中的数据批量持久化到磁盘 消费端读取CommitLog数据，由于程序的局部性，所以加载的数据基本可以在PageCache找到，就不用去磁盘读取。","categories":[{"name":"MQ","slug":"MQ","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/MQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/MQ/"}]},{"title":"Zookeeper","slug":"Zookeeper","date":"2022-02-20T16:39:00.000Z","updated":"2022-02-28T09:42:37.509Z","comments":true,"path":"2022/02/21/Zookeeper/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/02/21/Zookeeper/","excerpt":"","text":"Zookeeper概览ZooKeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。 ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。 Zookeeper 一个最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心。 基于观察者模式设计的分布式服务管理框架， 它负责存储和管理大家都关心的数据， 然后接受观察者的注册， 一旦这些数据的状态发生变化， Zookeeper就将负责通知已经在Zookeeper上注册的那些观察者做出 相应 的反 应 ， 从而 实现集群中类似Master/Slave管理模式 存储结构数据按照“树”结构进行存储，并且znode节点还分为4种不同的类型 Znode: 存储结构是按照“树”状进行的存储，其上的每一个节点，称为“znode” 每个znode可以存储1MB的数据（对于记录状态性质的数据来说够用） 可以使用zkCli命令，登录到zookeeper上，通过命令操作这些znode节点（ls,create,delete,sync） znode除了名称，数据外，可以一套zxid Znode的结构： zxid：时间戳，每次修改znode都会生成新的zxid version：每次节点修改都会使版本号+1 data：数据 tick：租约协议，如果当前节点是“临时节点”，在tick时间周期内没有收到新的客户端租约则认为失效。 此外Znode还有操作权限 znode的分类： 持久化节点：创建这个节点的客户端在与zookeeper服务的连接断开后，这个节点也不会被删除（除非您使用API强制删除） 持久化顺序编号节点： 当客户端请求创建这个节点A后，zookeeper会根据parent-znode的zxid状态，为这个A节点编写一个全目录唯一的编号（这个编号只会一直增长）。当客户端与zookeeper服务的连接断开后，这个节点也不会被删除。 临时目录节点： 连接断开后，这个节点（还有涉及到的子节点）就会被删除 临时顺序编号目录节点： 连接断开后，这个节点被删除 应用场景： 统一命名服务 负载均衡 统一配置管理 集群管理 服务动态上下线：客户端注册监控列表，大概注册中心和服务的心跳检测到服务节点下线就去通知客户端 写数据流程：Zookeeper是弱一致性，CAP限制，如果要读取最新的数据，要手动调用sync去leader同步数据 Zab协议：client向Zookeeper写数据，会将请求给leader，这个写请求会广播给所有节点，当半数以上的节点写成功了，则认为写成功 Leader选举ZK的leader负责同步数据，发起选举 半数机制：集群中半数以上机器存活，集群可用。所以zookeeper适合装在奇数台机器上。 Zookeeper虽然在配置文件中并没有指定master和slave。但是，zookeeper工作时，是有一个节点为leader，其他则为follower，Leader是通过内部的选举机制临时产生的","categories":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/Zookeeper/"}],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/Zookeeper/"}]},{"title":"微服务","slug":"微服务","date":"2022-02-20T06:55:14.000Z","updated":"2022-02-20T13:05:32.875Z","comments":true,"path":"2022/02/20/微服务/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/02/20/%E5%BE%AE%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"微服务小结什么是微服务？发展：由单体应用进化到服务化拆分部署，后期由于容器化技术的进步，微服务开始流行。 定义：将复杂臃肿的单体进行细粒度化的服务化拆分，将每个拆分出来的服务各自独立打包部署，由小团队进行开发和维护。 如何将单体应用进行服务化拆分： 什么时候进行服务化拆分： 通常单体应用只在起步阶段使用，当功能开始复杂，人数变多就需要进行服务化拆分了 怎么进行拆分 纵向拆分：从业务维度进行拆分，标准是按照业务的关联度来决定的。 横向拆分：从公共且独立的功能维度拆分，标准按照是否有公共的被多个其他服务调用，且依赖的资源独立的功能。 服务化拆分的前置条件和问题： 服务如何定义：通过接口，服务之间的调用通过接口描述来约定，约定的内容包括接口名，接口参数，接口返回值。 服务如何发布和订阅：通过一个注册中心，能够记录每个服务提供者的地址以供服务调用者查询。 服务如何监控：对于一个服务来说，需要关注的性能指标通常为QPS,AvgTime,P999这些指标，需要通用的监控方案，能够覆盖业务埋点，数据收集，数据处理到数据展示的全链路 服务如何治理：服务的数量变多以后，如果一个服务的性能出现问题，依赖的服务都会受到影响，可以设置一个调用阈值，如果超过这个值就会直接返回 故障如何定位：需要将用户请求进行标记，并在多个依赖服务系统之间继续传递，以便串联所有路径，从而进行故障定位。 基本框架结构 流程：服务提供者向注册中心注册服务，声明自己的服务以及服务的地址，然后消费者请求注册中心，查询要调用的服务的地址，然后发起请求，得到请求结果以后按照约定的协议解析结果。在服务调用过程中，服务的请求耗时，调用量，成功率等指标会被记录，调用链路的信息也会被记录。 依赖的基本组件： 服务描述 注册中心 服务框架 服务监控 服务追踪 服务治理 服务描述常见的服务描述方式：1. RESTful API, XML, IDL RESTful API是基于HTTP协议的服务描述，通常使用Wiki或者Swagger进行管理。 XML配置常用于RPC协议的服务描述，IDL通常在Thrift和gRPC这类跨语言服务调用框架中。 注册中心：注册(服务提供者-&gt;注册中心)，订阅(服务消费者-&gt;注册中心)，返回（注册中心-&gt;服务消费者），通知（注册中心-&gt;服务消费者） 服务框架通信协议，序列化协议等 服务监控指标收集，数据处理，数据展示 服务追踪 服务消费者发起调用前，需要在本地按照一定规则生成一个requestId，发起调用以后将requestId作为请求参数的一部分传递给服务提供者 服务提供者收到请求后，会记录下requestid，服务提供者继续请求其他服务，会生成一个自己的本地requestid然后也添加到参数中，这样就可以通过requestid串联整个调用链路了（需要监控链路，所以每个都要签一遍） 服务治理单机故障：自动摘除故障节点 单IDC（互联网数据中心）故障：部署多IDC，自动切换IDC 依赖服务不可用：当一个服务依赖了另一个服务，当一个服务出现问题后，服务治理会通过熔断机制，一段时间内停止发起调用而直接返回。 注册中心和注册中心原理角色：1. 服务提供者(RPC Server)，服务消费者(RPC Client)，服务注册中心(Registry) RPC Server:在启动时，根据服务发布文件中的配置信息，向Registry注册服务，并定期发送心跳汇报存活状态 RPC Client:调用服务时，根据服务引用文件中的配置信息，向Registry订阅服务，将Registry返回的服务节点缓存到本地，并与RPC Server建立连接 Server变动：当Server节点变动时，Registry会同步变更，Client感知后会刷新本地的服务节点 RPC发起调用时，会从本地的服务节点中，基于负载均衡算法选择一台RPC Server发起调用 实现的方式： 注册中心的API： 服务注册 2. 服务注销 3. 心跳汇报 4. 服务订阅 5. 服务变更查询 集群部署: 集群部署加上分布式一致性协议来保证高可用和数据一致性 Zookeeper:Zab加上主从 目录存储： Zookeepre会采用层次化的目录结构。 服务健康状态检测：Zookeeper通过客户端和服务端的长连接和会话超时控制机制来检测健康状态 服务状态变更通知：有服务提供者加入或者删除，注册中心会立刻通知所有订阅了该服务的服务消费者 白名单机制：注册中心提供一个白名单，只有添加到白名单的RPC Server才可以调用注册中心的注册接口 Todo：Zookeeper 如何监控微服务的调用： 监控的对象： 用户端监控，接口监控，资源监控，基础监控（CPU利用率，内存使用量，I/O读写量，网卡带宽） 监控的指标： 请求量(QPS)，响应时间，错误率 监控的维度： 分机房维度，单机维度，时间维度，核心维度（核心业务和非核心业务） 监控系统原理 数据采集： 服务主动上报：在业务中加入数据收集代码逻辑 代理收集：将调用的详细信息记录到本地日志，后面通过代理去解析本地日志，在上报服务 数据传输： UDP传输： 消息队列传输： 数据处理： 聚合：各种维度聚合（接口维度/机器维度） 存储：各类数据库 数据展示: 各种图形（曲线图，饼状图，格子图） 如何追踪微服务调用 为什么需要追踪微服务调用 因为在微服务的架构下，一次请求会涉及多个服务方，整个业务链路很长，需要追踪微服务调用才能找到是什么导致的失败 微服务追踪可以用来做什么 优化系统瓶颈（根据链路上的耗时） 优化链路调用路径（减少服务依赖） 生成网络拓扑（用于服务监控） 透明传输数据（业务上可能需要将一些数据在整个微服务调用链路都带上） 服务追踪的原理： 基于调用链：使用一个全局唯一的ID将分布在各个服务节点上的同一个请求串联 格式eg: traceid(全局id)+spanid（服务方的链路组合）+annonation（业务方埋点） 微服务治理的手段可能出现的问题： 注册中心：宕机，和服务消费者或者服务提供者的网络不通 服务提供者：节点宕机，节点性能变慢，短时间出现问题，与消费者网络不通，与注册中心网络不通 服务消费者：与注册中心，提供者网络不通 常见的服务治理的手段： 节点管理： 注册中心主动摘除：服务提供者和注册中心使用心跳机制，如果超时就会摘除并推送给消费者 服务消费者摘除：探活机制放在服务消费端，如果消费者调用服务提供者节点失败，就将这个节点从内存的列表中移除 负载均衡： 服务提供者一般是以集群的方式存在。 随机算法 2.轮询算法 3. 最少活跃调用（消费方维护服务提供方的每一个节点的调用次数，按连接数倒序排）4. 一致性hash算法 服务路由： 路由规则：按照一定的规则，比如条件表达式或者正则表达式来限定服务节点的选择范围 业务存在灰度发布的需求：可以选择只让部分人使用变更的功能，比如按尾号进行灰度，只有符合要求的才能访问到服务节点 多机房就近访问的需求：通过IP端来控制访问，优先选择就近的机房 如何配置路由规则：1. 静态配置（在服务消费者本地存放，但是改动就不方便） 2.动态配置（路由规则存在注册中心，消费者定期去注册中心拉新的路由规则来保持同步） 服务容错： FailOver:失败自动切换，消费者调用失败或者超时以后，选择下一个节点重新发起调用。要求调用的操作时幂等的（即同一个调用返回结果相同），一般是读请求的场景 FailBack:失败通知，调用失败或超时以后，不会重试，而是根据失败的详细信息来决定下一步的执行策略。对于非幂等的调用，如果失败或超时，需要去查看调用是否生效。 FailCache:失败缓存，调用失败或超时后，不立即重试，而是隔一段时间再次尝试，也是幂等调用适合。 FailFast:快速失败，调用失败以后不再重试，一般对于非核心业务调用会这样使用。快速失败，只记录一个失败日志。","categories":[{"name":"微服务","slug":"微服务","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"Netty小结","slug":"Netty小结","date":"2022-02-13T07:43:14.000Z","updated":"2022-02-13T08:58:24.897Z","comments":true,"path":"2022/02/13/Netty小结/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/02/13/Netty%E5%B0%8F%E7%BB%93/","excerpt":"","text":"Netty小结Netty的逻辑架构 I/O模型主从Reactor多线程模型 主从多线程模型由多个Reactor线程组成，每个Reactor线程都有独立的Selector对象。 MainReactor只负责处理客户端连接的Accept事件，连接建立成功后会将创建好的连接对象注册到SubReactor。 之后由SubReactor分配线程池中的I/O线程与其连接绑定，由该I/O线程负责连接生命周期内的所有I/O事件。 步骤： 连接注册：Channel建立后，注册到Reactor线程中的Selector选择器 事件轮询：轮询Selector中注册的所有Channel的I/O事件 事件分发：为准备就绪的I/O事件分配响应的处理线程 任务处理：Reactor线程还负责任务队列中的非I/O任务，每个工作线程从各自维护的任务队列中取出任务异步执行。 事件处理机制 BossEventLoopGroup(包含一个或多个EventLoop)负责监听客户端上的Accept事件，事件触发时会将事件（即Channel）注册到WorkerEventLoopGroup(包含一个或多个EventLoop)中的某个EventLoop上。 EventLoop在事件轮询时读到了Channel中的数据后，会调用绑定的ChannelPipeline进行事件传播，ChannelPipeline是线程安全的。数据传入到ChannelPipeline的第一个Handler，数据处理完成后会传递给下一个ChannelHandler，整个过程是串行化执行(增加吞吐量和降低业务难度)的。 服务编排层问题： ChannelPipeline 与 ChannelHandler 的关系是什么？它们之间是如何协同工作的？ ChannelHandler 的类型有哪些？有什么区别？ Netty 中 I/O 事件是如何传播的？ ChannelPipeline概述： Pipeline的意思是管道，它在Netty中的作用，就是把原始的网络字节流经过Pipeline，进一步加工包装 易用性API接口对数据协议，序列化的支持OS层面的零拷贝传统的数据拷贝： 从文件中读取数据，然后将数据传输到网络上 用户线程发起read()调用以后，上下文从用户态切换到内核态，从文件读取数据到内核缓冲区 从内核态切换到用户态，将数据从内核态缓冲区拷贝到用户态缓冲区，然后返回给用户线程 用户线程调用send()，用户态切换到内核态，请求数据从用户态缓冲区拷贝到内核态的Socket缓冲区 最终send()结束，从内核态返回到用户态。发送了4次上下文切换和4次拷贝。 问题：传统拷贝为何不是直接将数据传输到用户缓冲区？引入内核缓冲区可以充当缓存的作用，这样就可以实现文件数据的预读，提升 I/O 的性能 比较好的流程：文件读取到内核缓冲区，然后从内核缓冲区直接传输到Socket缓冲区（） 这里进行了3次拷贝，0次上下文切换 还可以优化：就是不需要从内核缓冲区拷贝到Socket缓冲区，只在Socket缓冲区记录必要的信息，然后直接从内核缓冲区拷贝即可，这样就只有2次拷贝，这里就只有2次DMA拷贝，0次CPU拷贝了 -&gt; 所以是零拷贝 Netty的零拷贝 使用堆外内存 -&gt; VM内部的数据需要拷贝到VM外部才能进行系统调用 CompositeByteBuf","categories":[{"name":"Netty","slug":"Netty","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/Netty/"}]},{"title":"内存分配器","slug":"内存分配器","date":"2022-02-10T13:02:56.000Z","updated":"2022-02-10T13:03:57.084Z","comments":true,"path":"2022/02/10/内存分配器/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/02/10/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8/","excerpt":"","text":"内存分配器 程序中的数据和变量都会被分配到程序所在的虚拟内存中，内存空间包含两个重要区域：栈区（Stack）和堆区（Heap）。 栈：函数调用的参数、返回值以及局部变量大都会被分配到栈上，这部分内存会由编译器进行管理； 堆：不同编程语言使用不同的方法管理堆区的内存，C++ 等编程语言会由工程师主动申请和释放内存，Go 以及 Java 等编程语言会由工程师和编译器共同管理，堆中的对象由内存分配器分配并由垃圾收集器回收。 内存管理当用户程序申请内存时，它会通过内存分配器申请新内存，而分配器会负责从堆中初始化相应的内存区域。 分配方法：一般编程语言的内存分配器包括两种，一种是线性分配器，还有一种是空闲列表分配器。 线性分配器使用线性分配器时，只需要在内存中维护一个指向内存特定位置的指针，如果用户程序向分配器申请内存，分配器只需要检查剩余的空闲内存、返回分配的内存区域并修改指针在内存中的位置 问题：线性分配器无法在内存被释放时重用内存。 因为线性分配器具有上述特性，所以需要与合适的垃圾回收算法配合使用，例如：标记压缩（Mark-Compact）、复制回收（Copying GC）和分代回收（Generational GC）等算法，它们可以通过拷贝的方式整理存活对象的碎片，将空闲内存定期合并，这样就能利用线性分配器的效率提升内存分配器的性能了。 因为线性分配器需要与具有拷贝特性的垃圾回收算法配合，所以 C 和 C++ 等需要直接对外暴露指针的语言就无法使用该策略 空闲列表分配器类似与早期操作系统的，使用链表管理内存的结构。 这种方式的分配器可以重新利用回收的资源，但是因为分配内存时需要遍历链表，所以它的时间复杂度是 𝑂(𝑛)。 选择策略上有4种: 首次适应 循环首次适应 最优适应 隔离适应 Go采用的方式 - 空闲列表分配器配合类似隔离适应基本数据结构：该策略会将内存分割成由 4、8、16、32 字节的内存块组成的链表，当我们向内存分配器申请 8 字节的内存时，它会在上图中找到满足条件的空闲内存块并返回。隔离适应的分配策略减少了需要遍历的内存块数量，提高了内存分配的效率。即先找到合适的链表，再去找合适的内存块。 分级分配：线程缓存分配（Thread-Caching Malloc，TCMalloc）是用于分配内存的机制，它比 glibc 中的 malloc 还要快很多。Go 语言的内存分配器就借鉴了 TCMalloc 的设计实现高速的内存分配，它的核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略。 运行时根据对象的大小将对象分成微对象、小对象和大对象三种： 类别 大小 微对象 (0, 16B) 小对象 [16B, 32KB] 大对象 (32KB, +∞) 表 7-1 对象的类别和大小 因为程序中的绝大多数对象的大小都在 32KB 以下，而申请的内存大小影响 Go 语言运行时分配内存的过程和开销，所以分别处理大对象和小对象有利于提高内存分配器的性能。 多级缓存内存分成不同的级别分别管理，线程缓存（Thread Cache）、中心缓存（Central Cache）和页堆（Page Heap）三个组件分级管理内存 32KB以上的对象，内存分配器会直接分配到页堆，线程缓存不足时，会使用中心缓存进行补充 虚拟内存布局稀疏内存： 稀疏内存是 Go 语言在 1.11 中提出的方案，使用稀疏的内存布局不仅能移除堆大小的上限，还能解决 C 和 Go 混合使用时的地址空间冲突问题，不过因为基于稀疏内存的内存管理失去了内存的连续性这一假设，这也使内存管理变得更加复杂。 如图所示，使用二维的 runtime.heapArena 数组管理所有的内存，每个单元都会管理 64MB 的内存空间。 123456789type heapArena struct &#123; bitmap [heapArenaBitmapBytes]byte spans [pagesPerArena]*mspan pageInUse [pagesPerArena / 8]uint8 pageMarks [pagesPerArena / 8]uint8 pageSpecials [pagesPerArena / 8]uint8 checkmarks *checkmarksMap zeroedBase uintptr&#125; bitmap 用于标识 arena 区域中的那些地址保存了对象，位图中的每个字节都会表示堆区中的 32 字节是否空闲； arena 区域是真正的堆区，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象； zeroedBase 字段指向了该结构体管理的内存的基地址。 内存管理组件最重要的几种组件：runtime.mspan, runtime.mcache, runtime.mcentral, runtime.mheap Go 语言程序都会在启动时初始化如上图所示的内存布局，每一个处理器都会分配一个线程缓存 runtime.mcache 用于处理微对象和小对象的分配，它们会持有内存管理单元 runtime.mspan。 每个类型的内存管理单元都会管理特定大小的对象，当内存管理单元中不存在空闲对象时，它们会从 runtime.mheap 持有的 134 个中心缓存 runtime.mcentral 中获取新的内存单元，中心缓存属于全局的堆结构体 runtime.mheap，它会从操作系统中申请内存。 内存管理单元runtime.mspan12345type mspan struct &#123; next *mspan prev *mspan ...&#125; mspan是Go语言内存管理的基本单元，它们会构成双向链表的形式，运行时使用mSpanList来使用 每个mspan都管理着npages个大小为8KB的页（操作系统内存页的整数倍） 123456789101112131415type mspan struct &#123; startAddr uintptr // 起始地址 npages uintptr // 页数 freeindex uintptr allocBits *gcBits gcmarkBits *gcBits allocCache uint64 ...&#125;startAddr 和 npages — 确定该结构体管理的多个页所在的内存，每个页的大小都是 8KB；freeindex — 扫描页中空闲对象的初始索引；allocBits 和 gcmarkBits — 分别用于标记内存的占用和回收情况；allocCache — allocBits 的补码，可以用于快速查找内存中未被使用的内存； mspan管理内存： 当结构体管理的内存不足时，运行时会以页为单位向堆申请内存： 当用户程序或者线程向 runtime.mspan 申请内存时，它会使用 allocCache 字段以对象为单位在管理的内存中快速查找待分配的空间。如果我们能在内存中找到空闲的内存单元会直接返回，当内存中不包含空闲的内存时，上一级的组件 runtime.mcache 会为调用 runtime.mcache.refill 更新内存管理单元以满足为更多对象分配内存的需求。 每个内存管理单元的状态使用mSpanStateBox管理 该状态可能处于 mSpanDead、mSpanInUse、mSpanManual 和 mSpanFree 四种情况。当 runtime.mspan 在空闲堆中，它会处于 mSpanFree 状态；当 runtime.mspan 已经被分配时，它会处于 mSpanInUse、mSpanManual 状态，运行时会遵循下面的规则转换该状态： 在垃圾回收的任意阶段，可能从 mSpanFree 转换到 mSpanInUse 和 mSpanManual； 在垃圾回收的清除阶段，可能从 mSpanInUse 和 mSpanManual 转换到 mSpanFree； 在垃圾回收的标记阶段，不能从 mSpanInUse 和 mSpanManual 转换到 mSpanFree； 123456type mspan struct &#123; ... state mSpanStateBox ...&#125; 跨度类runtime.spanClass 是 runtime.mspan 的跨度类，它决定了内存管理单元中存储的对象大小和个数。 Go 语言的内存管理模块中一共包含 67 种跨度类，每一个跨度类都会存储特定大小的对象并且包含特定数量的页数以及对象，所有的数据都会被预选计算好并存储在 runtime.class_to_size 和 runtime.class_to_allocnpages 等变量中。 跨度类的数据 会有ID为0的跨度类管理超过32KB的对象 class bytes/obj bytes/span objects tail waste max waste 1 8 8192 1024 0 87.50% 2 16 8192 512 0 43.75% 3 24 8192 341 0 29.24% 4 32 8192 256 0 46.88% 5 48 8192 170 32 31.52% 6 64 8192 128 0 23.44% 7 80 8192 102 32 19.07% … … … … … … 67 32768 32768 1 0 12.50% 线程缓存runtime.mcache 是 Go 语言中的线程缓存，它会与线程上的处理器一一绑定，主要用来缓存用户程序申请的微小对象。每一个线程缓存都持有 68 * 2 个 runtime.mspan，这些内存管理单元都存储在结构体的 alloc 字段中，线程缓存在刚刚被初始化时是不包含 runtime.mspan 的，只有当用户程序申请内存时才会从上一级组件获取新的 runtime.mspan 满足内存分配的需求。 初始化：在初始化处理器时，在系统栈中使用mheap的线程缓存分配器初始化，mcache 替换：runtime.mcache.refill 会为线程缓存获取一个指定跨度类的内存管理单元，被替换的单元不能包含空闲的内存空间，而获取的单元中需要至少包含一个空闲对象用于分配内存： 微分配器：线程缓存中还包含几个用于分配微对象的字段，下面的这三个字段组成了微对象分配器，专门管理 16 字节以下的对象。微分配器只会用于分配非指针类型的内存，上述三个字段中 tiny 会指向堆中的一片内存，tinyOffset 是下一个空闲内存所在的偏移量，最后的 local_tinyallocs 会记录内存分配器中分配的对象个数。 12345type mcache struct &#123; tiny uintptr tinyoffset uintptr local_tinyallocs uintptr&#125; 中心缓存每个中心缓存都会管理某个跨度类的内存管理单元，它会同时持有两个 runtime.spanSet，分别存储包含空闲对象和不包含空闲对象的内存管理单元。 页堆 runtime.mheap 是内存分配的核心结构体，Go 语言程序会将其作为全局变量存储，而堆上初始化的所有对象都由该结构体统一管理，该结构体中包含两组非常重要的字段，其中一个是全局的中心缓存列表 central，另一个是管理堆区内存区域的 arenas 以及相关字段。 页堆中包含一个长度为 136 的 runtime.mcentral 数组，其中 68 个为跨度类需要 scan 的中心缓存，另外的 68 个是 noscan 的中心缓存。 内存管理单元： mspan获取新的单元是通过mheap.alloc获取的 先调用 runtime.mheap.reclaim 方法回收一部分内存，随后运行时通过 runtime.mheap.allocSpan 分配新的内存管理单元 1234567891011func (h *mheap) alloc(npages uintptr, spanclass spanClass, needzero bool) *mspan &#123; var s *mspan systemstack(func() &#123; if h.sweepdone == 0 &#123; h.reclaim(npages) &#125; s = h.allocSpan(npages, false, spanclass, &amp;memstats.heap_inuse) &#125;) ... return s&#125; 扩容： runtime.mheap.grow 会向操作系统申请更多的内存空间，传入的页数经过对齐可以得到期望的内存大小，我们可以将该方法的执行过程分成以下几个部分： 通过传入的页数获取期望分配的内存空间大小以及内存的基地址； 如果 arena 区域没有足够的空间，调用 runtime.mheap.sysAlloc 从操作系统中申请更多的内存； 扩容 runtime.mheap 持有的 arena 区域并更新页分配器的元信息； 在某些场景下，调用 runtime.pageAlloc.scavenge 回收不再使用的空闲内存页； 内存分配堆上所有的对象都是通过runtime.newobject分配内存的，其会调用runtime.mallocgc分配 可以看到，其会按照对象大小来按不同的方式进行内存分配 三种对象 微对象 (0, 16B) — 先使用微型分配器，再依次尝试线程缓存、中心缓存和堆分配内存； 小对象 [16B, 32KB] — 依次尝试使用线程缓存、中心缓存和堆分配内存； 大对象 (32KB, +∞) — 直接在堆上分配内存； 1234567891011121314151617181920212223func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer &#123; mp := acquirem() mp.mallocing = 1 c := gomcache() var x unsafe.Pointer noscan := typ == nil || typ.ptrdata == 0 if size &lt;= maxSmallSize &#123; if noscan &amp;&amp; size &lt; maxTinySize &#123; // 微对象分配 &#125; else &#123; // 小对象分配 &#125; &#125; else &#123; // 大对象分配 &#125; publicationBarrier() mp.mallocing = 0 releasem(mp) return x&#125; 微对象小于 16 字节的对象划分为微对象，它会使用线程缓存上的微分配器提高微对象分配的性能，我们主要使用它来分配较小的字符串以及逃逸的临时变量。微分配器可以将多个较小的内存分配请求合入同一个内存块中，只有当内存块中的所有对象都需要被回收时，整片内存才可能被回收。 微分配器管理的对象不可以是指针类型，管理多个对象的内存块大小 maxTinySize 是可以调整的，在默认情况下，内存块的大小为 16 字节。maxTinySize 的值越大，组合多个对象的可能性就越高，内存浪费也就越严重；maxTinySize 越小，内存浪费就会越少，不过无论如何调整，8 的倍数都是一个很好的选择。 微分配器 小对象小对象是指大小为 16 字节到 32,768 字节的对象以及所有小于 16 字节的指针类型的对象，小对象的分配可以被分成以下的三个步骤： 确定分配对象的大小以及跨度类 runtime.spanClass； 从线程缓存、中心缓存或者堆中获取内存管理单元并从内存管理单元找到空闲的内存空间； 调用 runtime.memclrNoHeapPointers 清空空闲内存中的所有数据； 大对象运行时对于大于 32KB 的大对象会单独处理，我们不会从线程缓存或者中心缓存中获取内存管理单元，而是直接调用 runtime.mcache.allocLarge 分配大片内存 内存分配算法TCMalloc在 TCMalloc 内存管理内部分为两个部分：线程内存（thread memory)和页堆（page heap）。 每一个线程都可以获得一个用于无锁分配小对象的缓存，这样可以让并行程序分配小对象（&lt;=32KB）非常高效。PS, java 中叫TLAB：Thread Local Allocation Buffer。Go 中叫mcache（挂在每一个P上） TCMalloc 管理的堆由一组页组成，一组连续的页面被表示为 span。当分配的对象大于 32KB，将使用页堆（Page Heap）进行内存分配。 Go 的内存分配器基于 Thread-Cache Malloc (tcmalloc) ，tcmalloc 为每个线程实现了一个本地缓存， 区分了小对象（小于 32kb）和大对象分配两种分配类型，其管理的内存单元称为 span。但与 tcmalloc 存在一定差异。 这个差异来源于 Go 语言被设计为没有显式的内存分配与释放， 完全依靠编译器与运行时的配合来自动处理，因此也就造就了内存分配器、垃圾回收器两大组件。统一管理内存会提前分配或一次性释放一大块内存， 进而减少与操作系统沟通造成的开销，进而提高程序的运行性能。 支持内存管理另一个优势就是能够更好的支持垃圾回收。 内存分配器的核心组件： heapArena: 保留整个虚拟地址空间 mheap：分配的堆，在页大小为 8KB 的粒度上进行管理 mspan：是 mheap 上管理的一连串的页 mcentral：收集了给定大小等级的所有 span mcache：为 per-P 的缓存。 go 基于上述 struct 提供了 runtime.newobject 用于goroutine 代码申请内存，由gc 负责回收。runtime.newobject 就是内存分配的核心入口 页是向操作系统申请内存的最小单位，目前设计为 8KB。传统意义上的栈被 Go 的运行时霸占，不开放给用户态代码；而传统意义上的堆内存，又被 Go 运行时划分为了两个部分， 一个是 Go 运行时自身所需的堆内存，即堆外内存；另一部分则用于 Go 用户态代码所使用的堆内存，也叫做 Go 堆。 Go 堆负责了用户态对象的存放以及 goroutine 的执行栈。 Go 内存管理的一般思想是使用不同的内存结构为不同大小的对象使用不同的内存缓存级别来分配内存。将一个从操作系统接收的连续地址的块切分到多级缓存来减少锁的使用，同时根据object的大小分配内存减少内存碎片以提高内存分配的效率和在内存释放之后加快 GC 运行的速度。mcache ==&gt; mcentral ==&gt; mheap（向堆申请一个arena） ==&gt; 堆 大于 32K 的大对象直接从 mheap 分配。 小于 16B 的使用 mcache 的微型分配器分配 对象大小在 16B ~ 32K 之间的的，首先通过计算使用的大小规格，然后使用 mcache 中对应大小规格的块分配 如果对应的大小规格在 mcache 中没有可用的块，则向 mcentral 申请 如果 mcentral 中没有可用的块，则向 mheap 申请，并根据 BestFit 算法找到最合适的 mspan。如果申请到的 mspan 超出申请大小，将会根据需求进行切分，以返回用户所需的页数。剩余的页构成一个新的 mspan 放回 mheap 的空闲列表。 如果 mheap 中没有可用 span，则向操作系统申请一系列新的页（最小 1MB）。 Go 会在操作系统分配超大的页（称作 arena）。分配一大批页会减少和操作系统通信的成本。 参考文章： https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/","categories":[{"name":"内存管理","slug":"内存管理","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"}],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"}]},{"title":"序列化和反序列化小结","slug":"序列化和反序列化小结","date":"2022-02-10T08:40:37.000Z","updated":"2022-02-10T09:22:07.357Z","comments":true,"path":"2022/02/10/序列化和反序列化小结/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/02/10/%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E5%B0%8F%E7%BB%93/","excerpt":"","text":"序列化和反序列化小结序列化是指把数据结构或对象转化为可存储或可传输的结构，这种结构可以用于重建数据结构或对象。 协议 类型 优点 缺点 Json 文本 1. 人可读 2. 属性顺序对序列化反序列化无影响 1. 丢弃了类型信息，eg: “num”:100，这里对于num的类型信息是不可知的，解析存在二义性 2. 不支持二进制数据类型 Protobuf 二进制 性能高 1. 不宜读 2. 向后兼容有约定限制 JsonJSON建构于两种结构： “Key/Value”对的集合，在不同语言中，可以作为对象，字典，结构体等 值的有序列表。通常可以理解为数组。 以上两种结构在大多数语言中都存在，所以在不同语言中使用JSON进行交流非常自然。 形式： 对象是一个无序的’key/value’对集合。一个对象以”{“开始，”}”结束。键值对”key:value”表示。键值对之间使用”,”分隔 值的有序集合：一个数组以”[“开始,”]”结束，值之间使用”,”分隔 值value:可以为string-&gt;”abc”，number-&gt;1,Bool-&gt;true/false,null,对象或数组，同时结构可以嵌套 使用场景 传输数据量较小，且实时性要求比较低的服务 JSON的前后兼容性比较强，对于接口经常变化，对可调性要求高的场景比较适合，比如移动端和服务端通讯 JSON的典型场景： JSON+HTTP JSON的性能和序列化的额外空间开销比较大，对于大数据量服务或持久化来说，会有巨大的开销。同时JSON本身没有使用IDL约束参与方，尽管在大多数语言中它的形式都可以兼容，但是还是会存在问题，需要通过文档方式进行约束，对调试会带来不便。 Protobufprotobuf有许多作为优秀的序列化协议的众多优点： 使用了标志的IDL 序列化数据紧凑，空间开销小 序列化反序列化速度很快 protobuf产生与Google，其支持多种语言，支持的数据类型相对较少，常见与一下rpc框架中使用。 典型使用场景protobuf的空间开销小，加上解析性能高，使用与RPC调用的场景。protobuf提供了标志的IDL，IDL对于各方都有比较强的约束。此外对于应用层对象持久化来说，也比较适合。 缺点在于调试比较麻烦 使用ANTLR设计自己的序列化协议 TODOReferencehttps://tech.meituan.com/2015/02/26/serialization-vs-deserialization.html","categories":[{"name":"序列化","slug":"序列化","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/%E5%BA%8F%E5%88%97%E5%8C%96/"}],"tags":[{"name":"序列化","slug":"序列化","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%BA%8F%E5%88%97%E5%8C%96/"}]},{"title":"MySQL - 查询优化","slug":"MySQL-查询优化","date":"2022-01-29T09:16:04.000Z","updated":"2022-01-29T10:19:14.474Z","comments":true,"path":"2022/01/29/MySQL-查询优化/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/29/MySQL-%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96/","excerpt":"","text":"查询性能优化优化数据访问 确认程序是否在检索大量超过需要的数据 确认Mysql服务器是否在分析大量超过需要的数据行 请求了不需要的数据 查询不需要的记录：Mysql总是先返回全部结果集再计算，最好的办法是在查询后面加上LIMIT 多表关联时返回全部列：只取需要的列 使用select * 重复查询相同的数据：使用缓存将数据缓存下来 是否在扫描额外的记录衡量标准：1. 响应时间 2. 扫描的行数 3. 返回的行数 -&gt; 查询慢日志获得指标 4. 扫描的行数和访问类型 -&gt; 通过EXPLAIN语句中的type列可以获取访问类型。 优化思路： 使用索引覆盖扫描 改变库表结构 重写复杂查询，让优化器能够以更优化的方式去执行查询 重构查询的方式 将一个复杂查询分解为多个简单查询 切分查询：将一个重的事务分解为多个小的事务（eg：删除过期数据） 分解关联查询： 1234567SELECT * FROM tag JOIN tag_post WHERE tag_post.id=tag.id JOIN post ON tag_post.id=post.id WHERE tag.tag=&#x27;mysql&#x27;//将关联查询分解为多个单表查询，然后在业务程序再进行关联SELECT * FROM tag WHERE tag=&#x27;mysql&#x27;SELECT * FROM tag_post WHERE tag_id=1234SELECT * FROM post WHERE post.id in (123,456) Mysql客户端和服务端的通信协议: 半双工-&gt; 导致Mysql查询，需要所有的数据都接收到以后才能是否查询占用的资源。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/MySQL/"}]},{"title":"如何实现一个远程调用框架","slug":"如何实现一个远程调用框架","date":"2022-01-27T06:45:00.000Z","updated":"2022-01-27T09:09:32.634Z","comments":true,"path":"2022/01/27/如何实现一个远程调用框架/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/27/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8%E6%A1%86%E6%9E%B6/","excerpt":"","text":"如何实现一个远程调用框架RPC框架会涉及到的内容，线程模型，通信协议设计，同步/异步调用，负载均衡等。 RPC框架架构设计 大概有三个部分的组件，1. 客户端 2. 注册中心 3. 服务端 服务注册与发现使用注册中心来实现服务注册和发现的功能。 服务端节点上线以后自行向注册中心注册服务列表，节点下线时需要从注册中心将节点数据移除。 客户端向服务端发起调用时，自己从注册中心获取到服务端的服务列表，然后通过负载均衡算法选择其中一个服务节点进行调用。 问题：服务端节点下线时如何移除节点数据，尤其是异常下线的情况。 方式：主动通知+心跳检测 当服务端下线时会主动通知注册节点下线移除数据，同时注册中心会对服务节点进行探活。 通信协议与序列化：因为RPC框架对于性能要求较高，所以通信协议越简单越好。 主流的是TPC,HTTP，gRPC使用的HTTP2。需要稳定可靠的协议。 数据和序列化：如果是一般的框架会选用通用且高效的序列化方式，比如Json,Protocbuf等待，如果是特定场景下使用的话，可以使用特定的序列化方式，这样会更加高效。 RPC的调用方式：一般支持的调用方式： 同步Sync：客户端发起RPC调用后，当前线程会一直阻塞，指定服务端返回结果或者超时。 异步Future：客户端发起调用以后不会阻塞等待，而是拿到RPC框架的Future对象，调用结果会被服务端缓存，客户端自行决定何时拿到返回结果，主动获取结果的过程是阻塞等待的。 回调Callback：客户端发起调用时，将Callback对象传递给RPC框架，无需同步等待，直接返回。当获取到服务端响应结果或者超时，再执行用户注册的Callback回调。这种Callback接口一般包含了onResponse和onException两个方法 单向Oneway：客户端发起请求后直接返回，忽略结果 线程模型：使用主从Reactor线程模型，其中Boss和Worker线程池可以看做IO线程，IO线程用于处理网络数据，比如事件轮询，编解码，数据传输等。业务逻辑使用业务线程执行。 负载均衡：常见的负载均衡的策略： Round-Robin 轮询。Round-Robin 是最简单有效的负载均衡策略，并没有考虑服务端节点的实际负载水平，而是依次轮询服务端节点。 Weighted Round-Robin 权重轮询。对不同负载水平的服务端节点增加权重系数，这样可以通过权重系数降低性能较差或者配置较低的节点流量。权重系数可以根据服务端负载水平实时进行调整，使集群达到相对均衡的状态。 Least Connections 最少连接数。客户端根据服务端节点当前的连接数进行负载均衡，客户端会选择连接数最少的一台服务器进行调用。Least Connections 策略只是服务端其中一种维度，我们可以演化出最少请求数、CPU 利用率最低等其他维度的负载均衡方案。 Consistent Hash 一致性 Hash。目前主流推荐的负载均衡策略，Consistent Hash 是一种特殊的 Hash 算法，在服务端节点扩容或者下线时，尽可能保证客户端请求还是固定分配到同一台服务器节点。Consistent Hash 算法是采用哈希环来实现的，通过 Hash 函数将对象和服务器节点放置在哈希环上，一般来说服务器可以选择 IP + Port 进行 Hash，然后为对象选择对应的服务器节点，在哈希环中顺时针查找距离对象 Hash 值最近的服务器节点。 代理：RPC框架如果要做到像调用本地接口一样调用远端服务，需要创建代理对象，在代理对象中完成数据报文编码，然后发起调用数据给服务方，以此来屏蔽RPC框架的调用细节。可以通过动态代理的方式生成桩类（代理类），gRPC则是通过定义好的DSL，使用DSL来生成桩类和代理方法。 基本框架12345678910111213141516171819202122232425262728293031323334353637383940414243// rpc-facade # HelloFacadepublic interface HelloFacade &#123; String hello(String name);&#125;// rpc-provider # HelloFacadeImpl@RpcService(serviceInterface = HelloFacade.class, serviceVersion = &quot;1.0.0&quot;)public class HelloFacadeImpl implements HelloFacade &#123; @Override public String hello(String name) &#123; return &quot;hello&quot; + name; &#125;&#125;// rpc-consumer # HelloController@RestControllerpublic class HelloController &#123; @RpcReference(serviceVersion = &quot;1.0.0&quot;, timeout = 3000) private HelloFacade helloFacade; @RequestMapping(value = &quot;/hello&quot;, method = RequestMethod.GET) public String sayHello() &#123; return helloFacade.hello(&quot;mini rpc&quot;); &#125;&#125; 服务方 服务提供者启动服务，并暴露服务端口； 启动时扫描需要对外发布的服务，并将服务元数据信息发布到注册中心； 接收 RPC 请求，解码后得到请求消息； 提交请求至自定义线程池进行处理，并将处理结果写回客户端。","categories":[{"name":"RPC","slug":"RPC","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/RPC/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/RPC/"}]},{"title":"基于线程和事件驱动的响应模式","slug":"基于线程和事件驱动的响应模式","date":"2022-01-24T12:33:09.000Z","updated":"2022-01-24T13:02:52.500Z","comments":true,"path":"2022/01/24/基于线程和事件驱动的响应模式/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/24/%E5%9F%BA%E4%BA%8E%E7%BA%BF%E7%A8%8B%E5%92%8C%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%E7%9A%84%E5%93%8D%E5%BA%94%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"Reactor PatternReactor pattern的理念: 连接和线程总是存在一对一的关系。Unfortunately, there is always a one-to-one relationship between connections and threads 事件驱动的方法可以将线程与连接分开，它只对特定回调/处理程序的事件使用线程。Event-driven approach can separate threads from connections, which only uses threads for events on specific callbacks/handlers. 一个事件驱动的架构由事件的创建者和事件的消费者组成。创建者，也就是事件的源头，只知道事件发生了。消费者是需要知道事件已经发生的实体。消费者可能参与到事件处理中去，也可能只是受到事件的影响。An event-driven architecture consists of event creators and event consumers. The creator, which is the source of the event, only knows that the event has occurred. Consumers are entities that need to know the event has occurred. They may be involved in processing the event or they may simply be affected by the event. 反应器模式时事件驱动架构的一种实现，简单来说，它是由一个单线程的事件循环对发出事件的资源进行了阻塞并且将其分配给对应的处理程序或者回调。The reactor pattern is one implementation technique of the event-driven architecture. In simple words, it uses a single threaded event loop blocking on resources emitting events and dispatches them to corresponding handlers/callbacks. 只有注册了处理程序和回调，就没必要阻塞IO了。事件就行传入的一个新的连接，已经可以读，可以写了There is no need to block on I/O, as long as handlers/callbacks for events are registered to take care of them. Events are like incoming a new connection, ready for read, ready for write, etc. This pattern decouples modular application-level code from reusable reactor implementation.这种模式可以解耦模块化的应用级代码和可重复使用的反应器实现。 The purpose of the Reactor design pattern is to avoid the common problem of creating a thread for each message/request/connection.Avoid this problem is to avoid the famous and known problem C10K.反应器模式的目的是为了避免为每个消息/请求/连接创建一个线程的问题。也是为了解决C10K问题。","categories":[],"tags":[]},{"title":"MySQL高可用","slug":"MySQL高可用","date":"2022-01-17T18:01:29.000Z","updated":"2022-01-28T09:46:56.981Z","comments":true,"path":"2022/01/18/MySQL高可用/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/18/MySQL%E9%AB%98%E5%8F%AF%E7%94%A8/","excerpt":"","text":"MySQL高可用主备一致是如何保证的主库同步到从库的过程： 主库接收到写请求以后，执行内部事务的更新逻辑，同时写binlog 从库和主库直接维持了一个长连接，主库A内部有一个线程，专门用于服务备库B的长连接。 事务日志同步：从库和主库建立好长连接后，会收到主库的binlog，存储到本地为relaylog，会有一个线程读取relaylog，解析日志里的sql命令，然后执行 binlog的三种格式： statement statement格式存储的是原始的SQL语句。 存在的问题：主库和从库执行同一条sql语句，可能存在结果不一致的情况。 row row格式里存储的是: Table_map, Delete_rows，row格式记录了真实删除行的主键id，也就是主库和备库最终结果是一致的 mixed mixed是以上两种混合使用的结果 statement格式的binlog可能会造成主备不一致 row格式的话，会很占用空间 - 比如delete删除10万行，row格式要记录10w个记录，statement只记录一句sql Mixed: 主动判断SQL语句是否可能造成主备不一致，可能就用row，否则stament 实践：设置为mixed，如果需要恢复数据的场景，则设置为row 恢复数据 row格式中记录的信息中，bin_row_image的默认设置会存储行的所有字段的值，上面设置为只记录必要信息，只有id=4这个信息 所以在row格式中，可以记录所有的行的信息。 delete：执行的delete语句，在row格式的binlog中，被删除的每一行的信息都会保存，既可以将删除的数据insert回去。 insert: insert语句，row格式的binlog会记录所有字段信息，可以用于定义刚刚插入的一行，使用delete删除即可 update: update语句，row格式的binlog会记录修改前的整行数据和修改后的整行数据，只需要对调前后，执行update即可 双主结构和循环复制当两个库都作为主库时，会有2个长连接来保持相互同步，但是如何保证不会循环复制。这里使用serverid来做区分。 主备延迟数据同步的节点： 主库A执行完成一个事务，写入binlog T1 binlog传给备库B，备库接收完这个binlog T2 备库B执行完成事务 T3 主备延迟 = T3 - T1 T2 - T1 = 网络传输的时间，比较短 T3 - T2 = 接收完binlog并执行事务的时间（长） 主备延迟 约等于 T3-T2 接收完binlog，执行relaylog的速度差 主备延迟的来源： 主库机器被备库好 备库压力大 大事务 - 因为主库必须等事务执行完以后才会写入binlog，如果大事务执行时间为t1则延迟为t1 备库的并行复制 针对主备延迟带来的主备切换策略： 可靠性优先策略： 可用性优先策略： 小时级的主备延迟 - 备库并行复制在备库执行日志的速度持续低于主库生成日志的速度情况下，主备延迟有可能变成小时级别。 为什么要多线程并行复制 - 客户端事务是可以并发的，如果备库处理relaylog是单线程的，则会导致备库执行日志速度持续低于主库生成日志，造成较长时间的主备延迟。 协调器 - 多工作线程的模式（同时需要保证 不能更新覆盖，不能拆同一个事务） 一主多从的结构 具体结构：A与A1是互为主从，B，C，D是执行A的从库，主库为WR，从库为readonly 主库故障后的主从切换： 当A出错后，A1会作为新的主库，对于从库B来说需要执行change master命令，需要建立到新主库的连接并且将日志位点对齐新主库 重点问题：日志位点很难对齐 对于相同的日志，A和A1的位点是不同的，所以从库首先需要对齐位点 通用的做法是使用GTID来对齐位点： GTID(Global Transaction Identifier) 是全局事务ID，是一个事务在提交时生成的 在开启了GTID以后，日志位点就可以自动对齐了 流程： 从库B指定主库A1，基于主备协议建立连接 从库B把自己的GTID集合set_b发给新主库A1 主库A1把set_b和自己的GTID集合set_a比较，获取差集，然后看自己是否包含所有的差集 主库A1在binlog中找到第一个差集中的事务，然后向后顺序取binlog给B","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/MySQL/"}]},{"title":"Redis小结","slug":"Redis小结","date":"2022-01-13T09:59:13.000Z","updated":"2022-02-12T16:34:32.476Z","comments":true,"path":"2022/01/13/Redis小结/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/13/Redis%E5%B0%8F%E7%BB%93/","excerpt":"","text":"Redis学习小结 Redis的设计与实现核心点： Redis的五种数据类型是由什么数据结构实现？ String-&gt; 动态字符串 List-&gt; 压缩链表，双向链表 Hash-&gt; 压缩链表，hash表 Set-&gt;set sortedSet-&gt;压缩链表，跳表 Redis的字符串类型即可以存储字符串，又可以存储整数和浮点数，甚至二进制位，Redis内部如何存储这些不同的值？ 针对不同场景，为同一类型设置不同的数据结构实现。 比如字符串，数字时存为INT，长度小的时候为编码的简单字符串，长的时候就是简单动态字符串 Redis 的一部分命令只能对特定数据类型执行（比如 APPEND 只能对字符串执行， HSET 只能对哈希表执行）， 而另一部分命令却可以对所有数据类型执行（比如 DEL 、 TYPE 和 EXPIRE ）， 不同的命令在执行时是如何进行类型检查的？ Redis 在内部是否实现了一个类型系统？ 是的Redis内部实现了一套类型系统 Redis 的数据库是怎样储存各种不同数据类型的键值对的？ 数据库里面的过期键又是怎样实现自动删除的？ 1234567891011struct redisServer &#123; // ... redisDb *db; // 一个数组，保存着服务器中的所有数据库 int dbnum; // 服务器的数据库数量，默认16 // ...&#125;typedef struct redisDb &#123; // ... dict *dict; // 数据库键空间，保存着数据库中的所有键值对 dict *expires; // 过期字典，保存着键的过期时间&#125; Redis 还拥有发布与订阅、脚本、事务等特性， 这些特性又是如何实现的？ 怎么处理客户端的命令请求？ 使用RESP协议（自定义的）进行通信 整体结构： K-V如何组织使用的是Hash表的结构 问题： Hash冲突？ -&gt;链式解决 Rehash(分配更大的空间，减少冲突): Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步： 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍； 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中； 为了避免copy 过程阻塞用户请求，Redis 采用了渐进式 rehash，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中。PS：跟redis 通过用户请求顺带清理 过期数据是一样的。 释放哈希表 1 的空间。 RedisObject: 12345678910#define REDIS_LRU_BITS 24typedef struct redisObject &#123; unsigned type:4; // 类型 unsigned encoding:4; // 编码 unsigned lru:REDIS_LRU_BITS; // 对象最后一次被访问的时间 int refcount; // 引用计数 void *ptr; // 指向实际值的指针，可以指向不同的数据类型&#125; robj; 由于Redis的数据类型很多，所以是用了一个RedisObject来做封装 K-V底层数据结构Key只能为string类型，value可以为复杂类型 压缩列表： 由于压缩列表节约内存，所以hash,list,sortedSet的底层实现在数据量小的时候都采用压缩列表 1234567891011area |&lt;---- ziplist header ----&gt;|&lt;----------- entries -------------&gt;|&lt;-end-&gt;|size 4 bytes 4 bytes 2 bytes ? ? ? ? 1 byte +---------+--------+-------+--------+--------+--------+--------+-------+component | zlbytes | zltail | zllen | entry1 | entry2 | ... | entryN | zlend | +---------+--------+-------+--------+--------+--------+--------+-------+ ^ ^ ^address | | | ZIPLIST_ENTRY_HEAD | ZIPLIST_ENTRY_END | ZIPLIST_ENTRY_TAIL 图中各个域的作用如下： 域 长度/类型 域的值 zlbytes uint32_t 整个 ziplist 占用的内存字节数，对 ziplist 进行内存重分配，或者计算末端时使用。 zltail uint32_t 到达 ziplist 表尾节点的偏移量。 通过这个偏移量，可以在不遍历整个 ziplist 的前提下，弹出表尾节点。 zllen uint16_t ziplist 中节点的数量。 当这个值小于 UINT16_MAX （65535）时，这个值就是 ziplist 中节点的数量； 当这个值等于 UINT16_MAX 时，节点的数量需要遍历整个 ziplist 才能计算得出。 entryX ? ziplist 所保存的节点，各个节点的长度根据内容而定。 zlend uint8_t 255 的二进制值 1111 1111 （UINT8_MAX） ，用于标记 ziplist 的末端。 Entry的构成： 12345area |&lt;------------------- entry --------------------&gt;| +------------------+----------+--------+---------+component | pre_entry_length | encoding | length | content | +------------------+----------+--------+---------+ RESP协议Redis客户端与服务端使用了RESP(Redis Serialization Protocol)的二进制安全文本协议进行通信，通过TCP连接实现数据交互 123456*&lt;参数数量&gt; CR LF$&lt;参数 1 的字节数量&gt; CR LF&lt;参数 1 的数据&gt; CR LF...$&lt;参数 N 的字节数量&gt; CR LF&lt;参数 N 的数据&gt; CR LF 对于特定场景，使用自定义的通信协议，性能会好于通用的通信协议 整体结构1234567891011struct redisServer &#123; // ... redisDb *db; // 一个数组，保存着服务器中的所有数据库 int dbnum; // 服务器的数据库数量，默认16 // ...&#125;typedef struct redisDb &#123; // ... dict *dict; // 数据库键空间，保存着数据库中的所有键值对 dict *expires; // 过期字典，保存着键的过期时间&#125; 单线程的原因 只是对读写使用了单线程，底层使用了IO多路复用机制 单线程使用简单，并且这里主要的瓶颈不是单线程而是共享资源 持久化（单机高可用） AOF:MySQL使用的是写前日志（WAL）。但是AOF日志是写后日志，需要Redis先执行命令，写入内存后，再记录日志。 优点：记录每一条命令但是不需要检查语法。AOF也不会阻塞当前命令 缺点：存在执行完命令没有记录日志丢失数据的风险。AOF会阻塞下一个命令执行，如果后续磁盘写压力大会导致变慢。 解决问题： 丢失数据风险：提供三种配置, Always(同步写回)，EverySec(每秒写回),NO(只写到内存，有操作系统写入磁盘) 日志文件变大：使用AOF重写机制 AOF重写机制： 执行重写是，主线程fork一个子线程，内存会拷贝一份，如何对同一键值对的反复修改的命令只保留其值即可。主线程未阻塞，仍然可以处理新来的操作。如果有写操作，除了正在写的AOF 日志，还会再写一份AOF 重写日志。等到bgrewriteaof 拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，此时，就可以用新的 AOF 文件替代旧文件了。 RDB：记录某一时刻的内存中的数据，以文件的形式写到磁盘。即快照。 提供了两个命令生成RDB： Save: 主线程执行，会阻塞 Bgsave: 创建一个子进程，专门写入RDB文件，避免了主线程的阻塞，但是这样做确需要暂停写操作，可以使用Copy-On-Write，即会复制一份值用于写。 快照频率使用上，频率搞了消耗大，低了数据容易丢 更好的应用场景：快照不频繁使用，AOF记录两次快照之间的操作。 因为RDB和AOF都会使用fork，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长（所以使用RDB时，单个实例的redis 内存不宜过大） 同时，Redis 是内存数据库，内存使用量大，如果没有控制好内存的使用量，或者和其他内存需求大的应用一起运行了，就可能受到 swap 的影响，而导致性能变慢。 主从同步（多机高可用）主从同步 Redis提供了主从库模式，主从库同步是如何完成的呢？ 第一次同步：启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，然后使用RDB进行数据同步 主从级联模式：从库很多，如果都要和主库进行全量复制，就会导致主库压力大，通过“主-从-从”的模式就可以解决 主从库端口：通过增量复制的方式继续同步。主从库断连后，主库会将写操作持续写入一个buffer（注：环状） 主库挂了怎么办？ 通过哨兵机制解决： 哨兵是一个特殊模式下的Redis进程，主要用于：监控，选主，通知 监控。周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。 选主。筛选+打分，在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉（在线状态、断连次数）。然后，我们再按照一定的规则，给剩下的从库逐个打分（从库优先级、从库复制进度= master_repl_offset-slave_repl_offset 以及从库 ID 号），将得分最高的从库选为新主库。 通知。哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上 单哨兵也可能会出问题，所以可以使用哨兵集群： 切片集群 当数据量变大以后，就需要扩展，如果只是单纯的扩大单个Redis的内存，会导致fork时间变长，Redis性能变差。此时需要纵向扩展。通过切片集群解决，这里即对一个K-V,先通过K找到需要保存到那个redis示例，在通过K找到在redis的hash表的存放位置。对于第一步来说，还需要考虑负载均衡的问题。 实际：Redis Cluster是通过Hash Slot实现的，一个环状的hash槽（16384个），通过hash算法（hash(key)%N）找到slot位置。在部署时，Redis会自动将这些槽平均到集群实例上。 如何知道哈希槽分布在哪个实例上？Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键所对应的哈希槽，然后就可以给相应的实例发送请求了。 当出现增删节点和负载均衡情况等变化的情况，通过重定向机制处理，即原本的实例存放了变更的位置，会通过重定向将请求发给变更的位置 缓冲区缓冲区是Redis中用于，当客户端和服务端进行通信时，暂存客户端命令或服务端结果的。 淘汰策略 对于缓存来说，淘汰策略很重要，通过时间局部性和空间局部性来保证缓存的作用 单范围淘汰，即对设置了过期时间的数据进行淘汰 全范围淘汰，按照淘汰算法对所有数据进行 LRU（Redis）实现：在RedisObject中有个lru字段，保存一个数据访问的时间戳，因为数据量很大，Redis也只是抽取一定数量的数据，然后对齐按照lru的大小进行淘汰 LFU（Redis）实现: 也是使用RedisObject中lru字段，总共24bit，拆为16bit（时间戳）,counter(8bit)访问值（最大255）。Redis 并没有采用数据每被访问一次，就给对应的 counter 值加 1 的计数规则，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。这样可以保证访问次数很大也可以进行比较，但是这样本身存在一定误差，数据量大的时候其counter值才置信。 事务 Redis的事务，一致性和隔离性可以保证，持久性和原子性不行。 缓存异常问题缓存雪崩问题：应用请求无法在Redis处理，大量的被传导到数据库了 大量数据同时到期 -&gt; a. 微调时间，给业务数据加上一个小的随机数 b. 服务降级，只保证核心内容服务 Redis实例宕机导致 -&gt; a.进行服务熔断和请求限流 b. 建立高可靠的集群 缓存击穿问题：对于某个热点数据的访问很频繁，但是此时该数据刚好过期，导致大量请求到了数据库。 解决办法：对于热点数据，不设置过期时间 缓存穿透问题：要访问的数据即不在Redis缓存也不在数据库，通常由于业务层误操作或者恶意攻击导致 解决办法： 缓存空值 使用Bloom Filer（一个初值全为0的数组和N个hash函数组成，对于某个值，如果存在，则使用N个hash将它的位置置为1）快速判断数据是否存在。（存在一定通过Bloom Filter，不存在大部分通不过Bloom Filter） 对请求进行合法校验，避免恶意请求 缓存与数据库数据不一致问题核心：需要保证缓存中有数据，缓存的数据必须和数据库中相同。没有数据，则数据库中必须为最新值。 解决办法： 读写缓存：同步写回 只读缓存： 先删缓存再更新数据库：无并发，重试机制（使用消息队列保证操作成功） 并发：延迟双删（先删除缓存，再更新数据库，休眠一秒，再次删除缓存） 先更新数据库再删缓存（更好）：无并发，重试机制 并发：在客户端暂存并发请求","categories":[{"name":"Redis","slug":"Redis","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/Redis/"}]},{"title":"MySQL事务","slug":"MySQL事务","date":"2022-01-11T08:44:02.000Z","updated":"2022-01-14T03:03:51.154Z","comments":true,"path":"2022/01/11/MySQL事务/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/11/MySQL%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"Mysql事务在业务实现时，通常需要保证一批SQL同时具备ACID特性。 ACID: 原子性（Atomicity）：事务内SQL要么同时成功要么同时失败 ，基于UndoLog实现。 一致性（Consistency）：系统从一个正确态转移到另一个正确态，由应用通过AID来保证，并非数据库的责任。 隔离性（Isolation）：控制事务并发执行时数据的可见性，当多个应用并发访问数据库系统时，提供了一种隔离方法，防止彼此的操作相互干扰，基于锁和MVCC实现。 持久性（Durability）：提交后一定存储成功不会丢失，基于RedoLog实现。 日志系统 Undo日志记录某数据被修改前的值，可以用来在事务失败时进行rollback；Redo日志记录某数据块被修改后的值，可以用来恢复未写入data file的已成功事务更新的数据。 实现原子性：通过日志将所有对数据的更新操作都写入日志。如果事务一部分操作已完成又无法全部完成，则通过undolog将执行成功的操作撤销 实现持久性：在事务提交之前，redo log已经持久化了，对于已经执行成功未写入磁盘的操作，会通过redo log写入磁盘 最常见的场景是，数据库系统崩溃后重启，此时数据库处于不一致的状态，必须先执行一个crash recovery的过程：读取日志进行REDO（重新执行所有已经执行成功，但尚未写入到磁盘的操作，保证持久性），再对所有崩溃时尚未成功提交的事务进行进行undo（撤销所有执行一部分但尚未提交的操作，保证原子性）。crash recovery结束后，数据库恢复到一致性状态，可以继续被使用。 Todo: Redo Log Undo Log 锁与MVCC 隔离性: 数据库允许多个并发事务同时对数据进⾏读写和修改的能⼒，且互相不影响，看起来像串⾏执⾏⼀样， 并不会出现由于事务交叉执⾏⽽导致的数据不⼀致 如何判断一个事务调度是正确的：⼀个并发事务的调度执⾏结果能和多种串⾏执⾏的其中⼀个结果相等，我们认为这是⼀个正确的调度， 称之为serializable schedule 应该满足A+B = 2120 隔离级别： RAED UNCOMMITED：使用查询语句不会加锁，可能会读到未提交的行（Dirty Read）； READ COMMITED：只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近，所以再多次使用查询语句时，可能得到不同的结果（Non-Repeatable Read 不可重复读是读取了其他事务更改的数据，针对update操作）； REPEATABLE READ：加记录锁和间隙锁。多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但是可能发生幻读（读取了其他事务新增的数据，针对insert和delete操作）； SERIALIZABLE：InnoDB 隐式地将全部的查询语句加上共享锁，解决了幻读的问题； 并发产⽣的异象，本质上是出现了冲突： W-W冲突：两个事务先后修改了同⼀个数据库的相同object W-R冲突：⼀个事务T1修改某个object后(未提交)，另⼀个事务T2对改object进⾏了读操作 R-W冲突：⼀个事务T1读取了某个object或者某个range后，另⼀个事务T2对object或者range进⾏了修改 并发控制 2PL - 读写锁 可能发生死锁。需要进行死锁检测或死锁预防 T/O - T/O的核⼼思想就是利⽤时间戳来决定事务之间的等价执⾏顺序：如果TS(Ti) &lt; TS(Tj)，那么数据库必须保证实际的 schedule先执⾏Ti，后执⾏Tj的结果等价。 OCC - todo MV2PL: MVTO - todo MVOCC - todo MVCC为了提⾼数据库的并发性能，⼈们提出了MVCC(Multi-Version Concurrency Control)来实现读写互不阻塞，从⽽提⾼数据 库的并发性能 MySQL实现的是多版本的两阶段锁协议(Multiversion 2PL)将MVCC和2PL结合。每一个版本的数据行都有一个唯一的时间戳。 读事务：从多个（可见（时间戳早于当前事务））版本的数据项中返回具有最大时间戳的 更新操作：读取最新版本（可见）的数据计算更新的结果，然后创建一个新版本的数据，新数据的时间戳为当前数据行的最大版本+1 删除操作：MySQL 会将版本最低的数据定时从数据库中清除以保证不会出现大量的遗留内容 Reference锁与MVCC","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/MySQL/"}]},{"title":"系统监控","slug":"系统监控","date":"2022-01-10T16:26:10.000Z","updated":"2022-01-10T16:35:15.193Z","comments":true,"path":"2022/01/11/系统监控/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/11/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/","excerpt":"","text":"Go系统监控的设计和实现原理守护进程：后台运行的计算机程序，有操作系统启动，会在整个系统的生命周期存在，随着系统的启动而启动，系统的结束而结束。 Go的系统监控，会在内部启动一个不会中止的循环，循环内部进行网络轮询，抢占长期运行或者处于系统调用的Goroutine以及触发垃圾回收 监控循环启动时机：main函数进入时会通过系统调用创建一个新线程并启动系统监控（sysmon） 1234567891011121314151617181920func sysmon() &#123; sched.nmsys++ checkdead() //检查是否存在死锁 lasttrace := int64(0) idle := 0 delay := uint32(0) for &#123; //监控循环 if idle == 0 &#123; delay = 20 &#125; else if idle &gt; 50 &#123; delay *= 2 &#125; if delay &gt; 10*1000 &#123; delay = 10 * 1000 &#125; usleep(delay) //挂起当前线程 ... &#125;&#125; 在程序稳定后，系统监控会每10ms触发一次，完成如下工作: 运行计时器 — 获取下一个需要被触发的计时器； 轮询网络 — 获取需要处理的到期文件描述符； 抢占处理器 — 抢占运行时间较长的或者处于系统调用的 Goroutine； 垃圾回收 — 在满足条件时触发垃圾收集回收内存； 运行计时器轮询网络抢占处理器垃圾回收https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-sysmon/","categories":[],"tags":[]},{"title":"网络轮询器","slug":"网络轮询器","date":"2022-01-09T16:37:38.000Z","updated":"2022-01-09T18:30:20.399Z","comments":true,"path":"2022/01/10/网络轮询器/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/10/%E7%BD%91%E7%BB%9C%E8%BD%AE%E8%AF%A2%E5%99%A8/","excerpt":"","text":"IO与网络轮询器如今的大部分服务都是I/O密集型的，应用会花费大量的时间等待I/O操作完成。Go使用了网络轮询器用于处理I/O操作，底层使用了操作系统的多路复用机制epoll 通常的IO多路模型是通过回调机制进行控制的，Go的话将其隐藏在了runtime中了，Go开发者无需关注socket是否是 non-block的，也无需亲自注册文件描述符的回调，只需在每个连接对应的goroutine中以“block I/O”的方式对待socket处理即可。 原理和前言作用：监控网络I/O，文件I/O I/O模型“ 阻塞I/O模型：非阻塞I/O模型：I/O多路复用：网络轮询器：网络轮询器 多路复用依赖于epoll 机制 epoll 机制包含两个fd:epfd 和 待读写数据的fd（比如socket）。先创建efpd，然后向epfd 注册fd事件， 之后触发epoll_wait 轮询注册在epfd 的fd 事件发生了没有。 netpoller 负责将 操作系统 提供的nio 转换为 goroutine 支持的blocking io。为屏蔽linux、windows 等底层nio 接口的差异，netpoller 定义一个虚拟接口来封装底层接口。 接口12345func netpollinit() //单例，初始化轮询器func netpollopen(fd uintptr, pd *pollDesc) int32 //监听FD的事件，创建事件并加入监听func netpoll(delta int64) gList //轮询网络并返回一组已经准备就绪的Goroutine &lt;0 无限期等待 =0 非阻塞轮询 &gt;0 阻塞特定时间轮询func netpollBreak() //中断轮询器func netpollIsPollDescriptor(fd uintptr) bool //判断FD是否被轮询器使用 数据结构 pollCache是一个运行时包的全局变量，包含一个互斥锁和一个链表（pollDesc链表),pollDesc是对fd的封装 初始化和释放： 1234567891011121314151617181920func (c *pollCache) alloc() *pollDesc &#123; lock(&amp;c.lock) if c.first == nil &#123; //初次初始化时，会进行批量初始化以增加吞吐量 const pdSize = unsafe.Sizeof(pollDesc&#123;&#125;) n := pollBlockSize / pdSize if n == 0 &#123; n = 1 &#125; mem := persistentalloc(n*pdSize, 0, &amp;memstats.other_sys) for i := uintptr(0); i &lt; n; i++ &#123; pd := (*pollDesc)(add(mem, i*pdSize)) pd.link = c.first c.first = pd &#125; &#125; pd := c.first //返回的是链表头的没有使用过的pollDesc c.first = pd.link unlock(&amp;c.lock) return pd&#125; 已经用过的pollDesc会在运行时调用free释放 123456func (c *pollCache) free(pd *pollDesc) &#123; lock(&amp;c.lock) pd.link = c.first //释放时将其出队 c.first = pd unlock(&amp;c.lock)&#125; 多路复用网络轮询器的初始化调用 internal/poll.pollDesc.init 初始化文件描述符时不止会初始化网络轮询器，会通过 runtime.poll_runtime_pollOpen 函数重置轮询信息 runtime.pollDesc 并调用 runtime.netpollopen 初始化轮询事件。runtime.netpollopen 会调用 epollctl 向全局的轮询文件描述符 epfd 中加入新的轮询事件监听文件描述符的可读和可写状态 如何向网络轮询器加入待监控的任务如何从网络轮询器获取触发的事件事件循环 等待事件：在fd执行读写操作，如果fd不可读或者不可写，当前Goroutine会执行pollWait让出线程 12345678910111213141516171819func poll_runtime_pollWait(pd *pollDesc, mode int) int &#123; ... for !netpollblock(pd, int32(mode), false) &#123; ... &#125; return 0&#125;func netpollblock(pd *pollDesc, mode int32, waitio bool) bool &#123; gpp := &amp;pd.rg //检查pollDesc状态 if mode == &#x27;w&#x27; &#123; gpp = &amp;pd.wg &#125; ... if waitio || netpollcheckerr(pd, mode) == 0 &#123; gopark(netpollblockcommit, unsafe.Pointer(gpp), waitReasonIOWait, traceEvGoBlockNet, 5) //让出当前线程，Goroutine转换到休眠状态并等待运行时唤醒 &#125; ...&#125; 轮询等待 Go的runtime会在调度或系统监控中调用netpoll轮询网络 步骤： 根据传入的delay计算epoll系统调用需要等待的时间 调用epollwait等待可读或可写事件 在循环中依次处理epollevent事件 1234567891011121314151617181920212223242526272829303132333435363738394041424344var events [128]epolleventretry: n := epollwait(epfd, &amp;events[0], int32(len(events)), waitms) //等待fd可读或可写 if n &lt; 0 &#123; //epoll返回负值，返回空gList或者重试 if waitms &gt; 0 &#123; return gList&#123;&#125; &#125; goto retry &#125;//如果大于0，则在循环中处理事件var toRun gList for i := int32(0); i &lt; n; i++ &#123; ev := &amp;events[i] //netpollBreak的事件，中断网络轮询器 if *(**uintptr)(unsafe.Pointer(&amp;ev.data)) == &amp;netpollBreakRd &#123; ... continue &#125; //正常的读写事件，通过netpollready进行处理 var mode int32 if ev.events&amp;(_EPOLLIN|_EPOLLRDHUP|_EPOLLHUP|_EPOLLERR) != 0 &#123; mode += &#x27;r&#x27; &#125; ... if mode != 0 &#123; pd := *(**pollDesc)(unsafe.Pointer(&amp;ev.data)) pd.everr = false netpollready(&amp;toRun, pd, mode) &#125; &#125; return toRunfunc netpollready(toRun *gList, pd *pollDesc, mode int32) &#123; var rg, wg *g ... if mode == &#x27;w&#x27; || mode == &#x27;r&#x27;+&#x27;w&#x27; &#123; wg = netpollunblock(pd, &#x27;w&#x27;, true) //将pd中的读写信号转换为pdReady，并返回pd的Goroutine &#125; ... if wg != nil &#123; toRun.push(wg) //加入待执行列表，Goroutine列表会被加入到处理器或者全局运行队列 &#125;&#125; 截止日期计时器依赖于网络轮询器唤醒，文件和网络I/O的截止日期也由其负责处理。 123456789101112131415161718192021222324//用于设置截止日期func poll_runtime_pollSetDeadline(pd *pollDesc, d int64, mode int) &#123; rd0, wd0 := pd.rd, pd.wd if d &gt; 0 &#123; d += nanotime() &#125; pd.rd = d //先使用截止日期计算过期的时间点 ... if pd.rt.f == nil &#123; //如果没有设置执行的函数 if pd.rd &gt; 0 &#123; pd.rt.f = netpollReadDeadline //设置计时器到期执行的函数 pd.rt.arg = pd pd.rt.seq = pd.rseq resettimer(&amp;pd.rt, pd.rd) //重置计时器 &#125; &#125; else if pd.rd != rd0 &#123; //如果截止日期已改变 pd.rseq++ if pd.rd &gt; 0 &#123; //新截止日期 &gt; 0 ，修改计时器 modtimer(&amp;pd.rt, pd.rd, 0, rtf, pd, pd.rseq) &#125; else &#123; //新日期 &lt; 0 ，删除计时器, 并会在后面直接唤醒对应的Goroutine deltimer(&amp;pd.rt) pd.rt.f = nil &#125; &#125; 运行时会在计时器到期时调用netpolldeadlineimpl,直接使用netpollgoready唤醒对应的Goroutine，Goroutine被唤醒后，会意识到当前I/O操作已经超时，选择重试或者终止调用 IO前后的GPM G1 正在 M 上执行，还有 3 个 Goroutine 在 LRQ 上等待执行。网络轮询器空闲着，什么都没干。 G1 想要进行网络系统调用，因此它被移动到网络轮询器并且处理异步网络系统调用。然后，M 可以从LRQ 执行另外的 Goroutine。此时，G2 就被上下文切换到 M 上了。 异步网络系统调用由网络轮询器完成，G1 被移回到 P 的 LRQ 中。一旦 G1 可以在 M 上进行上下文切换，它负责的 Go 相关代码就可以再次执行。执行网络系统调用不需要额外的 M。网络轮询器使用系统线程，它时刻处理一个有效的事件循环/eventloop。 小结网络轮询器并不是一个独立运行的，调度器和系统调用都会通过netpoll与网络循环器交换信息，获取待执行的GoRoutine列表，并将待执行的Goroutine加入运行队列等待处理","categories":[],"tags":[{"name":"Go基础","slug":"Go基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/Go%E5%9F%BA%E7%A1%80/"}]},{"title":"手撸DSL和gRPC解析.proto分析","slug":"手撸DSL和gRPC解析-proto分析","date":"2022-01-07T03:27:36.000Z","updated":"2022-01-10T07:05:14.233Z","comments":true,"path":"2022/01/07/手撸DSL和gRPC解析-proto分析/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/07/%E6%89%8B%E6%92%B8DSL%E5%92%8CgRPC%E8%A7%A3%E6%9E%90-proto%E5%88%86%E6%9E%90/","excerpt":"","text":"DSL和gRPC protoc-gen-goDSL介绍定义：DSL(Domain Specific Language)为领域特定语言，GPL(General Purpose Language)通用编程语言(图灵完备)，比如C，C++，Python，C#等 常见的DSL：1. Regex,HTML,CSS,CocoaPods,Grandle,SQL Regex: 正则表达式，指定了字符串的模型，会判断当前字符串跟正则表达式是否匹配 SQL: 用于操作数据库，数据库会从SQL语句读取信息，然后返回使用者期望的结果 CocoaPods|Grandle: 设定了具体的规则，用于管理第三方库和工程配置 如何手撸DSL构建DSL 设计语法和语义，定义DSL中的元素（token）是什么样的，元素（token）代表什么意思 实现parser，对DSL进行解析，生成并处理抽象树(AST)，DSL最终通过解释器来执行 内部DSL和外部DSL外部DSL：语法语义，语法解析器和抽象树的处理都需要自己完成。 内部DSL：内部DSL嵌入一些编程语言中的，比如iOS的CocoaPods(Ruby)和Android的Gradle(Groovy)。 内部DSL使用了宿主的能力，不需要实现语法分析器(Parser)，通常会使用宿主语言的特性进行创造。 CocoaPods分析： 为什么基于Ruby: ruby一切皆对象，减少了语言中的元素，不存在基本类型，操作符 ruby方法传入代码块很方便 作为解释执行的语言，eval可以将字符串作为代码执行 代码格式不受限 Podfile: 123456source &#x27;https://github.com/volcengine/volcengine-specs.git&#x27; source &#x27;https://cdn.cocoapods.org/&#x27; target &#x27;testTTAcount&#x27; do pod &#x27;gRPC-Swift&#x27;, &#x27;~&gt; 1.0.0&#x27;end Source: 依赖的源地址 Target: 要添加依赖的工程的名字 Pod: 表示依赖，gRPC-Swift为依赖库，后面为版本号 将上面的部分以更符合代码形式则表示为: 在执行时会作为Ruby代码来执行 123456source(&#x27;https://github.com/volcengine/volcengine-specs.git&#x27;)source(&#x27;https://cdn.cocoapods.org/&#x27;)target(&#x27;testTTAcount&#x27;) do pod (&#x27;gRPC-Swift&#x27;, &#x27;~&gt; 1.0.0&#x27;)end 如何使用Ruby实现一个简单的内部DSL 创建一些Podfile中”代码“执行的上下文，即一些方法。 读取Podfile中的内容到脚本中。 使用eval在上下文中执行Podfile的”代码“ 实现： 12345678source &#x27;https://github.com/volcengine/volcengine-specs.git&#x27; source &#x27;https://cdn.cocoapods.org/&#x27;platform :ios, &#x27;10.0&#x27;target &#x27;testTTAcount&#x27; do pod &#x27;gRPC-Swift&#x27;, &#x27;~&gt; 1.0.0&#x27;end 这里的source, platform, target,pod都是方法，所以需要构建包含这些方法的上下文 123456789101112131415161718# eval_pod.rb$hash_value = &#123;&#125; //存储指定的依赖def source(url)enddef target(target)enddef platform(platform, version)enddef pod(pod)endcontent = File.read &#x27;./Podfile&#x27;//从一个podfile中读取eval content //使用eval执行，读取的内容（作为ruby代码执行）p $hash_value //打印指定的依赖 简单实现一下： 123456789101112131415161718192021def source(url) $hash_value[&#x27;source&#x27;] = urlenddef target(target) targets = $hash_value[&#x27;targets&#x27;] targets = [] if targets == nil targets &lt;&lt; target $hash_value[&#x27;targets&#x27;] = targets yield if block_given?enddef platform(platform, version)enddef pod(pod) pods = $hash_value[&#x27;pods&#x27;] pods = [] if pods == nil pods &lt;&lt; pod $hash_value[&#x27;pods&#x27;] = podsend 12$ ruby eval_pod.rb&#123;&quot;source&quot;=&gt;[&#x27;https://github.com/volcengine/volcengine-specs.git&#x27;,&#x27;https://cdn.cocoapods.org/&#x27;], &quot;targets&quot;=&gt;[&quot;testTTAcount&quot;], &quot;pods&quot;=&gt;[&quot;gRPC-Swift&quot;, &quot;SDWebImage&quot;]&#125; 编译原理:编译的过程： 预处理: 头文件替换 宏展开 注释清除 预编译指令处理 条件编译 … 词法分析: 简单的说就是想读英文文章一样，先一个一个的读出单词，获取到单词的意思。 这里将“词法记号”，即token。词法分析的过程叫做分词，可以将语句切割成多个token 通过正则文法读取 通过有限自动机 语法分析： 在词法分析的基础上识别程序的语法结构，生成一个树状结构，即抽象语法树(AST Abstract Syntax Tree) Eg: 1+2*3 语义分析： 基于AST，编译器会进行语义分析。语义分析会标注在抽象语法树的节点上。 Eg: 某个表达式的结果是什么类型？不一样能否自动转换 一个代码块内部和外部有相同名称的变量，执行时应该用哪一个 中间代码生成： 一般来说，编译器会有一个抽象于机器平台的中间语言（IR）以便后续的机器无关的优化 代码优化： 机器无关的优化。函数内联，for循环展开 目标代码生成： 生成目标平台的代码，如果是编译型的语言，往往是产生.o文件。这里编译器的工作已经结束了。 词法分析，语法分析，语义分析为编译器前端内容 中间代码生成，代码优化，目标代码生成为编译器后端内容 ANTLR:教程文档:https://wizardforcel.gitbooks.io/antlr4-short-course/content/ 官网：https://www.antlr.org/support.html 介绍: ANTLR v4是一款功能强大的语法分析器生成器，可以用来读取、处理、执行和转换结构化文本或二进制文件。它被广泛应用于学术界和工业界构建各种语言、工具和框架。 从称为文法的一种形式化的语言描述中，ANTLR生成该语言的语法分析器。生成的语法分析器可以自动构建语法分析树——表示文法如何匹配输入的数据结构。ANTLR还可以自动生成树遍历器，你可以用它来访问那些树的节点，以执行特定的代码。 原理： ANTLR原理 ANTLR-Go 算法表达式示例 词法定义： 词法规则类似与正则表达式，这里即关注数字和加减乘除，忽略空白符 文法规则： start为文法的入口； expresion定义了具体的计算表达式。 表达式：表达式可以是一个数字，数字的加减乘除，表达式的加减乘除，或者通过括号包裹表达式组合。 规则名称： antlr会将.g4定义的规则生成一个解析器的代码框架，能自动解析并生成AST。业务层拿到抽象语法树以后，还需要根据AST来处理业务逻辑以及业务需求 上下文标记： 为文法规则分配上下文标记，该标记可用再业务代码处理AST时，更加明确区分当前上下文的规则。 比如在：AdditionOrSubstraction这行，左右表达式都是expressin，这里通过上下文标记，left=,right=的方式为左右expresion添加了上下文标记，这样业务代码也就可用区分左右表达式了 生成解析器（Visitor模式|Listener模式） Visitor模式： 执行对于语言的命令后，会生成对应语言下的代码： 其中calcLexer是词法分析器，calcParser是语法分析器，calcVisitor是遍历AST的访问器的interface，业务代码需要实现该interface实现具体的业务需求逻辑 生成的结构： 根据名字大概可以看出各个文件的作用，calc_lexer为词法分析器，作用是生成tokens流。calc_parser是语法分析器，用于生成AST。calcVisitor是用于遍历AST的访问器的接口，业务代码通过实现该接口来实现具体的业务逻辑。 在calc_visitor这个接口中，定义了一系列以visit为前缀的函数，这些函数对应了.g4中的每一个规则名称。 eg: visitNumber对应了.g4里的#Number规则 这些访问函数，都接收一个上下文参数，不同的规则，上下文参数会有差异，最主要就是会有不同的上下文标记可用使用。 123456789101112131415161718192021type CalcVisitor interface &#123; antlr.ParseTreeVisitor // Visit a parse tree produced by CalcParser#start. VisitStart(ctx *StartContext) interface&#123;&#125; // Visit a parse tree produced by CalcParser#Number. VisitNumber(ctx *NumberContext) interface&#123;&#125; // Visit a parse tree produced by CalcParser#MultiplicationOrDivision. VisitMultiplicationOrDivision(ctx *MultiplicationOrDivisionContext) interface&#123;&#125; // Visit a parse tree produced by CalcParser#AdditionOrSubstraction. VisitAdditionOrSubstraction(ctx *AdditionOrSubstractionContext) interface&#123;&#125; // Visit a parse tree produced by CalcParser#Parentheses. VisitParentheses(ctx *ParenthesesContext) interface&#123;&#125; // Visit a parse tree produced by CalcParser#Power. VisitPower(ctx *PowerContext) interface&#123;&#125;&#125; 关键函数.visit：这个函数是遍历AST的核心函数，这个函数内部会根据visit的具体规则，进入到visitXXX函数，在具体的visitXXX函数，又通过业务代码调用.visit来实现深度优先遍历 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package visitorimport ( &quot;Calc/parser&quot; &quot;fmt&quot; &quot;github.com/antlr/antlr4/runtime/Go/antlr&quot; &quot;math&quot; &quot;strconv&quot;)func _opt(opr string,a,b interface&#123;&#125;) int &#123; //处理算术运行逻辑 fmt.Println(&quot;_opt&quot;,opr,a,b) a1,b1 := a.(int),b.(int) switch opr[0] &#123; case &#x27;+&#x27;: return a1+b1 case &#x27;-&#x27;: return a1-b1 case &#x27;*&#x27;: return a1*b1 case &#x27;/&#x27;: return a1/b1 case &#x27;^&#x27;: return int(math.Pow(float64(a1),float64(b1))) default: panic(&quot;_opt err&quot;) return 0 &#125;&#125;type MyCalVisitor struct &#123; parser.BaseCalcVisitor&#125;func (v *MyCalVisitor) Visit(tree antlr.ParseTree) interface&#123;&#125; &#123;//目前Go的实现为返回nil，需要自己处理一下 switch val := tree.(type) &#123; case *parser.NumberContext: return v.VisitNumber(val) case *parser.MultiplicationOrDivisionContext: return v.VisitMultiplicationOrDivision(val) case *parser.AdditionOrSubstractionContext: return v.VisitAdditionOrSubstraction(val) case *parser.ParenthesesContext: return v.VisitParentheses(val) case *parser.PowerContext: return v.VisitPower(val) default: return nil &#125;&#125;func (v *MyCalVisitor) VisitStart(ctx *parser.StartContext) interface&#123;&#125; &#123;//入口，为一个表达式 fmt.Println(&quot;VisitStart&quot;) return v.Visit(ctx.Expression())&#125;func (v *MyCalVisitor) VisitNumber(ctx *parser.NumberContext) interface&#123;&#125; &#123;//解析token为一个数字 fmt.Println(&quot;VisitNumber&quot;) num,_ := strconv.Atoi(ctx.NUMBER().GetText()) fmt.Println(num) return num&#125;func (v *MyCalVisitor) VisitMultiplicationOrDivision(ctx *parser.MultiplicationOrDivisionContext) interface&#123;&#125; &#123; //乘除算术运算 fmt.Println(&quot;VisitMultiplicationOrDivision&quot;) a := v.Visit(ctx.GetLeft()) b := v.Visit(ctx.GetRight()) return _opt(ctx.GetOperator().GetText(),a,b)&#125;func (v *MyCalVisitor) VisitAdditionOrSubstraction(ctx *parser.AdditionOrSubstractionContext) interface&#123;&#125; &#123; //加减算术运算 fmt.Println(&quot;VisitAdditionOrSubstraction&quot;) a := v.Visit(ctx.GetLeft()) b := v.Visit(ctx.GetRight()) return _opt(ctx.GetOperator().GetText(),a,b)&#125;func (v *MyCalVisitor) VisitParentheses(ctx *parser.ParenthesesContext) interface&#123;&#125; &#123; //括号 fmt.Println(&quot;VisitParentheses&quot;) return v.Visit(ctx.GetInner())&#125;func (v *MyCalVisitor) VisitPower(ctx *parser.PowerContext) interface&#123;&#125; &#123; //阶乘 fmt.Println(&quot;VisitPower&quot;) a := v.Visit(ctx.GetLeft()) b := v.Visit(ctx.GetRight()) return _opt(ctx.GetOperator().GetText(),a,b)&#125; protoc-gengenerator.GenerateAllFiles()1234567891011121314151617181920212223242526272829303132// 生成所有.proto文件对应的go源代码，这里只是将源代码内容存储到g.Response中，// 并没有直接创建源代码文件，插件将Response传递给protoc进程后由protoc进程来负// 责创建源代码文件func (g *Generator) GenerateAllFiles() &#123; // Initialize the plugins for _, p := range plugins &#123; p.Init(g) &#125; // Generate the output. The generator runs for every file, even the files // that we don&#x27;t generate output for, so that we can collate the full list // of exported symbols to support public imports. genFileMap := make(map[*FileDescriptor]bool, len(g.genFiles)) for _, file := range g.genFiles &#123; genFileMap[file] = true &#125; for _, file := range g.allFiles &#123; g.Reset() g.writeOutput = genFileMap[file] // 调用generator的generate(...)方法来生成该proto文件的 // FileDescriptorProto描述对应的go源代码 g.generate(file) if !g.writeOutput &#123; continue &#125; g.Response.File = append(g.Response.File, &amp;plugin.CodeGeneratorResponse_File&#123; Name: proto.String(file.goFileName()), Content: proto.String(g.String()), &#125;) &#125;&#125; generator .generate()方法如何实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384// 针对.proto文件（由FileDescriptor表示）生成对应的go源代码func (g *Generator) generate(file *FileDescriptor) &#123; g.file = g.FileOf(file.FileDescriptorProto) g.usedPackages = make(map[string]bool) // 要生成源代码的首个proto文件对应的go源代码，这部分代码顶部插入版权信息 if g.file.index == 0 &#123; // For one file in the package, assert version compatibility. g.P(&quot;// This is a compile-time assertion to ensure that this generated file&quot;) g.P(&quot;// is compatible with the proto package it is being compiled against.&quot;) g.P(&quot;// A compilation error at this line likely means your copy of the&quot;) g.P(&quot;// proto package needs to be updated.&quot;) g.P(&quot;const _ = &quot;, g.Pkg[&quot;proto&quot;], &quot;.ProtoPackageIsVersion&quot;, generatedCodeVersion, &quot; // please upgrade the proto package&quot;) g.P() &#125; // 生成import语句 for _, td := range g.file.imp &#123; g.generateImported(td) &#125; // 生成enum类型定义语句 for _, enum := range g.file.enum &#123; g.generateEnum(enum) &#125; // 生成message类型定义语句 for _, desc := range g.file.desc &#123; // Don&#x27;t generate virtual messages for maps. if desc.GetOptions().GetMapEntry() &#123; continue &#125; g.generateMessage(desc) &#125; // 生成extension类型定义语句 for _, ext := range g.file.ext &#123; g.generateExtension(ext) &#125; // 生成初始化函数语句 g.generateInitFunction() // 前面生成enum、message、extension等的方式都基本类似，后面我们只给出一个 // 生成枚举类型方法的说明，生成message、extension的实现方法可以执行查看 // generator.go中的实现。 // // 需要注意的是，前面的各个生成源代码的方法不能处理service服务定义的rpc接 // 口代码，这部分rpc代码的生成需要借助于grpc子插件来完成，即下面的g.runPlugins(...) g.runPlugins(file) g.generateFileDescriptor(file) // 待输出的源代码需要知道哪些package是需要import的，哪些不需要，因此先运行 // 插件生成go代码中除import之外的其他部分代码，然后知道了哪些package需要 // import，再插入具体的import语句。 // // 最后在go源代码中插入header、import rem := g.Buffer g.Buffer = new(bytes.Buffer) g.generateHeader() g.generateImports() if !g.writeOutput &#123; return &#125; g.Write(rem.Bytes()) // 重新格式化生成的go源代码（gofmt） fset := token.NewFileSet() raw := g.Bytes() ast, err := parser.ParseFile(fset, &quot;&quot;, g, parser.ParseComments) if err != nil &#123; // Print out the bad code with line numbers. // This should never happen in practice, but it can while changing generated code, // so consider this a debugging aid. var src bytes.Buffer s := bufio.NewScanner(bytes.NewReader(raw)) for line := 1; s.Scan(); line++ &#123; fmt.Fprintf(&amp;src, &quot;%5d\\t%s\\n&quot;, line, s.Bytes()) &#125; g.Fail(&quot;bad Go source code was generated:&quot;, err.Error(), &quot;\\n&quot;+src.String()) &#125; g.Reset() err = (&amp;printer.Config&#123;Mode: printer.TabIndent | printer.UseSpaces, Tabwidth: 8&#125;).Fprint(g, fset, ast) if err != nil &#123; g.Fail(&quot;generated Go source code could not be reformatted:&quot;, err.Error()) &#125;&#125; 如何生成enum123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 生成指定enum类型的go源代码func (g *Generator) generateEnum(enum *EnumDescriptor) &#123; // enum类型的完整类型名 typeName := enum.TypeName() // CamelCased之后的完整类型名 ccTypeName := CamelCaseSlice(typeName) ccPrefix := enum.prefix() // 打印enum类型定义之前的leading comments // - 提取源代码信息SourceCodeInfo都是通过Location path来获取的； // - 提取注释信息也不例外，下面我们会介绍PrintComments(path)如何通过 // Location path来生成注释信息； g.PrintComments(enum.path) // 生成枚举类型的定义起始部分：type 枚举类型名 int32 g.P(&quot;type &quot;, ccTypeName, &quot; int32&quot;) g.file.addExport(enum, enumSymbol&#123;ccTypeName, enum.proto3()&#125;) // 枚举类型里面的各个枚举值都作为const int32常量来定义 g.P(&quot;const (&quot;) // 枚举值定义之前缩进一下 g.In() // 针对枚举类型里面的所有枚举值进行源代码生成 for i, e := range enum.Value &#123; // 生成枚举值前面的leading comments g.PrintComments(fmt.Sprintf(&quot;%s,%d,%d&quot;, enum.path, enumValuePath, i)) // 生成枚举值的name = value形式的go源代码 name := ccPrefix + *e.Name g.P(name, &quot; &quot;, ccTypeName, &quot; = &quot;, e.Number) g.file.addExport(enum, constOrVarSymbol&#123;name, &quot;const&quot;, ccTypeName&#125;) &#125; // 枚举值定义完之后取消缩进 g.Out() // 打印最后的结束信息 g.P(&quot;)&quot;) // 生成枚举类型相关的两个map // - 其中一个是枚举值到枚举名的映射； // - 另一个是枚举名到枚举值的映射； g.P(&quot;var &quot;, ccTypeName, &quot;_name = map[int32]string&#123;&quot;) g.In() // 第一个map generated := make(map[int32]bool) // avoid duplicate values for _, e := range enum.Value &#123; duplicate := &quot;&quot; if _, present := generated[*e.Number]; present &#123; duplicate = &quot;// Duplicate value: &quot; &#125; g.P(duplicate, e.Number, &quot;: &quot;, strconv.Quote(*e.Name), &quot;,&quot;) generated[*e.Number] = true &#125; g.Out() g.P(&quot;&#125;&quot;) // 第二个map g.P(&quot;var &quot;, ccTypeName, &quot;_value = map[string]int32&#123;&quot;) g.In() for _, e := range enum.Value &#123; g.P(strconv.Quote(*e.Name), &quot;: &quot;, e.Number, &quot;,&quot;) &#125; g.Out() g.P(&quot;&#125;&quot;) // 其他处理动作，也会生成部分源代码，这里可以忽略不计了 // ...&#125; PrintComments如何通过Location path来提前并打印关联的注释信息 1234567891011121314151617181920// 打印.proto文件中对该location path关联的leading comments注释信息func (g *Generator) PrintComments(path string) bool &#123; if !g.writeOutput &#123; return false &#125; // 在protoc进程解析.proto文件的时候就已经将各个类型、字段的comments信息维 // 护起来了，k就是location的path，通过path就能获取到对应的location，每个 // location中保存了这个位置的源代码的leading comments、trailing comments信 // 息，这里只打印leading comments if loc, ok := g.file.comments[path]; ok &#123; text := strings.TrimSuffix(loc.GetLeadingComments(), &quot;\\n&quot;) for _, line := range strings.Split(text, &quot;\\n&quot;) &#123; g.P(&quot;// &quot;, strings.TrimPrefix(line, &quot; &quot;)) &#125; return true &#125; return false&#125; 如何生成service服务的rpc接口源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106// Run all the plugins associated with the file.func (g *Generator) runPlugins(file *FileDescriptor) &#123; // 在上述generator处理的基础上，继续运行generator中注册的插件，依次运行插件 for _, p := range plugins &#123; p.Generate(file) &#125;&#125;// 生成.proto文件中service定义的rpc接口的go源代码func (g *grpc) Generate(file *generator.FileDescriptor) &#123; // 如果没有定义service服务直接返回 if len(file.FileDescriptorProto.Service) == 0 &#123; return &#125; // 相关变量定义 g.P(&quot;// Reference imports to suppress errors if they are not otherwise used.&quot;) g.P(&quot;var _ &quot;, contextPkg, &quot;.Context&quot;) g.P(&quot;var _ &quot;, grpcPkg, &quot;.ClientConn&quot;) g.P() // 断言，检查版本兼容性 g.P(&quot;// This is a compile-time assertion to ensure that this generated file&quot;) g.P(&quot;// is compatible with the grpc package it is being compiled against.&quot;) g.P(&quot;const _ = &quot;, grpcPkg, &quot;.SupportPackageIsVersion&quot;, generatedCodeVersion) g.P() // 针对所有的service定义生成相关的service的go源代码 for i, service := range file.FileDescriptorProto.Service &#123; g.generateService(file, service, i) &#125;&#125;// grpc中对generateService的实现，生成service相关的go源代码// @param .proto解析后的各种DescriptorProto的wrapping类，通过它可以方便地访问.proto中定义的东西 // @param .proto中的某个service解析后对应的ServiceDescriptorProto// @param .proto中可能定义了多个service，当前这个service对应的索引值func (g *grpc) generateService(file *generator.FileDescriptor, service *pb.ServiceDescriptorProto, index int) &#123; // 构建当前service对应的path! path := fmt.Sprintf(&quot;6,%d&quot;, index) // 6 means service. // 获取service名称 origServName := service.GetName() fullServName := origServName if pkg := file.GetPackage(); pkg != &quot;&quot; &#123; fullServName = pkg + &quot;.&quot; + fullServName &#125; servName := generator.CamelCase(origServName) // 准备生成client相关的go源代码 g.P() g.P(&quot;// Client API for &quot;, servName, &quot; service&quot;) g.P() // 服务用户端go源代码生成 // - type 服务名+Client interface g.P(&quot;type &quot;, servName, &quot;Client interface &#123;&quot;) // - 服务用户端定义的各个接口方法 for i, method := range service.Method &#123; // 打印接口的leading comments g.gen.PrintComments(fmt.Sprintf(&quot;%s,2,%d&quot;, path, i)) // 2 means method in a service. // 生成接口的签名 g.P(g.generateClientSignature(servName, method)) &#125; g.P(&quot;&#125;&quot;) g.P() // 服务的用户端struct，其中包括了一个cc *grpc.ClientConn，后面会在该struct // 上实现上述服务接口 g.P(&quot;type &quot;, unexport(servName), &quot;Client struct &#123;&quot;) g.P(&quot;cc *&quot;, grpcPkg, &quot;.ClientConn&quot;) g.P(&quot;&#125;&quot;) g.P() // NewClient工厂 g.P(&quot;func New&quot;, servName, &quot;Client (cc *&quot;, grpcPkg, &quot;.ClientConn) &quot;, servName, &quot;Client &#123;&quot;) g.P(&quot;return &amp;&quot;, unexport(servName), &quot;Client&#123;cc&#125;&quot;) g.P(&quot;&#125;&quot;) g.P() var methodIndex, streamIndex int serviceDescVar := &quot;_&quot; + servName + &quot;_serviceDesc&quot; // 服务用户端的接口方法实现 for _, method := range service.Method &#123; var descExpr string if !method.GetServerStreaming() &amp;&amp; !method.GetClientStreaming() &#123; // Unary RPC method descExpr = fmt.Sprintf(&quot;&amp;%s.Methods[%d]&quot;, serviceDescVar, methodIndex) methodIndex++ &#125; else &#123; // Streaming RPC method descExpr = fmt.Sprintf(&quot;&amp;%s.Streams[%d]&quot;, serviceDescVar, streamIndex) streamIndex++ &#125; g.generateClientMethod(servName, fullServName, serviceDescVar, method, descExpr) &#125; g.P(&quot;// Server API for &quot;, servName, &quot; service&quot;) g.P() // 服务端接口go源代码生成 ...&#125; generator生成service以为的代码，grpc生成service相关的go代码 参考: https://draveness.me/dsl/ https://www.hitzhangjie.pro/blog/2017-05-23-protoc%E5%8F%8A%E6%8F%92%E4%BB%B6%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E7%B2%BE%E5%8D%8E%E7%89%88/#242-%E5%9B%9E%E9%A1%BE%E4%B8%80%E4%B8%8Bcodegeneratorrequest--codegeneratorresponse%E7%9A%84%E5%AE%9A%E4%B9%89","categories":[],"tags":[]},{"title":"MySQL - 索引和调优小结","slug":"MySQL-索引和调优小结","date":"2022-01-06T13:28:07.000Z","updated":"2022-01-29T09:10:15.228Z","comments":true,"path":"2022/01/06/MySQL-索引和调优小结/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2022/01/06/MySQL-%E7%B4%A2%E5%BC%95%E5%92%8C%E8%B0%83%E4%BC%98%E5%B0%8F%E7%BB%93/","excerpt":"","text":"MySQL索引和SQL调优MySQL索引MySQL支持多种引擎，各种引擎对所有的支持不同，因此MySQL数据库支持多种索引类型，如BTree索引，哈希索引，全文索引等等。其中只有为BTree索引。 B-Tree索引：eg: key(last_name, first_name, birthday) 适用于全键值，键值范围，键前缀查找 全值匹配：和索引的所有列匹配，查询一个名为 ab出生日期c的 人 匹配最左前缀：匹配 last_name = a的人，只使用了索引的第一列 匹配列前缀：查询last_name的第一个字母为J的人 匹配范围值：查询last_name在allen和Bob之间的人，只使用了索引第一列 精确匹配某一列并范围匹配另一列：查询姓为allen，名字k开头的人。即第一列last_name精确匹配，第二列first_name范围匹配 覆盖索引：即要查的数据都在索引中包含了，即不需要回查具体的行的内容 索引用于ORDER BY: 满足上述范围的查询，进行order by也可以使用索引 限制： 最左前缀匹配优先：如果不是按照索引最左列开始查找，就无法使用索引。比如上述的所有无法查找first_name = bill 的人，需要取出所有的值，然后再匹配 不能跳过索引中的列：比如无法在索引上找到last_name=’Smith’并且birthday=”1997-01-01”的人，只能通过索引找到last_name=Smith的所有行，然后在去匹配 如果最左匹配中遇到某一行为范围查询，则后续的列都无法使用索引：比如 where last_name = ‘Smith’ AND first_name list ‘%j’ and birthday = ‘1997-01-01’则会找到满足last_name和first_name的，然后取出所有行再和birthday做匹配 MySQL索引原理目的：提高查询效率（读，写），数据库的查询情况复杂，包括等值查询，范围查询，模糊查询，并集查询，多值匹配等。需要每次查找数据时，磁盘IO次数较少，高度可控的多路搜索树就是很好的选择。 索引结构：B+树 B+树B+树的重要性质： 索引字段越小，数据项的数目越多，树的高度越低 - 所以B+树的索引字段要尽量小 最左匹配：当B+树的数据项是复合的数据结构，比如(name, age, sex)的时候，b+树是按照从左到右的顺序来构建搜索树的。比如(张三，24，F)进行检索时，会优先比较name来确定下一个搜索方向，name相同再依次比较age，sex，最后得到检索的数据。 但是当(24,F)这样的没有name的数据来的时候，B+数不知道下一步该查哪一个节点 当（张三，F）进行检索，先根据name进行搜索，由于age缺失，只能把所有满足张三的都找到，然后再匹配性别为F的数据 B+树在磁盘存储中表现的特性 为了节省内存，是把B+树存储到硬盘中的，对于每一个节点的访问都对应了一次磁盘IO操作 -&gt; 树的高度 == 查询时的磁盘IO次数 一个m叉树，m越大高度越低。但是操作系统是按页（4KB）来读取磁盘或内存中的数据的。如果读取的数据量超过4KB，则会触发多次IO操作。所以在选择m的大小时，尽量让每个节点的大小等于一个页的大小。这样一个节点只需要一次IO。（总的次数：(向上取整)(节点大小)/4KB * 树的高度） 数据的增加删除修改都会导致B+树结构调整，自增字段会减少消耗 MySQL索引的实现主要为MyISAM和InnoDB MyISAM索引实现 使用B+树，叶子节点存放的是数据的地址。 在MyISAM中，主索引和辅助索引在结构上都是一样的，只是主索引要求key是唯一的 上图使用的是Col1作为Primary Key,如果使用Col2作为辅助索引如下图 所以，对于MyISAM来说，索引检索为首先按照B+树的方式搜索索引，找到key以后读取地址值，再根据地址值读取相应的数据（非聚集的索引） InnoDB索引实现使用B+树，但是InnoDB的数据文件本身就是索引文件，表数据文件本身是按照B+树组织的一个索引结构，叶节点保存了完整的数据，索引key是数据表的主键。这种叫做聚集索引。 由于InnoDB的数据文件本身需要根据主键组织，所以InnoDB要求必须有主键（MyISAM可以没有） 如果没有显示指定，则MySQL会自动旋转一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则会自动生成一个隐含字段作为主键（自增，6字节的长整形） 由于InnoDB的表数据文件按照B+数组织，所以对于InnoDB的辅助索引来说，辅助索引的叶子节点需要保存的是主键的值而不是地址 造成的不同：聚集索引的方式会使得按照主键（主索引）搜索的方式变得高效，但是对于辅助索引来说，需要进行两次检索（使用辅助索引检索到主键，然后在主索引通过主键找到记录） 重要特性： InnoDB的索引形式，导致其使用过长的字段作为主键，它的所有辅助索引都会因此变得过大 使用非单调的字段作为主键，在InnoDB中不是好事，因为InnoDB本身是B+树，非单调的主键会在插入新数据时，B+树频繁的分裂调整，所以使用自增字段作为主键是一个很好的选择 建立索引的原理联合索引： MySQL的索引可以按照一定的顺序引用多个列，这种索引叫做联合索引 一个联合索引是一个有序元祖。 索引匹配的最左原则： 假如索引列分别为A，B，C，顺序也是A，B，C 如果查询[A],[A,B],[A,B,C]可以通过索引查询 如果使用[A,C]，则只能使用到A索引 如果查询的时候，是[B],[B,C],[C]，由于没有用的第一列索引，所以后面的索引也用不到 如果查询时范围查询，并且是最左前缀，也就是第一列索引，那么可以用到索引，但是范围后面的列用不了索引 索引的代价： 索引本身需要空间存储 MySQL运行时也需要维护索引 InnoDB存储引擎：没有特殊情况，使用一个与业务无关的自增主键 磁盘IO: MySQL的数据都是以文件形式存储在磁盘上的，数据库对数据的读取以页为基本单位单位读取，一般为4KB的整数倍。为了提升效率，会有缓冲池（时间局部性&amp;空间局部性） 随机读取和顺序读取：随机读取的消耗时间大约为10ms，内存中的随机读取大约1ms，顺序读写能达到一页0.1ms。所以能减少随机IO，使用顺序读取，会大大提高磁盘吞吐量。 过滤因子：一个 SQL 查询扫描的索引片大小其实是由过滤因子决定的，也就是满足查询条件的记录行数所占的比例。如果过滤因子比较好，则该列的重复字段的比例低。 匹配列和过滤列： users 表中有 name、age 和 (name, sex, age) 三个辅助索引。当where存在age=21或name=”123”时，三个索引都会成功匹配列用于选择索引树中的数据行。 1234SELECT * FROM usersWHERE name = &quot;draven&quot; AND sex = &quot;male&quot; AND age &gt; 20;//对于这种有等值有范围的请求，只会使用name,sex作为匹配列//但是当其扫描到了所有的满足条件的数据行以后，会把age作为过滤列，这样可以减少去磁盘读取IO的情况 建立索引的常见技巧： 最终前缀匹配原则：MySQL会一直向右匹配直到遇见范围查询 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式 尽量选择区分度高的列作为索引，区分度高是指字段不重复的比例，比例越大扫描的记录数越少，唯一键的区分度为1 索引列不参与计算 eg:from_unixtime(create_time) = ’2014-05-29’就不能使用到索引 原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’); Eg: 123SELECT actor_id FROM actor WHERE actor_id + 1 = 5;//这里无法使用 key(actor_id) 因为mysql无法解析表达式SELECT actor_id FROM actor WHERE actor_id = 4; 保证索引列单独在比较符号的左边即可 尽量扩展索引而不是新建索引，比如本身已经有a索引了，需要（a，b）索引，则最好修改原来的索引a为（a，b）最好，否则会存冗余和重复索引（MySQL也不会自动删除） 前缀索引：对于value为字符串类型的索引来说，直接索引值会使得索引变得很大且很慢。如果只是索引开始的部分字符，就可以解决。前缀索引无法用于做ORDER BY和GROUP BY，也不能使用前缀索引做覆盖扫描。 多列索引和合适的索引列顺序：多列索引-&gt;不为每个列建一个索引，而是建一个多列索引。多列索引的顺序最好按照区分度来，区分度搞的在前面。对于有些情况，比如登录用户，除了普通用户以为，还有大量的游客用户是用的相同的username，则最好的办法是在业务层面上做好区分。 使用自增主键 对于常用的查询，建立覆盖索引 使用索引扫描来做排序：如何生成有序的结果：1. 通过排序操作 2. 按索引顺序扫描 扫描索引本身很快，但是不是覆盖索引，就需要回表，基本都是随机IO，所以按索引顺序读取数据通常比全表扫描更慢。只有当索引的列顺序和ORDER BY的子句顺序完全一致，并且排序方向都一致时，才能使用索引对结果进行排序。如果是Join多张表，只有ORDER BY子句引用的字段全是第一个表时，才能使用索引做排序。 索引设计的案列 支持多种过滤条件： 设计一个在线约会网站，用户信息表有很多列，包括国家，地区，城市，性别等。需要支持按照以上特质组合来搜索用户 这里由于sex, country使用的情况非常多，所以需要用(sex, country)列做前缀。但是sex, country的区分度很低，如果某个查询没有使用到sex该怎么办？这里使用 查询条件 AND SEX IN(‘m’, ‘f’) 来让索引能够被使用，包括contry也可以 避免多个范围条件： 在上述的在线约会网站中，有一个last_online列并希望能够查询过去几周上过线的用户： 1WHERE last_online &gt; DATE_SUB(NOW(),INTERVAL 7 DAY) AND age BETWEEN 18 AND 25 对于范围查询，MySQL无法使用范围列后面的其他索引列，但是对于多个“等值条件查询”没有这个限制 这里有两个范围条件, last_online和age，MySQL可以使用last_online或者age，但是没有办法同时使用，如果也无法使用IN来优化为多个等值条件查询，比如这里的，那就可以将范围查询转换为一个简单的等值查询来处理。 这里最好的解决办法是，维护以active列，在业务层使用定时任务来维护。 优化排序： 如何对区分度非常低的列进行排序 123SELECT &lt;cols&gt; FROM users WHERE sex=&#x27;M&#x27; ORDER BY rating LIMIT 10;//这个索引同时使用了ORDER BY 和 LIMIT 如果没有索引会很慢//创建索引 &lt;sex,rating&gt; 但是以上情况在查询翻页比较靠后的情况 LIMIT 100000,10也会很慢 这里需要现在用户翻页的数量，不过也可以通过延迟关联来优化 1SELECT &lt;cols&gt; FROM users INNER JOIN (SELECT &lt;primary key cols&gt; FROM users WHERE x.sex=&#x27;M&#x27; ORDER BY rating LIMIT 100000,10) AS x USING(&lt;primary key cols&gt;) 三星索引概念：如果一个查询语句的索引是三星索引，那么它只需要进行一次磁盘的随机读及一个窄索引片的顺序扫描就可以得到全部的结果集 最简单的方式：在设计单表的索引时，首先把查询中所有的等值谓词全部取出以任意顺序放在索引最前面，在这时，如果索引中同时存在范围索引和 ORDER BY 就需要权衡利弊了，希望最小化扫描的索引片厚度时，应该将过滤因子最小的范围索引列加入索引，如果希望避免排序就选择 ORDER BY 中的全部列，在这之后就只需要将查询中剩余的全部列加入索引了，通过这种固定的方法和逻辑就可以最快地获得一个查询语句的二星或者三星索引了。 Todo: 数据库索引设计与优化 Book","categories":[],"tags":[{"name":"MySql","slug":"MySql","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/MySql/"}]},{"title":"计算广告小结","slug":"计算广告小结","date":"2021-12-31T06:51:42.000Z","updated":"2021-12-31T08:09:21.175Z","comments":true,"path":"2021/12/31/计算广告小结/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/12/31/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A%E5%B0%8F%E7%BB%93/","excerpt":"","text":"计算广告小结 广告基础： 什么是广告？ 广告是由已确定的出资人通过各种媒介进行的有关产品的，有组织，综合，劝服性的非人员的信息传播活动 广告的目的？ 广告主通过媒体达到低成本的用户接触 广告的参与者： 需求方：广告主 供给方：媒体或者其他技术形态的变现平台 受众：普通群众，一个被动的参与方 分类： 大体上是按照售卖方式，分为品牌广告和效果广告。 如果按照广告的形式，可以有多种多样，比如开屏广告，激励视频广告，搜索广告等等。 品牌广告：广告主希望借助媒体达到宣传品牌形象，提升中长期购买率和利润空间的目的。 效果广告：广告主希望能利用广告手段马上带来大量的购买行为。 计算广告： 特点： 技术和计算导向 效果可衡量 创意和投放方式标准化 媒体概念多样化 数据驱动的投放决策 基本概念： 点击率CTR(Click Through Rate):广告点击与广告展现的比率 转化率CVR(Conversion Rate):点击广告以后，会打开广告主的落地页，落地页成功打开次数与点击次数的比率成为到达率。从落地页开始，进一步完成下单等操作，则是转化，转化次数与到达次数的比例成为转化率。 千次展示付费(Cost Per Mille)CPM：广告每展示千次作为单位收取广告费。 千次展示收入(Effective cost per maille)eCPM：每千次展示可以获得的广告收入 常见的收费模式： CPM： 对于效果和目的不便于直接衡量的，可以使用CPM（千次展示收费）方式计费。供给方和需求方约定好千次展示的计费标准，这些展示是否能够代理相应的收益，需要由需求方类估计和控制。 CPC： CPC(Cost Per Click)计费，按点击收费。通常用于效果广告。CPC计费有利于发挥供给方和需求方的长处，把点击率的估计交给供给方，点击价值的估计交给需求方。供给方通过收集大量用户数据，可以准确评估点击率，转化效果则是广告商站内的行为，需要由他们自己的数据分析体系更准确的对其进行评估。 CPS/CPA/ROI: 按照销售订单数，转化行为数，投入产出比来计费。这种情况下，需求方只按照最后的转化收益来结算，极大程度的规避了风险。供给方不但需要估计点击率，还需要对点击价值做出估计，才能合理决定流量分配。 问题： 转化行为对于供给方来说很难控制，也无法进行估计和优化。 存在广告主故意降低转化率以低成本获取大量品牌曝光的可能。 CPT: CPT(Cost Per Time)计费，这是针对大品牌广告主特定的广告活动，将某个广告位以独占的方式交给某广告主，按独占时间段收取费用。CPT虽然有额外的品牌效果和橱窗效应，但是无法利用受众定向技术。 广告投放和广告竞价","categories":[],"tags":[{"name":"其他","slug":"其他","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%85%B6%E4%BB%96/"}]},{"title":"链接,装载，库","slug":"链接-装载，库","date":"2021-12-29T11:13:32.000Z","updated":"2021-12-30T04:00:26.849Z","comments":true,"path":"2021/12/29/链接-装载，库/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/12/29/%E9%93%BE%E6%8E%A5-%E8%A3%85%E8%BD%BD%EF%BC%8C%E5%BA%93/","excerpt":"","text":"链接，装载，库从源代码到内存的通路可执行文件的组成在链接前，需要将源文件编译为目标文件，目标文件链接为可执行文件。可执行文件（动态链接与运行时加载）由多个段组成： 文件头：文件基本信息。 段表：描述各段的基本信息。 基本的代码段和数据段。 链接相关的。（符号的解析和重定位） 装载相关。 可执行文件的加载： 源代码编译而成的目标文件一般依赖系统的运行库和其他共享对象，将它们链接成可执行的程序并加载到内存。有以下这些方式“ 将所有相关文件静态链接成一个完整的可执行文件，然后加载到内存 将目标文件作为可执行文件，载入内存时由动态链接器加载其依赖的其他文件 将目标文件作为可执行文件，载入内存，由程序调用”依赖函数“加载或找到已加载到内存的函数地址，继续执行。 文件的映射程序并不会完整的加载到内存中，会在执行时访问数据发生缺页时再加载。其中有两个关键的映射关系：、 可执行文件各段与虚拟地址空间的映射。（VMA的数据结构） 虚拟地址空间与物理地址空间的映射。（页表） 进程虚拟地址空间的分布：代码区： 数据区： ​ 静态数据区，动态数据区（堆，栈） 符号&amp;模块，静态链接，动态链接符号&amp;模块符号：符号最早起源于汇编的概念，汇编最早使用机器码（数字）来描述指令，操作数，地址值，后续改进为使用符号代替机器码。后续的符号也通常用于表示地址值，对于函数地址和变量地址都以符号来表示。 模块：现代语言中，通常会按照功能划分为不同的模块。在C语言中，若干变量和函数组成了一个模块，存放到一个.c源码文件中，这些源代码文件按照目录结构组织。 大规模软件通常会有很大规模的模块，这些模块直接相互依赖又相互独立。编译器会对每一个模块单独编译，每一个模块都会生成中间文件。中间文件最后会组合为一个单一的可执行文件。 因为模块间存在相互依赖，表现为：1. 模块间的函数调用 2. 模块间的变量访问 函数访问需要知道目标函数的地址，变量访问需要知道变量的地址，即：模块间符号的引用 静态链接：主要过程： 1. 地址和空间分配： + 扫描所有的目标文件，获得它们每个节的长度，属性，位置，并将目标文件中的符号表中所有的符号定义和符合引用收集，统一放到一个全局的符号表。链接器可以获得所有输入目标文件的节的长度，并将它们合并，计算出输出文件中各个节合并后的长度和位置，建立映射关系。 2. 符号决议 + 将每个引用于它输入的可重定位目标文件的符号表中的一个确定的符合定义关联起来。 + 相同模块的局部符号的引用。（每个模块的每个局部符合只有一个定义） + 全局符号：编译器遇到一个不在当前模块中定义的符号，会假设其再其他某个模块中定义，生成一个链接器符号表条目，并将其交给链接器处理。如果链接器在它的任何输入模块都找不到被引用符号的定义，就会输出一条错误信息并终止。 + 多个目标文件出现相同名字的全局符合： 1. 不允许有多个同名的强符号 2. 如果有一个强符合与多个弱符合同名，选择强符合 3. 多个弱符号同名，则从这些弱符合中任意选择一个。 + 一个弱符号定义在多个目标文件 1. 多个强符号类型不同（非法） 2. 一个强符号，多个弱符合，出现类型不一致（同强符号，如果弱符合类型大于强，则发出警告） 3. 多个弱符合类型不一致（选择最大的类型） 3. **重定位**： + 链接器已经确定所有符合的虚拟地址了。链接器就可以根据符号的地址对每个需要重定位的指令进行地址修正。 12345678910111213141516/* a.c */extern int shared;void swap(int *a, int *b);int main() &#123; int a = 100; swap(&amp;a, &amp;shared); return 0;&#125;/* b.c */int shared = 42;void swap(int *a, int *b) &#123; int temp = &amp;a; &amp;a = &amp;b; &amp;b = temp;&#125; b.c中定义了2个全局符号，一个变量shared，一个函数swap. a.c中定义了一个全局符号main，a.c中引用了b.c中的2个符号。 1gcc -c a.c b.c 使用gcc将这两个文件编译为中间文件以后，a的中间文件中，符号shared,swap地址的值都为0. 在这个过程中，每个模块会有一个relocation table保存每个模块的那些符号需要重定位，整体上有一个symbol table保存符号地址。 静态链接过程中，各个中间文件会把relocation table中需要重定位的符号进行重定位。 静态链接的问题：1. 浪费磁盘和内存空间 - 各个可执行程序中依赖的库都需要链接到可执行文件中 2. 程序的更新，部署，发布会有很多麻烦 - 每当更新程序时，都需要重新进行编译和链接 动态链接：不对组成程序的目标文件进行链接，等到程序运行时才进行链接。即链接推迟到运行时进行。 动态链接还分为：non-lazy binding(程序运行前就会被绑定) lazy binding(符号第一次使用时)绑定 基本实现： 动态链接会涉及到运行时的链接以及多个文件的装载，必须有操作系统的支持。 在Linux中，ELF动态链接文件被称为 DSO（动态共享对象 Dynamic Shared Objects） Windows (DLL Dynamic Linking Library) 当程序被装载时，系统的动态链接器会将程序所需要的所有动态链接库装载到进程的地址空间，并将程序中所有未解析的符号绑定到相应的动态链接库，然后进行重定位。 动态链接程序运行时地址空间的分布 对于静态链接的可执行文件来说，整个进程只有一个文件要被映射即可执行文件。对于动态链接，除了可执行文件以外，还有它所依赖的共享目标文件。 共享目标文件的地址分配 静态共享库（地址固定）将程序的各个模块统一交给操作系统进行管理，操作系统在某个特定的地址划分出一些地址块，为哪些已知的模块预留足够的控件。这个地址对不同的应用程序都是固定的。 动态共享库（地址不固定）在链接时，对所有绝对地址的引用都不作重定位，而把这一步推迟到装载时再完成。一旦模块装载地址确定，即目标地址确定，那么系统就对所有绝对地址引用进行重定位。 地址无关代码： 把指令中需要修改的部分都剥离出来，和数据部分放在一起。这样指令部分就可以保持不变，而数据部分在每个进程都有一个副本。 地址引用的处理 模块内部的函数调用 调用函数和调用者在同一模块，相对位置固定，不需要重定位 模块内部的数据访问 统一模块，相对位置固定 模块外部的函数调用 会在数据段中建立一个指向这些变量的指针数组，也称为全局偏移表（Global Offset Table, GOT)，当需要引用该全局变量，可以通过GOT中相对应的间接引用。链接器会在装载模块时查找每个变量所在的地址，然后填充GOT中各项，确保指向地址正确。 模块外部的数据访问 会在数据段中建立一个指向这些变量的指针数组，也称为全局偏移表（Global Offset Table, GOT)，当需要引用该全局变量，可以通过GOT中相对应的间接引用。链接器会在装载模块时查找每个变量所在的地址，然后填充GOT中各项，确保指向地址正确。 其他内容：函数调用与栈： 为什么值传递：函数调用时，参数和返回值都是放到栈帧中的，对参数的操作访问是访问的栈帧中的内容。出栈时相关的修改部分就会丢失。 局部变量的生命周期：因为局部变量时存放到栈帧当中，所以局部变量的生命周期也就只有函数调用过程中。 构造函数和析构函数存在：可执行文件除了代码段以外，构造函数和析构函数一般存放在.init和.finit段。 运行库中包含由入口函数，这是进程执行的入口，它会在main之前执行.init中的代码，main执行完毕后执行.finit ?defer关键词是否存放到.finit 应用：应用场景1： 问题：APMInsight用于监控SDK本身的崩溃。对于动态库，由于可以拿到动态库的地址范围，所有很好判断。但是对于静态库SDK来说，它本身就是代码文件的一个集合，会被加入到App的compile source当中一起被编译，链接。最早的方案是通过对SDK的进行扫描，获得所有的符号集合，通过筛选符号是否在符合集合中判断堆栈里的函数是否是SDK的函数。 前提概念： Xcode的静态库： 由于Xcode编译源代码文件是按照compile source里顺序编译并链接的，并且是静态链接的。当整个SDK被添加到应用里的时候，相对于起始地址存在一个偏移量m，SDK的第一个符号symbol1的地址为addr1,第二个符号的地址为addr2,symbolN的地址为addrN,所有符号直接的地址偏差是固定的，也就是SDK的符号的地址范围为addr1-&gt;addrN，这样就可以在SDK的组件前后分别加上2个.c文件，获取自己的地址，这样就可以拿到SDK所属代码区间，在APM筛选过程中判断函数地址是否在SDK的范围内，即可筛选出是否为SDK的崩溃。","categories":[],"tags":[{"name":"编译原理","slug":"编译原理","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"}]},{"title":"并发编程 - Context","slug":"并发编程-Context","date":"2021-12-19T06:36:52.000Z","updated":"2021-12-19T07:14:22.393Z","comments":true,"path":"2021/12/19/并发编程-Context/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/12/19/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-Context/","excerpt":"","text":"并发编程 - 上下文ContextContext的作用和使用上下文 context.Context Go 语言中用来设置截止日期、同步信号，传递请求相关值的结构体。 该接口有4个需要实现的方法 123456type Context interface &#123; Deadline() (deadline time.Time, ok bool) //返回context.Context被取消的时间 Done() &lt;-chan struct&#123;&#125; //返回一个channel，会在工作完成或context被取消后关闭，重复调用返回同一个Channel Err() error //被取消 - Canceled错误 超时 - DeadlineExceeded Value(key interface&#123;&#125;) interface&#123;&#125; //获取键对应的值&#125; 作用：在 Goroutine 构成的树形结构中对信号进行同步以减少计算资源的浪费是 context.Context 的最大作用。 Go 服务的每一个请求都是通过单独的 Goroutine 处理的，HTTP/RPC 请求的处理器会启动新的 Goroutine 访问数据库和其他服务，如上图所示，对于同一个请求可能会创建多个Goroutine，需要使用Context.context在Goroutine直接同步特定数据，取消信号以及处理请求的截止日期。 当上层的Goroutine因为某些原因执行失败时，使用context.Context就可以在下层及时停掉无用的工作以减少额外资源的消耗 示例： 12345678910111213141516171819202122232425262728293031323334package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;time&quot;)func handle(ctx context.Context, duration time.Duration) &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;handle&quot;,ctx.Err()) case &lt;-time.After(duration): fmt.Println(&quot;process request with&quot;,duration) &#125;&#125;func main() &#123; ctx, cancel := context.WithTimeout(context.Background(),1 * time.Second) defer cancel() go handle(ctx,500*time.Millisecond) select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;main&quot;,ctx.Err()) &#125;&#125;//handle处理时间为500msprocess request with 500msmain context deadline exceeded//handle处理时间为1500mshandle context deadline exceededmain context deadline exceeded 多个Goroutine同时订阅ctx.Done()管道中的消息，一旦收到取消信号就立刻停止当前执行的工作 默认上下文context里最常用的方法是context.Background, context.TODO，这两个方法都会返回预先初始化好的私有变量backgroud和todo，这两个变量都是通过new(emptyCtx)初始化，即全为空实现的context.Context context.Background 是上下文的默认值，所有其他的上下文都应该从它衍生出来； context.TODO 应该仅在不确定应该使用哪种上下文时使用； 在多数情况下，如果当前函数没有上下文作为入参，我们都会使用 context.Background 作为起始的上下文向下传递。 取消信号context.WithCancel 函数能够从 context.Context 中衍生出一个新的子上下文并返回用于取消该上下文的函数。一旦我们执行返回的取消函数，当前上下文以及它的子上下文都会被取消，所有的 Goroutine 都会同步收到这一取消信号。 除了 context.WithCancel 之外，context 包中的另外两个函数 context.WithDeadline 和 context.WithTimeout 也都能创建可以被取消的计时器上下文 context.timerCtx： 传值方法如何使用上下文传值:context 包中的 context.WithValue 能从父上下文中创建一个子上下文，传值的子上下文使用 context.valueCtx 类型 如果 context.valueCtx 中存储的键值对与 context.valueCtx.Value 方法中传入的参数不匹配，就会从父上下文中查找该键对应的值直到某个父上下文中返回 nil 或者查找到对应的值 123456789101112131415func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123; return &amp;valueCtx&#123;parent, key, val&#125;&#125;type valueCtx struct &#123; Context key, val interface&#123;&#125;&#125;func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; if c.key == key &#123; return c.val &#125; return c.Context.Value(key)&#125; 总结Go 语言中的 context.Context 的主要作用还是在多个 Goroutine 组成的树中同步取消信号以减少对资源的消耗和占用，虽然它也有传值的功能，但是这个功能我们还是很少用到。 在真正使用传值的功能时我们也应该非常谨慎，使用 context.Context 传递请求的所有参数一种非常差的设计，比较常见的使用场景是传递请求对应用户的认证令牌以及用于进行分布式追踪的请求 ID。","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"Go并发编程 - 调度器","slug":"Go并发编程-调度器","date":"2021-12-12T16:32:29.000Z","updated":"2021-12-19T07:55:13.485Z","comments":true,"path":"2021/12/13/Go并发编程-调度器/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/12/13/Go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E8%B0%83%E5%BA%A6%E5%99%A8/","excerpt":"","text":"调度器调度器的由来多进程、多线程已经提高了系统的并发能力，但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存。 后来发现，线程可以分为 “内核态 “线程和” 用户态 “线程。一个 “用户态线程” 必须要绑定一个 “内核态线程”，但是 CPU 并不知道有 “用户态线程” 的存在，它只知道它运行的是一个 “内核态线程”。 协程与线程的映射关系N:1 -&gt; 一个进程的所有协程都绑定到一个线程了 1:1 -&gt; 协程的管理由CPU完成，成本过高 M:N: 比较合适 调度器发展单线程调度器只包含G，M 12345678910111213141516171819202122232425static void scheduler(void) &#123; G* gp; lock(&amp;sched);//获取调度器的全局锁 if(gosave(&amp;m-&gt;sched))&#123; //gosave保存栈寄存器和程序计数器 lock(&amp;sched); gp = m-&gt;curg; switch(gp-&gt;status)&#123; case Grunnable: case Grunning: gp-&gt;status = Grunnable; gput(gp); break; ... &#125; notewakeup(&amp;gp-&gt;stopped); &#125; gp = nextgandunlock(); //获取下一个需要运行的Goroutine并解锁调度器 noteclear(&amp;gp-&gt;stopped); gp-&gt;status = Grunning; m-&gt;curg = gp; //修改全局线程上要执行的Goroutine为gp g = gp; gogo(&amp;gp-&gt;sched);//调用gogo运行最新的Goroutine&#125; 多线程调度器123456789101112131415161718192021222324static void schedule(G *gp) &#123; schedlock(); if(gp != nil) &#123; gp-&gt;m = nil; uint32 v = runtime·xadd(&amp;runtime·sched.atomic, -1&lt;&lt;mcpuShift); if(atomic_mcpu(v) &gt; maxgomaxprocs) runtime·throw(&quot;negative mcpu in scheduler&quot;); switch(gp-&gt;status)&#123; case Grunning: gp-&gt;status = Grunnable; gput(gp); break; case ...: &#125; &#125; else &#123; ... &#125; gp = nextgandunlock(); gp-&gt;status = Grunning; m-&gt;curg = gp; gp-&gt;m = m; runtime·gogo(&amp;gp-&gt;sched, 0);&#125; 任务窃取调度器1234567891011121314151617static void schedule(void) &#123; G *gp; top: if(runtime·gcwaiting) &#123;//如果当前运行时在等待垃圾回收，则调用gcstopm gcstopm(); goto top; &#125; //调用runqget和findrunnable从本地或全局的运行队列获取待执行的Goroutine gp = runqget(m-&gt;p);//本地 if(gp == nil) gp = findrunnable();//全局获取，会触发工作窃取，从其他处理器的队列中随机获取Goroutine ... execute(gp);//调用execute在当前线程M上运行Goroutine&#125; 在G-M模型基础上引入了P 1234567891011121314151617struct P &#123; Lock; uint32 status; P* link; uint32 tick; M* m; MCache* mcache; G** runq; int32 runqhead; int32 runqtail; int32 runqsize; G* gfree; int32 gfreecnt;&#125;; 处理器持有一个由可运行的 Goroutine 组成的运行队列 runq，还反向持有一个线程。调度器在调度时会从处理器的队列中选择队列头的 Goroutine 放到线程 M 上执行。 抢占式调度器对于非抢占式的调度器饥饿问题很严重 基于协作的抢占式调度存在无法被抢占的边缘情况 Go 语言会在分段栈的机制上实现抢占调度，利用编译器在分段栈上插入的函数，所有 Goroutine 在函数调用时都有机会进入运行时检查是否需要执行抢占。 原理： 编译器会在调用函数前插入 runtime.morestack； Go 语言运行时会在垃圾回收暂停程序、系统监控发现 Goroutine 运行超过 10ms 时发出抢占请求 StackPreempt； 当发生函数调用时，可能会执行编译器插入的 runtime.morestack 函数，它调用的 runtime.newstack 会检查 Goroutine 的 stackguard0 字段是否为 StackPreempt； 如果 stackguard0 是 StackPreempt，就会触发抢占让出当前线程； 基于信号的抢占式调度 程序启动时，在 runtime.sighandler 函数中注册 SIGURG 信号的处理函数 runtime.doSigPreempt； 在触发垃圾回收的栈扫描时会调用runtime.suspendG挂起 Goroutine，该函数会执行下面的逻辑： 将 _Grunning 状态的 Goroutine 标记成可以被抢占，即将 preemptStop 设置成 true； 调用 runtime.preemptM 触发抢占； runtime.preemptM 会调用 runtime.signalM 向线程发送信号 SIGURG； 操作系统会中断正在运行的线程并执行预先注册的信号处理函数 runtime.doSigPreempt； runtime.doSigPreempt 函数会处理抢占信号，获取当前的 SP 和 PC 寄存器并调用 runtime.sigctxt.pushCall； runtime.sigctxt.pushCall 会修改寄存器并在程序回到用户态时执行 runtime.asyncPreempt； 汇编指令 runtime.asyncPreempt 会调用运行时函数 runtime.asyncPreempt2； runtime.asyncPreempt2 会调用 runtime.preemptPark； runtime.preemptPark 会修改当前 Goroutine 的状态到 _Gpreempted 并调用 runtime.schedule 让当前函数陷入休眠并让出线程，调度器会选择其它的 Goroutine 继续执行； STW 和栈扫描是一个可以抢占的安全点（Safe-points），所以 Go 语言会在这里先加入抢占功能 Go协程goroutineGo 中，协程被称为 goroutine，它非常轻量，一个 goroutine 只占几 KB，并且这几 KB 就足够 goroutine 运行完，这就能在有限的内存空间内支持大量 goroutine，支持了更多的并发。虽然一个 goroutine 的栈只占几 KB，但实际是可伸缩的，如果需要更多内容，runtime 会自动为 goroutine 分配。 Goroutine 特点： 占用内存更小（几 kb） 调度更灵活 (runtime 调度) GMP模型符号含义： G -&gt; goroutine P -&gt; processor M-&gt;thread 全局队列（Global Queue）：存放等待运行的 G。 P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 P和M的个数问题M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。 P: 由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行 M: go 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了，会创建新的 M。 P和M何时被创建1、P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。 2、M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。 调度器的设计策略 复用线程： work stealing 机制:当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 hand off 机制:当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。 利用并行： GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。 抢占： 在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。 全局G队列： 在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。 调度器的调度流程 1、我们通过 go func () 来创建一个 goroutine； 2、有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中； 3、G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行； 4、一个 M 调度 G 执行的过程是一个循环机制； 5、当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P； 6、当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。 调度器的生命周期 M0 M0 是启动程序后的编号为 0 的主线程，这个 M 对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配，M0 负责执行初始化操作和启动第一个 G， 在之后 M0 就和其他的 M 一样了。 G0 G0 是每次启动一个 M 都会第一个创建的 gourtine，G0 仅用于负责调度的 G，G0 不指向任何可执行的函数，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0。 1234567package mainimport &quot;fmt&quot;func main() &#123; fmt.Println(&quot;Hello world&quot;)&#125; 也会经历如上图所示的过程： 1.runtime 创建最初的线程 m0 和 goroutine g0，并把 2 者关联。 2.调度器初始化：初始化 m0、栈、垃圾回收，以及创建和初始化由 GOMAXPROCS 个 P 构成的 P 列表。 3.示例代码中的 main 函数是 main.main，runtime 中也有 1 个 main 函数 ——runtime.main，代码经过编译后，runtime.main 会调用 main.main，程序启动时会为 runtime.main 创建 goroutine，称它为 main goroutine 吧，然后把 main goroutine 加入到 P 的本地队列。 4.启动 m0，m0 已经绑定了 P，会从 P 的本地队列获取 G，获取到 main goroutine。 5.G 拥有栈，M 根据 G 中的栈信息和调度信息设置运行环境 6.M 运行 G 7.G 退出，再次回到 M 获取可运行的 G，这样重复下去，直到 main.main 退出，runtime.main 执行 Defer 和 Panic 处理，或调用 runtime.exit 退出程序。 GMP数据查看的工具 go tool trace Debug trace","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"how to read source code","slug":"how-to-read-source-code","date":"2021-12-10T06:31:00.000Z","updated":"2022-01-27T07:27:09.712Z","comments":true,"path":"2021/12/10/how-to-read-source-code/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/12/10/how-to-read-source-code/","excerpt":"","text":"怎样阅读源码怎样阅读源码focus on code which either does something that I want to replicate the style of in the future, or which deepens my knowledge of code I use daily find a high-level abstraction as a starting point and then gradually dig deeper into the internals make notes in OneNote as I study the code, describing the flow and how the code works This process is less about having a reference, although that can be useful, than it is about embedding the knowledge into my memory. By describing it in writing, I find that it sticks with me much longer Navigating code and forming a mental picture of the logical flow is a handy skill. If you can learn this through reading code, it’ll pay dividends when you’re next trying to fix a critical bug under pressure. Once I have an overview formed the next step is to go deeper. For this, I tend to clone the repository so that I can bring it into an IDE or VS Code. I like to think about how I’d have chosen to approach a problem and contrast it with the actual implementation。Is the author’s approach better or more efficient? Should I file it away for when I next face a similar requirement? Often the code may use APIs that I’ve never discovered when writing code.I study the description and method signature(s) to understand their designed use. This extends my code vocabulary. I find tricks and shortcuts to save time when navigating the code 不了解源码怎么办You want to expose yourself to new APIs or new syntax in the code which you read so that you further your own code vocabulary. Try to break things down into smaller chunks to work through in your head. What is the code doing and also why has it been written that way? Has the author used an approach to solving something you had not previously considered? As you come up against language syntax or keywords you don’t understand, stop and search for the documentation. Armed with an actual use case, often the documentation will make sense in the context you are approaching it from. Similarly, when you encounter framework APIs which you have never used before, visit the code documentation if there is any. 如何打造自己的技术体系，如何学习一个新的技术体系化：目标制定与执行 该技术能够解决什么问题，可以提升哪些能力？ 短期目标和长期目标是什么？ 我需要做哪些事情可以实现目标？ 首先可以通过官方文档，博客等渠道快速了解一门技术的概貌，当决定深入研究这门技术时，首先需要制定自己的学习计划，比如应该知道有哪些重要的概念，特性需要去深入学习，然后制定具体的学习计划表，在学习过程中，当理解更加深入时，会发现更多需要去挖掘的知识点，然后再去调整和完善学习计划。 途径：项目实战，源码学习，写博客，参加社区都是高效的办法。需要定时回顾相关的计划是否有效和阶段性的检验。 思考和总结学习一门技术时，除了使用层面上，还需要知道该技术能够解决什么问题，相比于同领域的其他技术有什么优缺点。可以从技术原理中去了解问题的本质，然后找到问题的解决防范，让结果更有说服力。同时从优秀的开源项目中去挖掘技术原理也是非常有帮助的。 同时多维度的思考，不停留于表明，一个技术问题需要考虑多种因素，需要将方方面面考虑得非常细致。同时对于别人的观点和他人的方案进行学习，总结出自己独特的思考。 分享和交流交流和分享时检验自己的学习成果的有效方法，技术分享，书籍，博客都是沉淀知识的途径。交流与分析可以让我们梳理自己的知识体系，牢固自己的知识，让别人检验自己对知识的理解是否正确。","categories":[],"tags":[]},{"title":"同步原语与锁","slug":"并发编程-同步原语与锁","date":"2021-12-08T17:03:41.000Z","updated":"2021-12-19T18:12:01.812Z","comments":true,"path":"2021/12/09/并发编程-同步原语与锁/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/12/09/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-%E5%90%8C%E6%AD%A5%E5%8E%9F%E8%AF%AD%E4%B8%8E%E9%94%81/","excerpt":"","text":"同步原语与锁 Mutex1234type Mutex struct &#123; state int32 //互斥锁的状态 sema uint32 //控制锁状态的信号量&#125; 状态： 在默认情况下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态： mutexLocked — 表示互斥锁的锁定状态； mutexWoken — 表示从正常模式被从唤醒； mutexStarving — 当前的互斥锁进入饥饿状态； waitersCount — 当前互斥锁上等待的 Goroutine 个数； 正常模式和饥饿模式 正常模式：正常模式下，锁的等待者会按照先进先出的顺序获取锁。但是刚被唤起的 Goroutine 与新创建的 Goroutine 竞争时，大概率会获取不到锁，为了减少这种情况的出现，一旦 Goroutine 超过 1ms 没有获取到锁，它就会将当前互斥锁切换饥饿模式，防止部分 Goroutine 被『饿死』 饥饿模式：饥饿模式中，互斥锁会直接交给等待队列最前面的 Goroutine。新的 Goroutine 在该状态下不能获取锁、也不会进入自旋状态，它们只会在队列的末尾等待。如果一个 Goroutine 获得了互斥锁并且它在队列的末尾或者它等待的时间少于 1ms，那么当前的互斥锁就会切换回正常模式 对比：正常模式下的互斥锁能够提供更好地性能，饥饿模式的能避免 Goroutine 由于陷入等待无法获取锁而造成的高尾延时 加锁与解锁: 前提条件:CAS操作的实现： 通过CPU提供的原子性指令实现了CAS 12345678910func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool)TEXT runtime∕internal∕atomic·Cas64(SB), NOSPLIT, $0-25 MOVQ ptr+0(FP), BX MOVQ old+8(FP), AX MOVQ new+16(FP), CX LOCK //锁住总线保证多次内存操作的原子性 CMPXCHGQ CX, 0(BX) //cmpxchg %cx, %bx；如果AX与BX相等，则CX送BX且ZF置1；否则BX送CX，且ZF清0 SETEQ ret+24(FP) RET 拿AX(old) 与 BX(共享数据ptr) 做对比。 相等，则修改BX(共享数据ptr)，状态码ZX设置为 1 。 不相等，则将CX(new)置为目前BX(共享数据ptr)的值， 状态码ZX设置为 0 加锁：123456func (m *Mutex) Lock() &#123; if atomic.CompareAndSwapInt32(&amp;m.state, 0, mutexLocked) &#123;//当锁的状态是 0 时，将 mutexLocked 位置成 1 return &#125; m.lockSlow()//尝试通过自旋（Spinnig）等方式等待锁的释放&#125; 123456789101112131415161718192021222324252627282930313233343536//1. 判断当前 Goroutine 能否进入自旋；//2. 通过自旋等待互斥锁的释放；//3. 计算互斥锁的最新状态；//4. 更新互斥锁的状态并获取锁；func (m *Mutex) lockSlow() &#123; var waitStartTime int64 starving := false awoke := false iter := 0 old := m.state for &#123; if old&amp;(mutexLocked|mutexStarving) == mutexLocked &amp;&amp; runtime_canSpin(iter) &#123; if !awoke &amp;&amp; old&amp;mutexWoken == 0 &amp;&amp; old&gt;&gt;mutexWaiterShift != 0 &amp;&amp; atomic.CompareAndSwapInt32(&amp;m.state, old, old|mutexWoken) &#123; awoke = true &#125; runtime_doSpin() iter++ old = m.state continue &#125;&#125; //进入自旋会调用doSpin并执行30次PAUSE指令func sync_runtime_doSpin() &#123; procyield(active_spin_cnt)&#125;TEXT runtime·procyield(SB),NOSPLIT,$0-0 MOVL cycles+0(FP), AXagain: PAUSE SUBL $1, AX JNZ again RET 自旋会使得当前进程一直保存CPU的占用，持续检查某个条件是否为真。在多核CPU上，自旋可以避免线程的上下文切换，在自旋时间较短的情况下会有较大收益。 Goroutine 进入自旋的条件非常苛刻： 互斥锁只有在普通模式才能进入自旋； runtime.sync_runtime_canSpin需要返回ture 运行在多 CPU 的机器上； 当前 Goroutine 为了获取该锁进入自旋的次数小于四次； 当前机器上至少存在一个正在运行的处理器 P 并且处理的运行队列为空； 处理了自旋相关的逻辑后，互斥锁会根据上下文计算当前互斥锁状态 1234567891011121314//几个不同的条件分别会更新 state 字段中存储的不同信息 — mutexLocked、mutexStarving、mutexWoken 和 mutexWaiterShiftnew := oldif old&amp;mutexStarving == 0 &#123; new |= mutexLocked&#125;if old&amp;(mutexLocked|mutexStarving) != 0 &#123; new += 1 &lt;&lt; mutexWaiterShift&#125;if starving &amp;&amp; old&amp;mutexLocked != 0 &#123; new |= mutexStarving&#125;if awoke &#123; new &amp;^= mutexWoken&#125; 计算了互斥锁的状态后，会使用CAS更新状态 123456789101112131415161718192021222324if atomic.CompareAndSwapInt32(&amp;m.state, old, new) &#123; if old&amp;(mutexLocked|mutexStarving) == 0 &#123; break // 通过 CAS 函数获取了锁 &#125; ... //如果没有通过 CAS 获得锁，会调用 runtime.sync_runtime_SemacquireMutex 通过信号量保证资源不会被两个 Goroutine 获取。 //runtime.sync_runtime_SemacquireMutex 会在方法中不断尝试获取锁并陷入休眠等待信号量的释放，一旦当前 Goroutine 可以获取信号量，它就会立刻返回，sync.Mutex.Lock 的剩余代码也会继续执行 runtime_SemacquireMutex(&amp;m.sema, queueLifo, 1) starving = starving || runtime_nanotime()-waitStartTime &gt; starvationThresholdNs old = m.state if old&amp;mutexStarving != 0 &#123; delta := int32(mutexLocked - 1&lt;&lt;mutexWaiterShift) if !starving || old&gt;&gt;mutexWaiterShift == 1 &#123; delta -= mutexStarving &#125; atomic.AddInt32(&amp;m.state, delta) break &#125; awoke = true iter = 0 &#125; else &#123; old = m.state &#125; &#125; 首先查看是否通过CAS获得了锁，没有则会通过信号量保证资源不会被多个Goroutine获取 在正常模式下，这段代码会设置唤醒和饥饿标记、重置迭代次数并重新执行获取锁的循环； 在饥饿模式下，当前 Goroutine 会获得互斥锁，如果等待队列中只存在当前 Goroutine，互斥锁还会从饥饿模式中退出； 解锁1234567func (m *Mutex) Unlock() &#123; //首先尝试使用AddInt32快速解锁 new := atomic.AddInt32(&amp;m.state, -mutexLocked) if new != 0 &#123; m.unlockSlow(new) &#125;&#125; 如果该函数返回的新状态等于 0，当前 Goroutine 就成功解锁了互斥锁； 如果该函数返回的新状态不等于 0，这段代码会调用 sync.Mutex.unlockSlow 开始慢速解锁： 123456789101112131415161718192021222324func (m *Mutex) unlockSlow(new int32) &#123; if (new+mutexLocked)&amp;mutexLocked == 0 &#123;//校验锁状态的合法性 — 如果当前互斥锁已经被解锁过了会直接抛出异常 “sync: unlock of unlocked mutex” 中止当前程序 throw(&quot;sync: unlock of unlocked mutex&quot;) &#125; if new&amp;mutexStarving == 0 &#123; // 正常模式 old := new for &#123; if old&gt;&gt;mutexWaiterShift == 0 || old&amp;(mutexLocked|mutexWoken|mutexStarving) != 0 &#123; //互斥锁不存在等待者或者互斥锁的 mutexLocked、mutexStarving、mutexWoken 状态不都为 0，那么当前方法可以直接返回，不需要唤醒其他等待者 return &#125; new = (old - 1&lt;&lt;mutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(&amp;m.state, old, new) &#123; //存在等待者，则会通过runtime_Semrelease唤醒等待者 runtime_Semrelease(&amp;m.sema, false, 1) return &#125; old = m.state &#125; &#125; else &#123; // 饥饿模式 //直接调用runtime_Semrelease将当前锁交给下一个正在尝试获取锁的等待者，等待者被唤醒后会得到锁，在这时互斥锁还不会退出饥饿状态 runtime_Semrelease(&amp;m.sema, true, 1) &#125;&#125; 总结互斥锁的加锁过程比较复杂，它涉及自旋、信号量以及调度等概念： 如果互斥锁处于初始化状态，会通过置位 mutexLocked 加锁； 如果互斥锁处于 mutexLocked 状态并且在普通模式下工作，会进入自旋，执行 30 次 PAUSE 指令消耗 CPU 时间等待锁的释放； 如果当前 Goroutine 等待锁的时间超过了 1ms，互斥锁就会切换到饥饿模式； 互斥锁在正常情况下会通过 runtime.sync_runtime_SemacquireMutex 将尝试获取锁的 Goroutine 切换至休眠状态，等待锁的持有者唤醒； 如果当前 Goroutine 是互斥锁上的最后一个等待的协程或者等待的时间小于 1ms，那么它会将互斥锁切换回正常模式； 互斥锁的解锁过程与之相比就比较简单，其代码行数不多、逻辑清晰，也比较容易理解： 当互斥锁已经被解锁时，调用 sync.Mutex.Unlock 会直接抛出异常； 当互斥锁处于饥饿模式时，将锁的所有权交给队列中的下一个等待者，等待者会负责设置 mutexLocked 标志位； 当互斥锁处于普通模式时，如果没有 Goroutine 等待锁的释放或者已经有被唤醒的 Goroutine 获得了锁，会直接返回；在其他情况下会通过 sync.runtime_Semrelease 唤醒对应的 Goroutine； RWMutex结构体: 1234567type RWMutex struct &#123; w Mutex //Mutex锁 writerSem uint32 //写等待读 readerSem uint32 //读等待写 readerCount int32 //正在执行的读操作 readerWait int32 //写操作被阻塞时等待的读操作的个数&#125; 使用： 写操作使用 sync.RWMutex.Lock 和 sync.RWMutex.Unlock 方法； 读操作使用 sync.RWMutex.RLock 和 sync.RWMutex.RUnlock 方法； 写锁:获取写锁： 12345678func (rw *RWMutex) Lock() &#123; rw.w.Lock() //获取Mutex锁 r := atomic.AddInt32(&amp;rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders //阻塞后续的读操作，readerConnt设置为负数 //仍然有其他 Goroutine 持有互斥锁的读锁，该 Goroutine 会调用 runtime.sync_runtime_SemacquireMutex 进入休眠状态等待所有读锁所有者执行结束后释放 writerSem 信号量将当前协程唤醒 if r != 0 &amp;&amp; atomic.AddInt32(&amp;rw.readerWait, r) != 0 &#123; runtime_SemacquireMutex(&amp;rw.writerSem, false, 0) &#125;&#125; 释放写锁: 12345678910func (rw *RWMutex) Unlock() &#123; r := atomic.AddInt32(&amp;rw.readerCount, rwmutexMaxReaders) //将readerCount变成正数释放读锁 if r &gt;= rwmutexMaxReaders &#123; throw(&quot;sync: Unlock of unlocked RWMutex&quot;) &#125; for i := 0; i &lt; int(r); i++ &#123;//for 循环释放所有因为获取读锁而陷入等待的 Goroutine runtime_Semrelease(&amp;rw.readerSem, false, 0) &#125; rw.w.Unlock()//释放Mutex&#125; 获取写锁时会先阻塞写锁的获取，后阻塞读锁的获取，这种策略能够保证读操作不会被连续的写操作『饿死』 读锁:读锁加锁： 1234567func (rw *RWMutex) RLock() &#123; if atomic.AddInt32(&amp;rw.readerCount, 1) &lt; 0 &#123; //如果该方法返回负数 — 其他 Goroutine 获得了写锁，当前 Goroutine 就会调用 runtime.sync_runtime_SemacquireMutex 陷入休眠等待锁的释放； runtime_SemacquireMutex(&amp;rw.readerSem, false, 0) &#125; //非负数则成功返回&#125; 读锁释放： 12345678func (rw *RWMutex) RUnlock() &#123; //减少readerCount数 //返回值&gt;=0读锁解锁成功 //返回值&lt;0有正在执行的写操作，执行rw.rUnlockSlow(r) if r := atomic.AddInt32(&amp;rw.readerCount, -1); r &lt; 0 &#123; rw.rUnlockSlow(r) &#125;&#125; 123456789func (rw *RWMutex) rUnlockSlow(r int32) &#123; //减少获取锁的写操作等待的读操作数 readerWait 并在所有读操作都被释放之后触发写操作的信号量 writerSem，该信号量被触发时，调度器就会唤醒尝试获取写锁的 Goroutine if r+1 == 0 || r+1 == -rwmutexMaxReaders &#123; throw(&quot;sync: RUnlock of unlocked RWMutex&quot;) &#125; if atomic.AddInt32(&amp;rw.readerWait, -1) == 0 &#123; runtime_Semrelease(&amp;rw.writerSem, false, 1) &#125;&#125; 总结读锁和写锁的关系： 调用sync.RWMutex.Lock尝试获取写锁时； 每次 sync.RWMutex.RUnlock 都会将 readerCount 其减一，当它归零时该 Goroutine 会获得写锁； 将 readerCount 减少 rwmutexMaxReaders 个数以阻塞后续的读操作； 调用 sync.RWMutex.Unlock 释放写锁时，会先通知所有的读操作，然后才会释放持有的互斥锁； 读写互斥锁在互斥锁之上提供了额外的更细粒度的控制，能够在读操作远远多于写操作时提升性能。 WaitGroupsync.WaitGroup 可以等待一组 Goroutine 的返回，一个比较常见的使用场景是批量发出 RPC 或者 HTTP 请求 1234567891011requests := []*Request&#123;...&#125;wg := &amp;sync.WaitGroup&#123;&#125;wg.Add(len(requests))for _, request := range requests &#123; go func(r *Request) &#123; defer wg.Done() // res, err := service.call(r) &#125;(request)&#125;wg.Wait() 结构体： 1234type WaitGroup struct &#123; noCopy noCopy //在编译期间检查，保证 sync.WaitGroup 不会被开发者通过再赋值的方式拷贝 state1 [3]uint32 //存储着状态和信号量 私有方法 sync.WaitGroup.state 能够帮我们从 state1 字段中取出它的状态和信号量&#125; 接口： Add +1 Wait 等待group事件完成 Done -1 12345678910111213141516func (wg *WaitGroup) Add(delta int) &#123; statep, semap := wg.state() state := atomic.AddUint64(statep, uint64(delta)&lt;&lt;32) v := int32(state &gt;&gt; 32) w := uint32(state) if v &lt; 0 &#123; panic(&quot;sync: negative WaitGroup counter&quot;) &#125; if v &gt; 0 || w == 0 &#123; return &#125; *statep = 0 for ; w != 0; w-- &#123; runtime_Semrelease(semap, false, 0) //唤醒等待状态的Goroutine &#125;&#125; 12345678910111213141516171819//会在计数器大于 0 并且不存在等待的 Goroutine 时，调用 runtime.sync_runtime_Semacquire 陷入睡眠//当 sync.WaitGroup 的计数器归零时，陷入睡眠状态的 Goroutine 会被唤醒，上述方法也会立刻返回func (wg *WaitGroup) Wait() &#123; statep, semap := wg.state() for &#123; state := atomic.LoadUint64(statep) v := int32(state &gt;&gt; 32) if v == 0 &#123; return &#125; if atomic.CompareAndSwapUint64(statep, state, state+1) &#123; runtime_Semacquire(semap) if +statep != 0 &#123; panic(&quot;sync: WaitGroup is reused before previous Wait has returned&quot;) &#125; return &#125; &#125;&#125; 总结： sync.WaitGroup 必须在 sync.WaitGroup.Wait 方法返回之后才能被重新使用； sync.WaitGroup.Done 只是对 sync.WaitGroup.Add 方法的简单封装，我们可以向 sync.WaitGroup.Add 方法传入任意负数（需要保证计数器非负）快速将计数器归零以唤醒等待的 Goroutine； 可以同时有多个 Goroutine 等待当前 sync.WaitGroup 计数器的归零，这些 Goroutine 会被同时唤醒； Once sync.Once 可以保证在 Go 程序运行期间的某段代码只会执行一次。通常可以用于实现单例： 在运行如下所示的代码时，我们会看到如下所示的运行结果: 1234567891011func main() &#123; o := &amp;sync.Once&#123;&#125; for i := 0; i &lt; 10; i++ &#123; o.Do(func() &#123; fmt.Println(&quot;only once&quot;) &#125;) &#125;&#125;$ go run main.goonly once 结构体： 1234type Once struct &#123; done uint32 //标识代码块是否执行过,保证函数不会被执行第二次 m Mutex&#125; 接口： 123456789101112131415func (o *Once) Do(f func()) &#123; if atomic.LoadUint32(&amp;o.done) == 0 &#123; //传入的参数已经执行过了，会直接返回，没有则会调用doSlow执行传入的函数 o.doSlow(f) &#125;&#125;func (o *Once) doSlow(f func()) &#123; o.m.Lock() //获取互斥锁 defer o.m.Unlock() if o.done == 0 &#123; defer atomic.StoreUint32(&amp;o.done, 1) //将成员变量更新为1 f() //执行传入的无入参函数 &#125;&#125; 总结：作为用于保证函数执行次数的 sync.Once 结构体，它使用互斥锁和 sync/atomic 包提供的方法实现了某个函数在程序运行期间只能执行一次的语义。在使用该结构体时，我们也需要注意以下的问题： sync.Once.Do 方法中传入的函数只会被执行一次，哪怕函数中发生了 panic； 两次调用 sync.Once.Do 方法传入不同的函数只会执行第一次调传入的函数； Cond条件变量 sync.Cond，它可以让一组的 Goroutine 都在满足特定条件时被唤醒。每一个 sync.Cond 结构体在初始化时都需要传入一个互斥锁 使用123456789101112131415161718192021222324252627282930313233343536373839var status int64func main() &#123; c := sync.NewCond(&amp;sync.Mutex&#123;&#125;) for i := 0; i &lt; 10; i++ &#123; go listen(c) &#125; time.Sleep(1 * time.Second) go broadcast(c) ch := make(chan os.Signal, 1) signal.Notify(ch, os.Interrupt) &lt;-ch&#125;func broadcast(c *sync.Cond) &#123; c.L.Lock() atomic.StoreInt64(&amp;status, 1) c.Broadcast() c.L.Unlock()&#125;func listen(c *sync.Cond) &#123; c.L.Lock() for atomic.LoadInt64(&amp;status) != 1 &#123; c.Wait() &#125; fmt.Println(&quot;listen&quot;) c.L.Unlock()&#125;$ go run main.golisten...listen//同时运行了 11 个 Goroutine，这 11 个 Goroutine 分别做了不同事情//10 个 Goroutine 通过 sync.Cond.Wait 等待特定条件的满足；//1 个 Goroutine 会调用 sync.Cond.Broadcast 唤醒所有陷入等待的 Goroutine； 结构体:123456789101112131415type Cond struct &#123; noCopy noCopy //保证结构体不会在编译期间拷贝 L Locker //用于保护内部的 notify 字段，Locker接口类型的变量； notify notifyList //一个 Goroutine 的链表，它是实现同步机制的核心结构 checker copyChecker //用于禁止运行期间发生的拷贝&#125;type notifyList struct &#123; wait uint32 //正在等待的Goroutine索引 notify uint32 //已经通知到的Goroutine索引 lock mutex head *sudog //链表头 tail *sudog //链表尾&#125; 接口： sync.Cond.Wait 将当前 Goroutine 陷入休眠状态 1234567891011121314151617181920212223242526func (c *Cond) Wait() &#123; c.checker.check() t := runtime_notifyListAdd(&amp;c.notify) // 将等待加数器加一并解锁 c.L.Unlock() runtime_notifyListWait(&amp;c.notify, t) // 等待其他Goroutine的唤醒并加锁 c.L.Lock()&#125;func notifyListAdd(l *notifyList) uint32 &#123; return atomic.Xadd(&amp;l.wait, 1) - 1&#125;//获取当前 Goroutine 并将它追加到 Goroutine 通知链表的最末端func notifyListWait(l *notifyList, t uint32) &#123; s := acquireSudog() s.g = getg() s.ticket = t if l.tail == nil &#123; l.head = s &#125; else &#123; l.tail.next = s &#125; l.tail = s goparkunlock(&amp;l.lock, waitReasonSyncCondWait, traceEvGoBlockCond, 3)//将当前的Goroutine陷入休眠 releaseSudog(s)&#125; sync.Cond.Signal唤醒队列最前面的Goroutine 123456789101112131415161718192021222324252627func (c *Cond) Signal() &#123; c.checker.check() runtime_notifyListNotifyOne(&amp;c.notify)&#125;//从notifyList链表中找到满足条件的Goroutine并唤醒func notifyListNotifyOne(l *notifyList) &#123; t := l.notify atomic.Store(&amp;l.notify, t+1) for p, s := (*sudog)(nil), l.head; s != nil; p, s = s, s.next &#123; if s.ticket == t &#123; n := s.next if p != nil &#123; p.next = n &#125; else &#123; l.head = n &#125; if n == nil &#123; l.tail = p &#125; s.next = nil readyWithTime(s, 4) //唤醒 return &#125; &#125;&#125; sync.Cond.Broadcast唤醒队列中全部的Goroutine 123456789101112131415161718192021func (c *Cond) Broadcast() &#123; c.checker.check() runtime_notifyListNotifyAll(&amp;c.notify)&#125;//依次通过readWithTime唤醒链表中的Goroutine//Goroutine 的唤醒顺序也是按照加入队列的先后顺序，先加入的会先被唤醒，而后加入的可能 Goroutine 需要等待调度器的调度。func notifyListNotifyAll(l *notifyList) &#123; s := l.head l.head = nil l.tail = nil atomic.Store(&amp;l.notify, atomic.Load(&amp;l.wait)) for s != nil &#123; next := s.next s.next = nil readyWithTime(s, 4) s = next &#125;&#125; 总结：在一般情况下，我们都会先调用 sync.Cond.Wait 陷入休眠等待满足期望条件，当满足唤醒条件时，就可以选择使用 sync.Cond.Signal 或者 sync.Cond.Broadcast 唤醒一个或者全部的 Goroutine。 sync.Cond 不是一个常用的同步机制，但是在条件长时间无法满足时，与使用 for &#123;&#125; 进行忙碌等待相比，sync.Cond 能够让出处理器的使用权，提高 CPU 的利用率。使用时我们也需要注意以下问题： sync.Cond.Wait 在调用之前一定要使用获取互斥锁，否则会触发程序崩溃； sync.Cond.Signal 唤醒的 Goroutine 都是队列最前面、等待最久的 Goroutine； sync.Cond.Broadcast 会按照一定顺序广播通知等待的全部 Goroutine；","categories":[],"tags":[]},{"title":"垃圾收集器","slug":"垃圾收集器","date":"2021-12-05T13:32:34.000Z","updated":"2021-12-20T12:53:10.432Z","comments":true,"path":"2021/12/05/垃圾收集器/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/12/05/%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/","excerpt":"","text":"垃圾收集器 对于一门语言来说，除了需要负责堆内存的分配以外，还需要负责回收不再使用的对象和内存空间。 垃圾收集器的原理通常来说管理内存的方式有两种，手动的方式和自动的方式，C,C++等是手动的方式管理的，Java，C#，Objective-C，Go是通过自动管理的，其中Objective-C是通过引用计数，半自动的方式管理的。 在GO语言中，用户程序是通过内存分配器在堆上申请内存，通过垃圾收集器来负责回收堆上的内存。 垃圾回收的基本算法： GO的垃圾回收器是使用的三色标记清除算法，无分代，不整理，并发。 分代GC依赖分代假设，即GC将主要的回收目标放在新创建的对象（新生代）上，而非频繁的检查所有的对象。但是对于Go来说，Go的编译器会通过逃逸分析将大部分的新生对象存储到栈上，只有需要长期存在的对象才会被分配到需要进行垃圾回收的堆中。 基本思想串行标记清扫：回收器开始执行的时候，会将并发的赋值器挂起（即Stop The World）。 挂起赋值器，stop the world 从根集合（寄存器，执行栈，全局变量）开始遍历对象图，标记根对象可达的每一个对象 清扫回收时，会检查堆中的每一个对象，将所有未标记的对象当做垃圾进行回收 1234567891011121314151617181920212223242526272829303132// 标记追踪：从根集合（寄存器、执行栈、全局变量）开始遍历对象图，标记遇到的每个对象；func mark() &#123; worklist.Init() // 初始化标记 work 列表 for root := range roots &#123; // 从根开始扫描 ref := *root if ref != nil &amp;&amp; !isMarked(ref) &#123; // 标记每个遇到的对象 setMarked(ref) worklist.Add(ref) for !worklist.Empty() &#123; ref := worklist.Remove() // ref 已经标记过 for fld := range Pointers(ref) &#123; child := *fld if child != nil &amp;&amp; !isMarked(child) &#123; setMarked(child) worlist.Add(child) &#125; &#125; &#125; &#125; &#125;&#125;// 清扫回收：检查堆中每一个对象，将所有未标记的对象当做垃圾进行回收。func sweep() &#123; // 检查堆区间内所有的对象 for scan := worklist.Start(); scan &lt; worklist.End(); scan = scan.Next &#123; if isMarked(scan) &#123; unsetMarked(scan) &#125; else &#123; free(scan) // 将未标记的对象释放 &#125; &#125;&#125; 三色标记法当垃圾回收开始时，只有白色对象。随着标记过程开始进行时，灰色对象开始出现（着色），这时候波面便开始扩大。当一个对象的所有子节点均完成扫描时，会被着色为黑色。当整个堆遍历完成时，只剩下黑色和白色对象，这时的黑色对象为可达对象，即存活；而白色对象为不可达对象，即死亡。这个过程可以视为以灰色对象为波面，将黑色对象和白色对象分离，使波面不断向前推进，直到所有可达的灰色对象都变为黑色对象为止的过程。 并发标记清扫123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//并发标记func markSome() bool &#123; if worklist.empty() &#123; // 初始化回收过程 scan(Roots) // 赋值器不持有任何白色对象的引用 if worklist.empty() &#123; // 此时灰色对象已经全部处理完毕 sweep() // 标记结束，立即清扫 return false &#125; &#125; // 回收过程尚未完成，后续过程仍需标记 ref = worklist.remove() scan(ref) return true&#125;func scan(ref interface&#123;&#125;) &#123; for fld := range Pointers(ref) &#123; child := *fld if child != nil &#123; shade(child) &#125; &#125;&#125;func shade(ref interface&#123;&#125;) &#123; if !isMarked(ref) &#123; setMarked(ref) worklist.add(ref) &#125;&#125;在这个过程中，回收器会首先扫描 worklist，而后对根集合进行扫描并重新建立 worklist。 在根集合扫描过程中赋值器现场被挂起时，扫描完成后则不会再存在白色对象。//并发清扫// 并发清扫func New() (interface&#123;&#125;, error) &#123; collectEnough() ref := allocate() if ref == nil &#123; return nil, errors.New(&quot;Out of memory&quot;) &#125; return ref, nil&#125;func collectEnough() &#123; stopTheWorld() defer startTheWorld() for behind() &#123; // behind() 控制回收工作每次的执行量 if !markSome() &#123; return &#125; &#125;&#125;在没有mutator并发修改三色抽象的情况下，回收可以正常结束。但并发回收的根本问题在于， mutator在回收过程中会并发的更新对象图，从而mutator和回收器可能对对象图的结构产生不同的认知， 这时以一个固定的三色波面作为回收过程前进的边界则不再合理。 垃圾回收器的正确性体现在：不应出现对象的丢失，也不应错误的回收还不需要回收的对象。可以证明，当以下两个条件同时满足时会破坏垃圾回收器的正确性 mutator修改对象图，导致某一黑色对象引用白色对象； 从灰色对象出发，到达白色对象的、未经访问过的路径被mutator破坏。 只要能够避免其中任何一个条件，则不会出现对象丢失的情况。两个条件都避免，称为强三色不变性，只避免条件1，称为弱三色不变性。 mutator屏障技术mutator屏障技术即内存屏障，保证代码对内存的操作顺序。不会被CPU乱序执行也不会被编译器优化 三色标记法是一种可以并发执行的算法。Collector可以做了一段标记工作后，就让mutator再运行一段。如果在mutator运行期间，一个黑色对象被修改了，比如往一个黑色对象 a 里新存储了一个指针 b，那么把 a 涂成灰色，或者把 b 涂成灰色，就可以了。增量标记的过程中，需要编译器做配合往生成的目标代码中插入读屏障（Read Barrier）和写屏障（Write Barrier）的代码。也就是在程序读写对象的时候，要执行一些逻辑，保证三色的正确性。比如Write Barrier 主要做这样一件事情，修改原先的写逻辑，当白色节点交由黑色节点引用时， 立刻对被引用节点进行着色，并且着色为”灰色“，并加入到work pool。因此打开了 Write Barrier 可以保证了三色标记法在并发下安全正确地运行。 整体实现 什么时候触发下一次GC？ 目前触发 GC 的条件使用的是从 Go 1.5 时提出的调步（Pacing）算法，调步算法包含四个部分： GC 周期所需的扫描估计器 为用户代码根据堆分配到目标堆大小的时间估计扫描工作量的机制 用户代码为未充分利用 CPU 预算时进行后台扫描的调度程序 GC 触发比率的控制器 回收器阶段 说明 mutator状态 清扫终止 为下一个阶段的并发标记做准备工作，启动写屏障 STW 标记 与mutator并发执行，写屏障处于开启状态 并发 标记终止 保证一个周期内标记任务完成，停止写屏障 STW 内存清扫 将需要回收的内存归还到堆中，写屏障处于关闭状态 并发 内存归还 将过多的内存归还给操作系统，写屏障处于关闭状态 并发 GC如何标记内存 GC 从栈开始，递归地顺着指针找指针指向的对象，遍历内存。每个指针被加入到一个 work pool(type gcWork/workbuf struct) 中的队列。后台运行的标记 worker 从这个 work pool 中拿到前面出列的 指针，扫描这个对象然后把在这个对象里找到的指针加入到队列。归功于每一个 span 中的名为 gcmarkBits 的 bitmap 属性，三色被原生地实现了，bitmap 对 scan 中相应的 bit 设为 1 来追踪 对象。灰色和黑色在 gcmarkBits 中皆为 1 触发GC的入口 可以调用 runtime.GC来手动的触发 GC。但实际上，触发 GC 的入口一般不会手动调用。正常触发 GC 应该是在申请内存时会调用 runtime.mallocgc或者是 Go 后台的监控线程 sysmon 定时检查调用 runtime.forcegchelper","categories":[],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"}]},{"title":"内存管理 - go栈内存管理","slug":"内存管理-栈内存管理","date":"2021-12-04T09:56:30.000Z","updated":"2021-12-08T08:50:41.750Z","comments":true,"path":"2021/12/04/内存管理-栈内存管理/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/12/04/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86-%E6%A0%88%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","excerpt":"","text":"栈空间管理 堆与栈的区别 功能不同：函数调用的参数、返回值以及局部变量都会分配到栈上。 共享性不同：栈是线程私有，堆是共享 栈的空间一般远远小于堆 设计原理应用程序的内存一般会分成堆区和栈区，程序在运行期间可以主动从堆区申请内存空间，这些内存由内存分配器分配并由垃圾收集器负责回收。 栈区的内存由编译器自动分配和释放，其中存储的是函数的入参和局部变量。 总结：Go的栈使用连续栈进行管理，对象或结构体是分配到栈还是堆，由逃逸分析决定，栈是线程私有，Go的栈是以Goroutine作为context，为了高效管理栈，使用了2个寄存器BP,SP来表明其基址和栈顶。 寄存器栈寄存器是 CPU 寄存器中的一种，它的主要作用是跟踪函数的调用栈，Go 语言的汇编代码包含 BP 和 SP 两个栈寄存器，它们分别存储了栈的基址指针和栈顶的地址。BP 和 SP 之间的内存就是当前函数的调用栈。 栈区内存都是从高地址向低地址扩展的，当应用程序申请或者释放栈内存时只需要修改 SP 寄存器的值，这种线性的内存分配方式与堆内存相比更加快速，仅会带来极少的额外开销。 线程栈创建一个线程时，系统会根据架构不同选择不同的默认栈大小，一般为2~4MB左右，用户程序可以在栈上存储函数参数和局部变量。 对于Go:由于Go设计时以协程实现，所以其再用户态实现Goroutine作为执行上下文。 逃逸分析在手动管理内存的语言中，可以选择将对象或结构体分配到栈或者堆上，但是这样会存在2个问题： 不需要分配到堆上的对象分配到了堆上 — 浪费内存空间； 需要分配到堆上的对象分配到了栈上 — 悬挂指针、影响内存安全； Eg: 123456int *dangling_pointer() &#123; int i = 2; return &amp;i;&#125;//当 dangling_pointer 函数返回后，它的本地变量会被编译器回收，调用方获取的是危险的悬挂指针 Go 语言的逃逸分析遵循以下两个不变性： 指向栈对象的指针不能存在于堆中； 指向栈对象的指针不能在栈对象回收后存活； Go 语言的编译器使用逃逸分析决定哪些变量应该在栈上分配，哪些变量应该在堆上分配，其中包括使用 new、make 和字面量等方法隐式分配的内存。为了保证内存的绝对安全，编译器可能会将一些变量错误地分配到堆上，但是因为堆也会被垃圾收集器扫描，所以不会造成内存泄露以及悬挂指针等安全问题。 逃逸分析的实现： 逃逸分析是静态分析的一种，在编译器活动抽象语法树以后，可以通过抽象语法树分析静态的数据流。 构建带权重的有向图，其中顶点表示被分配的变量，边表示变量之间的分配关系，权重表示寻址和取地址的次数； 遍历对象分配图并查找违反两条不变性的变量分配关系，如果堆上的变量指向了栈上的变量，那么该变量需要分配在堆上； 记录从函数的调用参数到堆以及返回值的数据流，增强函数参数的逃逸分析； 栈内存空间Go 语言使用用户态线程 Goroutine 作为执行上下文，它的额外开销和默认栈大小都比线程小很多 在1.3版本以后，都是有连续栈，最小栈空间在1.4版本，为2KB 连续栈： 核心原理是每当程序的栈空间不足时，初始化一片更大的栈空间并将原栈中的所有值都迁移到新栈中，新的局部变量或者函数调用就有充足的内存空间。 步骤： 在内存空间中分配更大的栈内存空间； 将旧栈中的所有内容复制到新栈中； 将指向旧栈对应变量的指针重新指向新栈； 销毁并回收旧栈的内存空间； 因为需要拷贝变量和调整指针，连续栈增加了栈扩容时的额外开销，但是通过合理栈缩容机制就能避免热分裂带来的性能问题，即在GC时期合理调整栈的大小。 GC 期间如果 Goroutine 使用了栈内存的四分之一，那就将其内存减少一半，这样在栈内存几乎充满时也只会扩容一次，不会因为函数调用频繁扩缩容。 栈操作栈初始化运行时使用全局的 runtime.stackpool 和线程缓存中的空闲链表分配 32KB 以下的栈内存，使用全局的 runtime.stackLarge 和堆内存分配 32KB 以上的栈内存，提高本地分配栈内存的性能。 栈空间在运行时中包含两个重要的全局变量，分别是 runtime.stackpool 和 runtime.stackLarge，这两个变量分别表示全局的栈缓存和大栈缓存，前者可以分配小于 32KB 的内存，后者用来分配大于 32KB 的栈空间： 每一个线程缓存 runtime.mcache 中也都加入了栈缓存减少锁竞争影响。 1234567891011121314var stackpool [_NumStackOrders]struct &#123; item stackpoolItem _ [cpu.CacheLinePadSize - unsafe.Sizeof(stackpoolItem&#123;&#125;)%cpu.CacheLinePadSize]byte&#125;type stackpoolItem struct &#123; mu mutex span mSpanList&#125;var stackLarge struct &#123; lock mutex free [heapAddrBits - pageShift]mSpanList&#125; Go语言的栈内存都是分配到堆上的，运行时初始化会调用runtime.stackinit 初始化这些全局变量。 栈分配运行时会在 Goroutine 的初始化函数 runtime.malg 中调用 runtime.stackalloc 分配一个大小足够栈内存空间，根据线程缓存和申请栈的大小，该函数会通过三种不同的方法分配栈空间： 如果栈空间较小，使用全局栈缓存或者线程缓存上固定大小的空闲链表分配内存； 如果栈空间较大，从全局的大栈缓存 runtime.stackLarge 中获取内存空间； 如果栈空间较大并且 runtime.stackLarge 空间不足，在堆上申请一片大小足够内存空间； 栈扩容编译器会在函数调用中插入运行时检查，检查函数调用当前Goroutine的栈空间是否充足，当需要扩容时，会保存一些栈的信息并调用runtime.newstack创建新栈进行扩容 runtime.newstack 会先做一些准备工作并检查当前 Goroutine 是否发出了抢占请求。如果当前 Goroutine 不需要被抢占，意味着我们需要新的栈空间来支持函数调用和本地变量的初始化，运行时会先检查目标大小的栈是否会溢出。 如果目标栈的大小没有超出程序的限制，我们会将 Goroutine 切换至 _Gcopystack 状态并调用 runtime.copystack 开始栈拷贝。在拷贝栈内存之前，运行时会通过 runtime.stackalloc 分配新的栈空间： 分配好以后开始拷贝栈空间 同上的连续栈扩容 栈缩容GC时，使用率为1/4时，缩容为之前的一半，也会coptyStack 栈内容扩展栈的汇编分析12345678910111213141516#include &lt;stdio.h&gt;int foo(int a, int b)&#123; char x =1; int c = 0; c = a + b + x; return c;&#125;int main()&#123; int ret = 0; ret = foo(2, 3); return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960foo:.LFB0: .file 1 &quot;call_no_stack.c&quot; .loc 1 4 0 .cfi_startproc pushq %rbp //rbp入栈 （rsp-8） .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp //rsp 赋值给 rbp，这里rsp并没有移动，可能是因为这里是最后一个函数调用，所以不需要移动rsp .cfi_def_cfa_register 6 movl %edi, -20(%rbp) //这里通过rbp来访问栈，将main函数中的实参2放入rbp-20内存 movl %esi, -24(%rbp) //这里表示栈空间分配了24字节，猜测：函数中的参数值从栈顶开始存储 .loc 1 5 0 movb $1, -5(%rbp) //局部变量x入栈，x占用1个字节，相当于x后入栈：栈的地址是向下减少的 .loc 1 6 0 movl $0, -4(%rbp) //局部变量c入栈，放在rbp-4处 .loc 1 7 0 movl -20(%rbp), %edx movl -24(%rbp), %eax addl %eax, %edx //相加操作 movsbl -5(%rbp), %eax addl %edx, %eax movl %eax, -4(%rbp) .loc 1 8 0 movl -4(%rbp), %eax //将c变量的结果保存到eax寄存器，以便函数返回 .loc 1 9 0 popq %rbp //将堆栈pop，此时栈顶保存着调用函数的rbp值，将栈顶元素赋予rbp寄存器（恢复rbp寄存器） .cfi_def_cfa 7, 8 ret //跳转回上一层处继续执行 .cfi_endproc.LFE0: .size foo, .-foo .globl main .type main, @functionmain:.LFB1: .loc 1 12 0 .cfi_startproc pushq %rbp //rbp：64位寄存器——指向栈底，将rbp寄存器内的值入栈-pushq操作会改变rsp的值 .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp //rsp：64位堆栈指针寄存器——指向栈顶，将rsp值存入rbp寄存器内 .cfi_def_cfa_register 6 subq $16, %rsp //rsp-16，这里讲栈顶指针向下移动16字节，相当于为main函数预留了16字节的栈空间-保存局部变量包括实参 .loc 1 13 0 movl $0, -4(%rbp) //对应局部变量ret = 0 .loc 1 14 0 movl $3, %esi //这里直接将实参存入esi寄存器而不是放入堆栈，可加快访问速度 movl $2, %edi call foo //调用foo函数:call指令有另个作用：1，将call指令的下一条指令入栈-并改变rsp 2，修改程序计数器eip，跳转到foo函数的开头执行 movl %eax, -4(%rbp) //eax寄存器保存着返回值，这里将eax赋值给rbp-4的位置，也就是ret .loc 1 15 0 movl $0, %eax .loc 1 16 0 leave //leave指令是函数开头的pushq %rbp和movq %rsp,%rbp的逆操作, //有两个作用：1，把rbp赋值给rsp 2,然后把该函数栈栈顶保存的rbp值恢复到rbp寄存器中,同时rsp+4(第二部的操作相当于pop栈顶元素) .cfi_def_cfa 7, 8 ret //现在栈顶元素保存的是下一条执行的指令，ret的作用就是pop栈顶元素，并将栈顶元素赋值给程序计数器bip，然后程序跳转回bip所在地址继续执行 .cfi_endproc.LFE1: .size main, .-main 变量存储会按照会根据类型，在汇编的得出其偏移量来操作 只有两个寄存器bp,sp来管理当前栈帧，之前已经入栈的栈帧的相关信息，会存储到其上下文中 栈空间对齐栈的字节对齐，实际是指栈顶指针必须是16字节的整数倍，栈对齐是为了尽可能少的内存访问周期读取数据，保证性能 - 任何内存分配函数(alloca, malloc, calloc)生成的块的起始地址必须为16的整数倍。大多数函数的栈帧的边界必须为16的整数倍。 相关文章C语言函数栈帧实例：https://gitbook.coder.cat/function-call-principle/content/c-stack-frame-example.html","categories":[],"tags":[{"name":"内存管理","slug":"内存管理","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"}]},{"title":"Go多线程编程2","slug":"Go多线程编程2","date":"2021-11-28T08:09:04.000Z","updated":"2021-11-28T10:11:35.613Z","comments":true,"path":"2021/11/28/Go多线程编程2/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/28/Go%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B2/","excerpt":"","text":"Go多线程编程定时器 Timer：时间到了，执行只执行1次 12345678910111213141516171819201. 使用timer1 := time.NewTimer(2 * time.Second)t2 := &lt;-timer1.C2. 延时(1) time.Sleep(time.Second)(2) timer3 := time.NewTimer(2 * time.Second) &lt;-timer3.C(3)&lt;-time.After(2*time.Second)3. 停止timer4 := time.NewTimer(2 * time.Second)timer4.Stop()4. 重置定时器timer5 := time.NewTimer(3 * time.Second)timer5.Reset(1 * time.Second) 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 1.timer基本使用 //timer1 := time.NewTimer(2 * time.Second) //t1 := time.Now() //fmt.Printf(&quot;t1:%v\\n&quot;, t1) //t2 := &lt;-timer1.C //fmt.Printf(&quot;t2:%v\\n&quot;, t2) // 2.验证timer只能响应1次 //timer2 := time.NewTimer(time.Second) //for &#123; // &lt;-timer2.C // fmt.Println(&quot;时间到&quot;) //&#125; // 3.timer实现延时的功能 //(1) //time.Sleep(time.Second) //(2) //timer3 := time.NewTimer(2 * time.Second) //&lt;-timer3.C //fmt.Println(&quot;2秒到&quot;) //(3) //&lt;-time.After(2*time.Second) //fmt.Println(&quot;2秒到&quot;) // 4.停止定时器 //timer4 := time.NewTimer(2 * time.Second) //go func() &#123; // &lt;-timer4.C // fmt.Println(&quot;定时器执行了&quot;) //&#125;() //b := timer4.Stop() //if b &#123; // fmt.Println(&quot;timer4已经关闭&quot;) //&#125; // 5.重置定时器 timer5 := time.NewTimer(3 * time.Second) timer5.Reset(1 * time.Second) fmt.Println(time.Now()) fmt.Println(&lt;-timer5.C) for &#123; &#125; Ticker：时间到了，多次执行 1234567891011121314151617181920212223242526package mainimport ( &quot;fmt&quot; &quot;time&quot;)func main() &#123; // 1.获取ticker对象 ticker := time.NewTicker(1 * time.Second) i := 0 // 子协程 go func() &#123; for &#123; //&lt;-ticker.C i++ fmt.Println(&lt;-ticker.C) if i == 5 &#123; //停止 ticker.Stop() &#125; &#125; &#125;() for &#123; &#125;&#125; Select用法类似与Socket里的select 作用：select关键字，可以同时响应多个通道的操作。 select可以同时监听一个或多个channel，直到其中一个channel ready 如果多个channel同时ready，则随机选择一个执行 可以用于判断管道是否存满 123456789select &#123; case &lt;-chan1: // 如果chan1成功读到数据，则进行该case处理语句 case chan2 &lt;- 1: // 如果成功向chan2写入数据，则进行该case处理语句 default: // 如果上面都没有成功，则进入default处理流程 &#125; 判断管道是否存满 1234567891011121314151617181920212223242526272829303132package mainimport ( &quot;fmt&quot; &quot;time&quot;)// 判断管道有没有存满func main() &#123; // 创建管道 output1 := make(chan string, 10) // 子协程写数据 go write(output1) // 取数据 for s := range output1 &#123; fmt.Println(&quot;res:&quot;, s) time.Sleep(time.Second) &#125;&#125;func write(ch chan string) &#123; for &#123; select &#123; // 写数据 case ch &lt;- &quot;hello&quot;: fmt.Println(&quot;write hello&quot;) default: fmt.Println(&quot;channel full&quot;) &#125; time.Sleep(time.Millisecond * 500) &#125;&#125; 并发安全与锁Syncsync.WaitGroup 方法名 功能 (wg * WaitGroup) Add(delta int) 计数器+delta (wg *WaitGroup) Done() 计数器-1 (wg *WaitGroup) Wait() 阻塞直到计数器变为0 sync.WaitGroup内部维护着一个计数器，计数器的值可以增加和减少。例如当我们启动了N 个并发任务时，就将计数器值增加N。每个任务完成时通过调用Done()方法将计数器减1。通过调用Wait()来等待并发任务执行完，当计数器值为0时，表示所有并发任务已经完成。 注意：sync.WaitGroup是一个结构体，传递的时候要传递指针。 sync.Once实现单例和资源只加载一次的方法 sync.Once其实内部包含一个互斥锁和一个布尔值，互斥锁保证布尔值和数据的安全，而布尔值用来记录初始化是否完成。这样设计就能保证初始化操作的时候是并发安全的并且初始化操作也不会被执行多次。 sync.Once只有一个Do方法，其签名如下： 1func (o *Once) Do(f func()) &#123;&#125; 123456789101112131415161718var icons map[string]image.Imagevar loadIconsOnce sync.Oncefunc loadIcons() &#123; icons = map[string]image.Image&#123; &quot;left&quot;: loadIcon(&quot;left.png&quot;), &quot;up&quot;: loadIcon(&quot;up.png&quot;), &quot;right&quot;: loadIcon(&quot;right.png&quot;), &quot;down&quot;: loadIcon(&quot;down.png&quot;), &#125;&#125;// Icon 是并发安全的func Icon(name string) image.Image &#123; loadIconsOnce.Do(loadIcons) return icons[name]&#125; sync.Mapmap不是线程安全的，Go语言的sync包中提供了一个开箱即用的并发安全版map–sync.Map。开箱即用表示不用像内置的map一样使用make函数初始化就能直接使用。同时sync.Map内置了诸如Store、Load、LoadOrStore、Delete、Range等操作方法。 猜测实现类似于Java中的ConcurrentHashMap，待研究 12345678910111213141516var m = sync.Map&#123;&#125;func main() &#123; wg := sync.WaitGroup&#123;&#125; for i := 0; i &lt; 20; i++ &#123; wg.Add(1) go func(n int) &#123; key := strconv.Itoa(n) m.Store(key, n) value, _ := m.Load(key) fmt.Printf(&quot;k=:%v,v:=%v\\n&quot;, key, value) wg.Done() &#125;(i) &#125; wg.Wait()&#125; 原子操作代码中的加锁操作因为涉及内核态的上下文切换会比较耗时、代价比较高。针对基本数据类型我们还可以使用原子操作来保证并发安全，因为原子操作是Go语言提供的方法它在用户态就可以完成，因此性能比加锁操作更好。Go语言中原子操作由内置的标准库sync/atomic提供。 atomic包提供了底层的原子级内存操作，对于同步算法的实现很有用。这些函数必须谨慎地保证正确使用。除了某些特殊的底层应用，使用通道或者sync包的函数/类型实现同步更好。 atomic包 方法 解释 func LoadInt32(addr *int32) (val int32) func LoadInt64(addr *int64) (val int64)func LoadUint32(addr*uint32) (val uint32)func LoadUint64(addr*uint64) (val uint64)func LoadUintptr(addr*uintptr) (val uintptr)func LoadPointer(addr*unsafe.Pointer) (val unsafe.Pointer) 读取操作 func StoreInt32(addr *int32, val int32) func StoreInt64(addr *int64, val int64) func StoreUint32(addr *uint32, val uint32) func StoreUint64(addr *uint64, val uint64) func StoreUintptr(addr *uintptr, val uintptr) func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer) 写入操作 func AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) 修改操作 func SwapInt32(addr *int32, new int32) (old int32) func SwapInt64(addr *int64, new int64) (old int64) func SwapUint32(addr *uint32, new uint32) (old uint32) func SwapUint64(addr *uint64, new uint64) (old uint64) func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer) 交换操作 func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool) func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) 比较并交换操作 原子操作和互斥锁的性能比较123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051var x int64var l sync.Mutexvar wg sync.WaitGroup// 普通版加函数func add() &#123; // x = x + 1 x++ // 等价于上面的操作 wg.Done()&#125;// 互斥锁版加函数func mutexAdd() &#123; l.Lock() x++ l.Unlock() wg.Done()&#125;// 原子操作版加函数func atomicAdd() &#123; atomic.AddInt64(&amp;x, 1) wg.Done()&#125;func main() &#123; start := time.Now() for i := 0; i &lt; 10000; i++ &#123; wg.Add(1) // go add() // 普通版add函数 不是并发安全的 // go mutexAdd() // 加锁版add函数 是并发安全的，但是加锁性能开销大 go atomicAdd() // 原子操作版add函数 是并发安全，性能优于加锁版 &#125; wg.Wait() end := time.Now() fmt.Println(x) fmt.Println(end.Sub(start))&#125;//outgo mutexAdd()100004.672672msgo atomicAdd()100004.63377msgo add()91715.170112ms","categories":[],"tags":[{"name":"go多线程编程","slug":"go多线程编程","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/"}]},{"title":"go基础 - 方法","slug":"go基础-方法","date":"2021-11-27T08:43:49.000Z","updated":"2021-11-27T15:56:07.415Z","comments":true,"path":"2021/11/27/go基础-方法/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/27/go%E5%9F%BA%E7%A1%80-%E6%96%B9%E6%B3%95/","excerpt":"","text":"方法Golang 方法总是绑定对象实例，并隐式将实例作为第一实参 (receiver)。 一个方法就是一个包含了接受者的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针。 所有给定类型的方法属于该类型的方法集。 12345• 只能为当前包内命名类型定义方法。• 参数 receiver 可任意命名。如方法中未曾使用 ，可省略参数名。• 参数 receiver 类型可以是 T 或 *T。基类型 T 不能是接口或指针。 • 不支持方法重载，receiver 只是参数签名的组成部分。• 可用实例 value 或 pointer 调用全部方法，编译器自动转换。 方法定义12345678910111213141516171819202122232425262728293031func (recevier type) methodName(参数列表)(返回值列表)&#123;&#125;参数和返回值可以省略package mainimport ( &quot;fmt&quot;)//结构体type User struct &#123; Name string Email string&#125;//方法func (u User) Notify() &#123; fmt.Printf(&quot;%v : %v \\n&quot;, u.Name, u.Email)&#125;func main() &#123; // 值类型调用方法 u1 := User&#123;&quot;golang&quot;, &quot;golang@golang.com&quot;&#125; u1.Notify() // 指针类型调用方法 u2 := User&#123;&quot;go&quot;, &quot;go@go.com&quot;&#125; u3 := &amp;u2 u3.Notify()&#125;//首先我们定义了一个叫做 User 的结构体类型，然后定义了一个该类型的方法叫做 Notify，该方法的接受者是一个 User 类型的值。要调用 Notify 方法我们需要一个 User 类型的值或者指针。 指针类型接收者和值类型接收者：当接受者不是一个指针时，该方法操作对应接受者的值的副本(意思就是即使你使用了指针调用函数，但是函数的接受者是值类型，所以函数内部操作还是对副本的操作，而不是指针操作。 1234567891011121314151617181920212223242526272829303132333435//方法不过是一种特殊的函数，只需将其还原，就知道 receiver T 和 *T 的差别。package mainimport &quot;fmt&quot;type Data struct &#123; x int&#125;func (self Data) ValueTest() &#123; // func ValueTest(self Data); fmt.Printf(&quot;Value: %p\\n&quot;, &amp;self)&#125;func (self *Data) PointerTest() &#123; // func PointerTest(self *Data); fmt.Printf(&quot;Pointer: %p\\n&quot;, self)&#125;func main() &#123; d := Data&#123;&#125; p := &amp;d fmt.Printf(&quot;Data: %p\\n&quot;, p) d.ValueTest() // ValueTest(d) d.PointerTest() // PointerTest(&amp;d) p.ValueTest() // ValueTest(*p) p.PointerTest() // PointerTest(p)&#125;//outData: 0xc42007c008Value: 0xc42007c018Pointer: 0xc42007c008Value: 0xc42007c020Pointer: 0xc42007c008 普通函数与方法的区别1.对于普通函数，接收者为值类型时，不能将指针类型的数据直接传递，反之亦然。 2.对于方法（如struct的方法），接收者为值类型时，可以直接用指针类型的变量调用方法，反过来同样也可以。但是值类型的接受者，使用指针类型的变量调用方法也是值拷贝的形式。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package main//普通函数与方法的区别（在接收者分别为值类型和指针类型的时候）import ( &quot;fmt&quot;)//1.普通函数//接收值类型参数的函数func valueIntTest(a int) int &#123; return a + 10&#125;//接收指针类型参数的函数func pointerIntTest(a *int) int &#123; return *a + 10&#125;func structTestValue() &#123; a := 2 fmt.Println(&quot;valueIntTest:&quot;, valueIntTest(a)) //函数的参数为值类型，则不能直接将指针作为参数传递 //fmt.Println(&quot;valueIntTest:&quot;, valueIntTest(&amp;a)) //compile error: cannot use &amp;a (type *int) as type int in function argument b := 5 fmt.Println(&quot;pointerIntTest:&quot;, pointerIntTest(&amp;b)) //同样，当函数的参数为指针类型时，也不能直接将值类型作为参数传递 //fmt.Println(&quot;pointerIntTest:&quot;, pointerIntTest(b)) //compile error:cannot use b (type int) as type *int in function argument&#125;//2.方法type PersonD struct &#123; id int name string&#125;//接收者为值类型func (p PersonD) valueShowName() &#123; fmt.Println(p.name)&#125;//接收者为指针类型func (p *PersonD) pointShowName() &#123; fmt.Println(p.name)&#125;func structTestFunc() &#123; //值类型调用方法 personValue := PersonD&#123;101, &quot;hello world&quot;&#125; personValue.valueShowName() personValue.pointShowName() //指针类型调用方法 personPointer := &amp;PersonD&#123;102, &quot;hello golang&quot;&#125; personPointer.valueShowName() personPointer.pointShowName() //与普通函数不同，接收者为指针类型和值类型的方法，指针类型和值类型的变量均可相互调用&#125;func main() &#123; structTestValue() structTestFunc()&#125;//outvalueIntTest: 12pointerIntTest: 15hello worldhello worldhello golanghello golang 匿名字段可以像字段成员那样访问匿名字段方法，编译器负责查找。 123456789101112131415161718192021222324type User struct &#123; id int name string&#125;type Manager struct &#123; User&#125;func (u *User) ToString() string &#123; return fmt.Sprintf(&quot;User: %p, %v&quot;,u,u)&#125;func main() &#123; m := Manager&#123;User&#123;id: 1,name: &quot;Tom&quot;&#125;&#125; fmt.Printf(&quot;Manager: %p\\n&quot;, &amp;m) fmt.Println(m.ToString()) u := User&#123; id: 2, name: &quot;Jerry&quot;, &#125; fmt.Printf(&quot;User: %p\\n&quot;,&amp;u) fmt.Println(u.ToString())&#125; 通过匿名字段，可获得和继承类似的复用能力。依据编译器查找次序，只需在外层定义同名方法，就可以实现 “override”。 123456789101112131415161718192021222324252627282930313233package mainimport &quot;fmt&quot;type User struct &#123; id int name string&#125;type Manager struct &#123; User title string&#125;func (self *User) ToString() string &#123; return fmt.Sprintf(&quot;User: %p, %v&quot;, self, self)&#125;func (self *Manager) ToString() string &#123; return fmt.Sprintf(&quot;Manager: %p, %v&quot;, self, self)&#125;func main() &#123; m := Manager&#123;User&#123;1, &quot;Tom&quot;&#125;, &quot;Administrator&quot;&#125; fmt.Println(m.ToString()) fmt.Println(m.User.ToString())&#125;//outManager: 0xc420074180, &amp;&#123;&#123;1 Tom&#125; Administrator&#125;User: 0xc420074180, &amp;&#123;1 Tom&#125; 方法集Golang方法集 ：每个类型都有与之关联的方法集，这会影响到接口实现规则。 12345• 类型 T 方法集包含全部 receiver T 方法。• 类型 *T 方法集包含全部 receiver T + *T 方法。• 如类型 S 包含匿名字段 T，则 S 和 *S 方法集包含 T 方法。 • 如类型 S 包含匿名字段 *T，则 S 和 *S 方法集包含 T + *T 方法。 • 不管嵌入 T 或 *T，*S 方法集总是包含 T + *T 方法。 用实例 value 和 pointer 调用方法 (含匿名字段) 不受方法集约束，编译器总是查找全部方法，并自动转换 receiver 实参。 方法集对接口的影响： 1234567891011121314151617181920212223242526272829package mainimport &quot;fmt&quot;type notifier interface &#123; notify()&#125;type user struct &#123; name string email string&#125;func (u *user) notify() &#123; fmt.Printf(&quot;Sending user email to %s&lt;%s&gt;\\n&quot;, u.name, u.email)&#125;func main() &#123; u := user&#123;&quot;Bill&quot;, &quot;bill@email.com&quot;&#125; sendNotificatioin(u)&#125;func sendNotificatioin(n notifier) &#123; n.notify()&#125;//out./main.go:20: cannot use u (type user) as type notifier in argument to sendNotificatioin: user does not implement notifier (notify method has pointer receiver) 表达式Golang 表达式 ：根据调用者不同，方法分为两种表现形式: 123instance.method(args...) ---&gt; &lt;type&gt;.func(instance, args...)前者称为 method value，后者 method expression。两者都可像普通函数那样赋值和传参，区别在于 method value 绑定实例，而 method expression 则须显式传参。 1234567891011121314151617181920212223package mainimport &quot;fmt&quot;type User struct &#123; id int name string&#125;func (self *User) Test() &#123; fmt.Printf(&quot;%p, %v\\n&quot;, self, self)&#125;func main() &#123; u := User&#123;1, &quot;Tom&quot;&#125; u.Test() mValue := u.Test // 立即复制 receiver，因为不是指针类型，不受后续修改影响。 mValue() // 隐式传递 receiver mExpression := (*User).Test mExpression(&amp;u) // 显式传递 receiver&#125; 方法“还原”成函数 1234567891011121314151617181920package maintype Data struct&#123;&#125;func (Data) TestValue() &#123;&#125;func (*Data) TestPointer() &#123;&#125;func main() &#123; var p *Data = nil p.TestPointer() (*Data)(nil).TestPointer() // method value (*Data).TestPointer(nil) // method expression // p.TestValue() // invalid memory address or nil pointer dereference // (Data)(nil).TestValue() // cannot convert nil to type Data // Data.TestValue(nil) // cannot use nil as type Data in function argument&#125; 自定义error接口接口（interface）定义了一个对象的行为规范，只定义规范不实现，由具体的对象来实现规范的细节。 接口类型在Go语言中接口（interface）是一种类型，一种抽象的类型。 interface是一组method的集合，是duck-type programming的一种体现。接口做的事情就像是定义一个协议（规则），只要一台机器有洗衣服和甩干的功能，我就称它为洗衣机。不关心属性（数据），只关心行为（方法）。","categories":[],"tags":[{"name":"go语言基础","slug":"go语言基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"}]},{"title":"go并发编程","slug":"go并发编程","date":"2021-11-27T08:43:27.000Z","updated":"2021-11-28T08:08:18.032Z","comments":true,"path":"2021/11/27/go并发编程/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/27/go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","excerpt":"","text":"Go多线程编程并发介绍协程和线程： 12协程：独立的栈空间，共享堆空间，调度由用户自己控制，本质上有点类似于用户级线程，这些用户级线程的调度也是自己实现的。线程：一个线程上可以跑多个协程，协程是轻量级的线程。 goroutine 只是由官方实现的超级”线程池”。每个实力4~5KB的栈内存占用和由于实现机制而大幅减少的创建和销毁开销是go高并发的根本原因。 并发不是并行：并发主要由切换时间片来实现”同时”运行，并行则是直接利用多核实现多线程的运行，go可以设置使用核数，以发挥多核计算机的能力。 goroutine 奉行通过通信来共享内存，而不是共享内存来通信。Goroutinegoroutine的概念类似于线程，但 goroutine是由Go的运行时（runtime）调度和管理的。Go程序会智能地将 goroutine 中的任务合理地分配给每个CPU。Go语言之所以被称为现代化的编程语言，就是因为它在语言层面已经内置了调度和上下文切换的机制。 Goroutine的使用类似于OC中一样，开发者只需要定义很多任务，由系统去帮助我们把这些任务并发执行。 使用goroutine 在调用函数的时候在前面加上go关键字，就可以为一个函数创建一个goroutine。 一个goroutine必定对应一个函数，可以创建多个goroutine去执行相同的函数。 使用： 启动单个goroutine, 主协程退出其他协程也会退出 123456789101112func main() &#123; go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(&quot;main goroutine done!&quot;)&#125;//这里执行只会打印 main goroutine done//在程序启动的时候，Go程序会为main函数创建一个默认的goroutine，main返回时goroutine会结束，所有在main中启动的goroutine会一同结束func main() &#123; go hello() // 启动另外一个goroutine去执行hello函数 fmt.Println(&quot;main goroutine done!&quot;) time.Sleep(time.Second)&#125; 启动多个goroutine 1234567891011121314var wg sync.WaitGroupfunc hello(i int) &#123; defer wg.Done() // goroutine结束就登记-1 fmt.Println(&quot;Hello Goroutine!&quot;, i)&#125;func main() &#123; for i := 0; i &lt; 10; i++ &#123; wg.Add(1) // 启动一个goroutine就登记+1 go hello(i) &#125; wg.Wait() // 等待所有登记的goroutine都结束&#125; goroutine与线程 可增长的栈 OS线程（操作系统线程）一般都有固定的栈内存（通常为2MB）,一个goroutine的栈在其生命周期开始时只有很小的栈（典型情况下2KB），goroutine的栈不是固定的，他可以按需增大和缩小，goroutine的栈大小限制可以达到1GB，虽然极少会用到这个大。所以在Go语言中一次创建十万左右的goroutine也是可以的。 goroutine调度 GPM是Go语言运行时（runtime）层面的实现，是go语言自己实现的一套调度系统。区别于操作系统调度OS线程。 1.G很好理解，就是个goroutine的，里面除了存放本goroutine信息外 还有与所在P的绑定等信息。 2.P管理着一组goroutine队列，P里面会存储当前goroutine运行的上下文环境（函数指针，堆栈地址及地址边界），P会对自己管理的goroutine队列做一些调度（比如把占用CPU时间较长的goroutine暂停、运行后续的goroutine等等）当自己的队列消费完了就去全局队列里取，如果全局队列里也消费完了会去其他P的队列里抢任务。 3.M（machine）是Go运行时（runtime）对操作系统内核线程的虚拟， M与内核线程一般是一一映射的关系， 一个groutine最终是要放到M上执行的； P与M一般也是一一对应的。他们关系是： P管理着一组G挂载在M上运行。当一个G长久阻塞在一个M上时，runtime会新建一个M，阻塞G所在的P会把其他的G 挂载在新建的M上。当旧的G阻塞完成或者认为其已经死掉时 回收旧的M。 P的个数是通过runtime.GOMAXPROCS设定（最大256），Go1.5版本之后默认为物理线程数。 在并发量大的时候会增加一些P和M，但不会太多，切换太频繁的话得不偿失。 单从线程调度讲，Go语言相比起其他语言的优势在于OS线程是由OS内核来调度的，goroutine则是由Go运行时（runtime）自己的调度器调度的，这个调度器使用一个称为m:n调度的技术（复用/调度m个goroutine到n个OS线程）。 其一大特点是goroutine的调度是在用户态下完成的， 不涉及内核态与用户态之间的频繁切换，包括内存的分配与释放，都是在用户态维护着一块大的内存池， 不直接调用系统的malloc函数（除非内存池需要改变），成本比调度OS线程低很多。 另一方面充分利用了多核的硬件资源，近似的把若干goroutine均分在物理线程上， 再加上本身goroutine的超轻量，以上种种保证了go调度方面的性能。 runtime包runtime.Gosched()让出CPU时间片，重新等待安排任务 1234567891011121314151617181920212223242526272829package mainimport ( &quot;fmt&quot; &quot;runtime&quot;)func main() &#123; go func(s string) &#123; for i := 0; i &lt; 2; i++ &#123; fmt.Println(s) &#125; &#125;(&quot;world&quot;) // 主协程 for i := 0; i &lt; 2; i++ &#123; // 切一下，再次分配任务 runtime.Gosched() fmt.Println(&quot;hello&quot;) &#125;&#125;//不注释，使用了runtime.Gosched()worldworldhellohello//不使用runtime.Gosched()hellohello runtime.Goexit()退出当前协程 1234567891011121314151617181920212223242526package mainimport ( &quot;fmt&quot; &quot;runtime&quot;)func main() &#123; go func() &#123; defer fmt.Println(&quot;A.defer&quot;) func() &#123; defer fmt.Println(&quot;B.defer&quot;) // 结束协程 runtime.Goexit() defer fmt.Println(&quot;C.defer&quot;) fmt.Println(&quot;B&quot;) &#125;() fmt.Println(&quot;A&quot;) &#125;() for &#123; &#125;&#125;//outB.deferA.defer runtime.GOMAXPROCSGo运行时的调度器使用GOMAXPROCS参数来确定需要使用多少个OS线程来同时执行Go代码。默认值是机器上的CPU核心数。例如在一个8核心的机器上，调度器会把Go代码同时调度到8个OS线程上（GOMAXPROCS是m:n调度中的n）。 Go语言中可以通过runtime.GOMAXPROCS()函数设置当前程序并发时占用的CPU逻辑核心数。 Go1.5版本之前，默认使用的是单核心执行。Go1.5版本之后，默认使用全部的CPU逻辑核心数。 我们可以通过将任务分配到不同的CPU逻辑核心上实现并行的效果，这里举个例子： 123456789101112131415161718func a() &#123; for i := 1; i &lt; 10; i++ &#123; fmt.Println(&quot;A:&quot;, i) &#125;&#125;func b() &#123; for i := 1; i &lt; 10; i++ &#123; fmt.Println(&quot;B:&quot;, i) &#125;&#125;func main() &#123; runtime.GOMAXPROCS(1) //runtime.GOMAXPROCS(2) go a() go b() time.Sleep(time.Second)&#125; Go语言中的操作系统线程和goroutine的关系： 1.一个操作系统线程对应用户态多个goroutine。 2.go程序可以同时使用多个操作系统线程。 3.goroutine和OS线程是多对多的关系，即m:n。 ChannelGo语言的并发模型是CSP（Communicating Sequential Processes），提倡通过通信共享内存而不是通过共享内存而实现通信。 如果说goroutine是Go程序并发的执行体，channel就是它们之间的连接。channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。 Go 语言中的通道（channel）是一种特殊的类型。通道像一个传送带或者队列，总是遵循先入先出（First In First Out）的规则，保证收发数据的顺序。每一个通道都是一个具体类型的导管，也就是声明channel的时候需要为其指定元素类型。 channel类型channel是一种类型，一种引用类型。声明通道类型的格式如下： 12345678var 变量 chan 元素类型//创建 通道是引用类型，通道类型的空值是nil。var ch chan intfmt.Println(ch) // &lt;nil&gt;//初始化make(chan 元素类型, [缓冲大小]) channel操作通道有发送（send）、接收(receive）和关闭（close）三种操作。 发送和接收都使用&lt;-符号。 1234567891011ch := make(chan int)//发送ch &lt;- 10//接收x := &lt;-ch//关闭//关于关闭通道需要注意的事情是，只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。通道是可以被垃圾回收机制回收的，它和关闭文件是不一样的，在结束操作之后关闭文件是必须要做的，但关闭通道不是必须的。close(ch) 注：关闭后的通道有以下特定： 12341.对一个关闭的通道再发送值就会导致panic。2.对一个关闭的通道进行接收会一直获取值直到通道为空。3.对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。4.关闭一个已经关闭的通道会导致panic。 无缓冲的通道 无缓冲的通道又称为阻塞的通道 无缓冲通道上的发送操作会阻塞，直到另一个goroutine在该通道上执行接收操作，这时值才能发送成功，两个goroutine将继续执行。相反，如果接收操作先执行，接收方的goroutine将阻塞，直到另一个goroutine在该通道上发送一个值。 使用无缓冲通道进行通信将导致发送和接收的goroutine同步化。因此，无缓冲通道也被称为同步通道。 12345678910func recv(c chan int) &#123; ret := &lt;-c fmt.Println(&quot;接收成功&quot;, ret)&#125;func main() &#123; ch := make(chan int) go recv(ch) // 启用goroutine从通道接收值 ch &lt;- 10 fmt.Println(&quot;发送成功&quot;)&#125; 有缓冲的通道 在使用make函数初始化通道的时候为其指定通道的容量 可以使用内置的len函数获取通道内元素的数量，使用cap函数获取通道的容量 12345func main() &#123; ch := make(chan int, 1) // 创建一个容量为1的有缓冲区通道 ch &lt;- 10 fmt.Println(&quot;发送成功&quot;)&#125; close()通过内置的close()函数关闭channel（如果你的管道不往里存值或者取值的时候一定记得关闭管道） 123456789101112131415161718192021package mainimport &quot;fmt&quot;func main() &#123; c := make(chan int) go func() &#123; for i := 0; i &lt; 5; i++ &#123; c &lt;- i &#125; close(c) &#125;() for &#123; if data, ok := &lt;-c; ok &#123; fmt.Println(data) &#125; else &#123; break &#125; &#125; fmt.Println(&quot;main结束&quot;)&#125; 常见使用场景 从通道循环取值 当通过通道发送有限的数据时，我们可以通过close函数关闭通道来告知从该通道接收值的goroutine停止等待。当通道被关闭时，往该通道发送值会引发panic，从该通道里接收的值一直都是类型零值。那如何判断一个通道是否被关闭了呢？ 1234567891011121314151617181920212223242526func main() &#123; ch1 := make(chan int) ch2 := make(chan int) // 开启goroutine将0~100的数发送到ch1中 go func() &#123; for i := 0; i &lt; 100; i++ &#123; ch1 &lt;- i &#125; close(ch1) &#125;() // 开启goroutine从ch1中接收值，并将该值的平方发送到ch2中 go func() &#123; for &#123; i, ok := &lt;-ch1 // 通道关闭后再取值ok=false if !ok &#123; break &#125; ch2 &lt;- i * i &#125; close(ch2) &#125;() // 在主goroutine中从ch2中接收值打印 for i := range ch2 &#123; // 通道关闭后会退出for range循环 fmt.Println(i) &#125;&#125; 单向通道 有的时候我们会将通道作为参数在多个任务函数间传递，很多时候我们在不同的任务函数中使用通道都会对其进行限制，比如限制通道在函数中只能发送或只能接收。 Go语言中提供了单向通道来处理这种情况。 1231.chan&lt;- int是一个只能发送的通道，可以发送但是不能接收；2.&lt;-chan int是一个只能接收的通道，可以接收但是不能发送。3.函数传参及任何赋值操作中将双向通道转换为单向通道是可以的，但反过来是不可以的 通道总结 12345678910111213141516171819202122func main() &#123; ch1 := make(chan int,3) for i := 0; i &lt; 3; i++ &#123; ch1&lt;-i &#125; close(ch1) for &#123; if i,ok := &lt;-ch1;ok &#123; fmt.Println(i) &#125; else &#123; fmt.Println(&quot;read over&quot;) break &#125; &#125;&#125;//012read over","categories":[],"tags":[{"name":"go多线程编程","slug":"go多线程编程","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/"}]},{"title":"go语言基础 - 函数","slug":"go语言基础-函数","date":"2021-11-27T05:22:16.000Z","updated":"2021-11-27T08:07:32.225Z","comments":true,"path":"2021/11/27/go语言基础-函数/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/27/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80-%E5%87%BD%E6%95%B0/","excerpt":"","text":"函数定义函数特点12345678910• 无需声明原型。• 支持不定 变参。• 支持多返回值。• 支持命名返回参数。 • 支持匿名函数和闭包。• 函数也是一种类型，一个函数可以赋值给变量。• 不支持 嵌套 (nested) 一个包不能有两个名字一样的函数。• 不支持 重载 (overload) • 不支持 默认参数 (default parameter)。 函数声明函数声明包含一个函数名，参数列表， 返回值列表和函数体。如果函数没有返回值，则返回列表可以省略。函数从第一条语句开始执行，直到执行return语句或者执行函数的最后一条语句。 12345func test(x, y int, s string) (int, string) &#123; // 类型相同的相邻参数，参数类型可合并。 多返回值必须用括号。 n := x + y return n, fmt.Sprintf(s, n)&#125; 12345678910111213141516171819202122232425//函数是第一类对象，可作为参数传递package mainimport &quot;fmt&quot;func test(fn func() int) int &#123; return fn()&#125;// 定义函数类型。type FormatFunc func(s string, x, y int) string func format(fn FormatFunc, s string, x, y int) string &#123; return fn(s, x, y)&#125;func main() &#123; s1 := test(func() int &#123; return 100 &#125;) // 直接将匿名函数当参数。 s2 := format(func(s string, x, y int) string &#123; return fmt.Sprintf(s, x, y) &#125;, &quot;%d, %d&quot;, 10, 20) println(s1, s2)&#125; 参数: 函数参数 当函数调用时，函数的形参放到栈帧里一起被压栈，调用完成后会出栈，使用上类似局部变量。 map、slice、chan、指针、interface默认以引用的方式传递，拷贝的是地址，其他基本都是值传递 可变参数 Golang的可变参数本质是一个slice（可变数组），只能有一个且必须为最后一个 在参数赋值时可以不用用一个一个的赋值，可以直接传递一个数组或者切片，特别注意的是在参数后加上“…”即可。 12345678func myfunc(args ...int) &#123; //0个或多个参数&#125;func add(a int, args…int) int &#123; //1个或多个参数&#125;func add(a int, b int, args…int) int &#123; //2个或多个参数&#125; 任意类型的不定参数，使用interface{}传递任意参数 12345678910111213141516171819func myfunc(args ...interface&#123;&#125;) &#123; &#125;func test(s string, n ...int) string &#123; var x int for _, i := range n &#123; x += i &#125; return fmt.Sprintf(s, x)&#125;func main() &#123; println(test(&quot;sum: %d&quot;, 1, 2, 3)) s := []int&#123;1, 2, 3&#125; //使用 slice 对象做变参时，必须展开。（slice...） res := test(&quot;sum: %d&quot;, s...) // slice... 展开slice println(res)&#125; 返回值&quot;_&quot;标识符，用来忽略函数的某个返回值 Go 的返回值可以被命名，并且就像在函数体开头声明的变量那样使用。 返回值的名称应当具有一定的意义，可以作为文档使用。 没有参数的 return 语句返回各个返回变量的当前值。这种用法被称作“裸”返回。 直接返回语句仅应当用在像下面这样的短函数中。在长的函数中它们会影响代码的可读性。 直接返回语句.命名返回参数可看做与形参类似的局部变量，最后由 return 隐式返回。 命名返回参数可被同名局部变量遮蔽，此时需要显式返回。 123456789101112131415161718192021222324252627package mainimport ( &quot;fmt&quot;)func add(a, b int) (c int) &#123; c = a + b return&#125;func calc(a, b int) (sum int, avg int) &#123; sum = a + b avg = (a + b) / 2 return&#125;func main() &#123; var a, b int = 1, 2 c := add(a, b) sum, avg := calc(a, b) fmt.Println(a, b, c, sum, avg)&#125;//out 1 2 3 3 1 Golang返回值不能用容器对象接收多返回值。只能用多个变量，或 &quot;_&quot; 忽略。 12345678910111213package mainfunc test() (int, int) &#123; return 1, 2&#125;func main() &#123; // s := make([]int, 2) // s = test() // Error: multiple-value test() in single-value context x, _ := test() println(x)&#125; 多返回值可直接作为其他函数调用实参。 123456789101112131415161718192021222324252627package mainfunc test() (int, int) &#123; return 1, 2&#125;func add(x, y int) int &#123; return x + y&#125;func sum(n ...int) int &#123; var x int for _, i := range n &#123; x += i &#125; return x&#125;func main() &#123; println(add(test())) println(sum(test()))&#125;//out 3 3 命名返回参数允许 defer 延迟调用通过闭包读取和修改。 12345678910111213141516package mainfunc add(x, y int) (z int) &#123; defer func() &#123; z += 100 &#125;() z = x + y return&#125;func main() &#123; println(add(1, 2)) &#125;//out 103 显式 return 返回前，会先修改命名返回参数。 执行顺序:return先执行，return负责将结果写入返回值，defer做收尾工作，最后函数携带当前返回值退出 123456789101112131415161718package mainfunc add(x, y int) (z int) &#123; defer func() &#123; println(z) // 输出: 203 &#125;() z = x + y return z + 200 // 执行顺序: (z = z + 200) -&gt; (call defer) -&gt; (return)&#125;func main() &#123; println(add(1, 2)) // 输出: 203&#125;// out 203 203 匿名函数匿名函数是指不需要定义函数名的一种函数实现方式。1958年LISP首先采用匿名函数。 在Go里面，函数可以像普通变量一样被传递或使用，Go语言支持随时在代码里定义匿名函数。 匿名函数由一个不带函数名的函数声明和函数体组成。匿名函数的优越性在于可以直接使用函数内的变量，不必申明。(猜测是匿名函数的结构体里捕获了变量) 12345678910111213package mainimport ( &quot;fmt&quot; &quot;math&quot;)func main() &#123; getSqrt := func(a float64) float64 &#123; return math.Sqrt(a) &#125; fmt.Println(getSqrt(4))&#125; Golang匿名函数可赋值给变量，做为结构字段，或者在 channel 里传送。 123456789101112131415161718192021222324252627282930313233package mainfunc main() &#123; // --- function variable --- fn := func() &#123; println(&quot;Hello, World!&quot;) &#125; fn() // --- function collection --- fns := [](func(x int) int)&#123; func(x int) int &#123; return x + 1 &#125;, func(x int) int &#123; return x + 2 &#125;, &#125; println(fns[0](100)) // --- function as field --- d := struct &#123; fn func() string &#125;&#123; fn: func() string &#123; return &quot;Hello, World!&quot; &#125;, &#125; println(d.fn()) // --- channel of function --- fc := make(chan func() string, 2) fc &lt;- func() string &#123; return &quot;Hello, World!&quot; &#125; println((&lt;-fc)())&#125;//outHello, World!101Hello, World!Hello, World! 闭包闭包是由函数及其相关引用环境组合而成的实体(即：闭包=函数+引用环境)。 “官方”的解释是：所谓“闭包”，指的是一个拥有许多变量和绑定了这些变量的环境的表达式（通常是一个函数），因而这些变量也是该表达式的一部分。 Go的闭包： 闭包复制的是原对象指针，这就很容易解释延迟引用现象。 123456789101112131415161718192021222324package mainimport &quot;fmt&quot;func test() func() &#123; x := 100 fmt.Printf(&quot;x (%p) = %d\\n&quot;, &amp;x, x) return func() &#123; fmt.Printf(&quot;x (%p) = %d\\n&quot;, &amp;x, x) &#125;&#125;func main() &#123; f := test() f()&#125;//out x (0xc42007c008) = 100 x (0xc42007c008) = 100在汇编层 ，test 实际返回的是 FuncVal 对象，其中包含了匿名函数地址、闭包对象指针。当调 匿名函数时，只需以某个寄存器传递该对象即可。 FuncVal &#123; func_address, closure_var_pointer ... &#125; 1234567891011121314151617181920212223242526272829303132package mainimport &quot;fmt&quot;// 返回2个函数类型的返回值func test01(base int) (func(int) int, func(int) int) &#123; // 定义2个函数，并返回 // 相加 add := func(i int) int &#123; base += i return base &#125; // 相减 sub := func(i int) int &#123; base -= i return base &#125; // 返回 return add, sub&#125;func main() &#123; f1, f2 := test01(10) // base一直是没有消 fmt.Println(f1(1), f2(2)) // 此时base是9 fmt.Println(f1(3), f2(4))&#125;//out11 912 8 延迟调用Defer defer特性: 12341. 关键字 defer 用于注册延迟调用。2. 这些调用直到 return 前才被执。因此，可以用来做资源清理。3. 多个defer语句，按先进后出的方式执行。4. defer语句中的变量，在defer声明时就决定了。 defer用途 1231. 关闭文件句柄2. 锁资源释放3. 数据库连接释放 defer先进后出 123456789101112131415161718package mainimport &quot;fmt&quot;func main() &#123; var whatever [5]struct&#123;&#125; for i := range whatever &#123; defer fmt.Println(i) &#125;&#125;//out43210 defer和闭包 Each time a “defer” statement executes, the function value and parameters to the call are evaluated as usualand saved anew but the actual function is not invoked. 也就是说函数正常执行,由于闭包用到的变量 i 在执行的时候已经变成4,所以输出全都是4. 1234567891011121314151617package mainimport &quot;fmt&quot;func main() &#123; var whatever [5]struct&#123;&#125; for i := range whatever &#123; defer func() &#123; fmt.Println(i) &#125;() &#125;&#125;//out 4 4 4 4 4 常见错误defer f.Close 123456789101112131415161718192021package mainimport &quot;fmt&quot;type Test struct &#123; name string&#125;func (t *Test) Close() &#123; fmt.Println(t.name, &quot; closed&quot;)&#125;func main() &#123; ts := []Test&#123;&#123;&quot;a&quot;&#125;, &#123;&quot;b&quot;&#125;, &#123;&quot;c&quot;&#125;&#125; for _, t := range ts &#123; defer t.Close() &#125;&#125;//out c closed c closed c closed 处理: 123456789101112131415161718192021222324package mainimport &quot;fmt&quot;type Test struct &#123; name string&#125;func (t *Test) Close() &#123; fmt.Println(t.name, &quot; closed&quot;)&#125;func Close(t Test) &#123; t.Close()&#125;func main() &#123; ts := []Test&#123;&#123;&quot;a&quot;&#125;, &#123;&quot;b&quot;&#125;, &#123;&quot;c&quot;&#125;&#125; for _, t := range ts &#123; defer Close(t) &#125;&#125;//outc closedb closeda closed 或者：使用forr defer后面的语句在执行的时候，函数调用的参数会被保存起来，但是不执行。也就是复制了一份。但是并没有说struct这里的this指针如何处理，通过这个例子可以看出go语言并没有把这个明确写出来的this指针当作参数来看待。 多个 defer 注册，按 FILO 次序执行 ( 先进后出 )。哪怕函数或某个延迟调用发生错误，这些调用依旧会被执行。 123456789101112131415161718192021package mainfunc test(x int) &#123; defer println(&quot;a&quot;) defer println(&quot;b&quot;) defer func() &#123; println(100 / x) // div0 异常未被捕获，逐步往外传递，最终终止进程。 &#125;() defer println(&quot;c&quot;)&#125;func main() &#123; test(0)&#125;//outcbapanic: runtime error: integer divide by zero defer会存在性能问题，在循环中要慎重使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)var lock sync.Mutexfunc test() &#123; lock.Lock() lock.Unlock()&#125;func testdefer() &#123; lock.Lock() defer lock.Unlock()&#125;func main() &#123; func() &#123; t1 := time.Now() for i := 0; i &lt; 10000; i++ &#123; test() &#125; elapsed := time.Since(t1) fmt.Println(&quot;test elapsed: &quot;, elapsed) &#125;() func() &#123; t1 := time.Now() for i := 0; i &lt; 10000; i++ &#123; testdefer() &#125; elapsed := time.Since(t1) fmt.Println(&quot;testdefer elapsed: &quot;, elapsed) &#125;()&#125;//outtest elapsed: 223.162µstestdefer elapsed: 781.304µs defer使用常见陷阱 如果 defer 后面跟的不是一个 closure 最后执行的时候我们得到的并不是最新的值。 12345678910111213141516171819202122232425262728package mainimport ( &quot;errors&quot; &quot;fmt&quot;)func foo(a, b int) (i int, err error) &#123; defer fmt.Printf(&quot;first defer err %v\\n&quot;, err) defer func(err error) &#123; fmt.Printf(&quot;second defer err %v\\n&quot;, err) &#125;(err) defer func() &#123; fmt.Printf(&quot;third defer err %v\\n&quot;, err) &#125;() if b == 0 &#123; err = errors.New(&quot;divided by zero!&quot;) return &#125; i = a / b return&#125;func main() &#123; foo(2, 0)&#125;//outthird defer err divided by zero!second defer err &lt;nil&gt;first defer err &lt;nil&gt; defer 与 return解释：在有具名返回值的函数中（这里具名返回值为 i），执行 return 2 的时候实际上已经将 i 的值重新赋值为 2。所以defer closure 输出结果为 2 而不是 1。 12345678910111213141516171819package mainimport &quot;fmt&quot;func foo() (i int) &#123; i = 0 defer func() &#123; fmt.Println(i) &#125;() return 2&#125;func main() &#123; foo()&#125;//out2 defer nil 函数解释：名为 test 的函数一直运行至结束，然后 defer 函数会被执行且会因为值为 nil 而产生 panic 异常。然而值得注意的是，run() 的声明是没有问题，因为在test函数运行完成后它才会被调用。 123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot;)func test() &#123; var run func() = nil defer run() fmt.Println(&quot;runs&quot;)&#125;func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; fmt.Println(err) &#125; &#125;() test()&#125;//outrunsruntime error: invalid memory address or nil pointer dereference defer处理资源的常见写法 1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( &quot;fmt&quot; &quot;io&quot; &quot;os&quot;)func do() error &#123; f, err := os.Open(&quot;book.txt&quot;) if err != nil &#123; return err &#125; if f != nil &#123; //需要先判断是否成功再进行defer defer func(f io.Closer) &#123; if err := f.Close(); err != nil &#123; //在defer要处理error fmt.Printf(&quot;defer close book.txt err %v\\n&quot;, err) &#125; &#125;(f) &#125; // ..code... f, err = os.Open(&quot;another-book.txt&quot;) if err != nil &#123; return err &#125; if f != nil &#123; defer func(f io.Closer) &#123; if err := f.Close(); err != nil &#123; fmt.Printf(&quot;defer close another-book.txt err %v\\n&quot;, err) &#125; &#125;(f) //直接使用闭包捕获变量，可能会导致使用的是最终的f，需要作为参数传入保证使用的f正确 &#125; return nil&#125;func main() &#123; do()&#125; 异常处理Golang 没有结构化异常，使用 panic 抛出错误，recover 捕获错误。 异常的使用场景简单描述：Go中可以抛出一个panic的异常，然后在defer中通过recover捕获这个异常，然后正常处理。 panic 12341、内置函数2、假如函数F中书写了panic语句，会终止其后要执行的代码，在panic所在函数F内如果存在要执行的defer函数列表，按照defer的逆序执行3、返回函数F的调用者G，在G中，调用函数F语句之后的代码不会执行，假如函数G中存在要执行的defer函数列表，按照defer的逆序执行4、直到goroutine整个退出，并报告错误 recover 123451、内置函数2、用来控制一个goroutine的panicking行为，捕获panic，从而影响应用的行为3、一般的调用建议 a). 在defer函数中，通过recever来终止一个goroutine的panicking过程，从而恢复正常代码的执行 b). 可以获取通过panic传递的error 注意： 1231.利用recover处理panic指令，defer 必须放在 panic 之前定义，另外 recover 只有在 defer 调用的函数中才有效。否则当panic时，recover无法捕获到panic，无法防止panic扩散。2.recover 处理异常后，逻辑并不会恢复到 panic 那个点去，函数跑到 defer 之后的那个点。3.多个 defer 会形成 defer 栈，后定义的 defer 语句会被最先调用。 使用: 12func panic(v interface&#123;&#125;)func recover() interface&#123;&#125; 123456789101112131415161718package mainfunc main() &#123; test()&#125;func test() &#123; defer func() &#123; if err := recover(); err != nil &#123; println(err.(string)) // 将 interface&#123;&#125; 转型为具体类型。 &#125; &#125;() panic(&quot;panic error!&quot;)&#125;//outpanic error! 向已关闭的通道发送数据会引发panic 12345678910111213141516171819package mainimport ( &quot;fmt&quot;)func main() &#123; defer func() &#123; if err := recover(); err != nil &#123; fmt.Println(err) &#125; &#125;() var ch chan int = make(chan int, 10) close(ch) ch &lt;- 1&#125;//outsend on closed channel 延迟调用中引发的错误，可被后续延迟调用捕获，但仅最后一个错误可被捕获。 12345678910111213141516171819202122package mainimport &quot;fmt&quot;func test() &#123; defer func() &#123; fmt.Println(recover()) &#125;() defer func() &#123; panic(&quot;defer panic&quot;) &#125;() panic(&quot;test panic&quot;)&#125;func main() &#123; test()&#125;//outdefer panic 捕获函数 recover 只有在延迟调用内直接调用才会终止错误，否则总是返回 nil。任何未捕获的错误都会沿调用堆栈向外传递。 12345678910111213141516171819202122232425262728package mainimport &quot;fmt&quot;func test() &#123; defer func() &#123; fmt.Println(recover()) //有效 &#125;() defer recover() //无效！ defer fmt.Println(recover()) //无效！ defer func() &#123; func() &#123; println(&quot;defer inner&quot;) recover() //无效！ &#125;() &#125;() panic(&quot;test panic&quot;)&#125;func main() &#123; test()&#125;//outdefer inner&lt;nil&gt;test panic 使用延迟匿名函数或下面这样都是有效的。 123456789101112131415161718192021package mainimport ( &quot;fmt&quot;)func except() &#123; fmt.Println(recover())&#125;func test() &#123; defer except() panic(&quot;test panic&quot;)&#125;func main() &#123; test()&#125;//out test panic 如果需要保护代码 段，可将代码块重构成匿名函数，如此可确保后续代码被执 123456789101112131415161718192021222324252627package mainimport &quot;fmt&quot;func test(x, y int) &#123; var z int func() &#123; defer func() &#123; if recover() != nil &#123; z = 0 &#125; &#125;() panic(&quot;test panic&quot;) z = x / y return &#125;() fmt.Printf(&quot;x / y = %d\\n&quot;, z)&#125;func main() &#123; test(2, 1)&#125;//outx / y = 0 除用 panic 引发中断性错误外，还可返回 error 类型错误对象来表示函数调用状态。 1234567891011121314151617181920212223242526272829303132333435type error interface &#123; Error() string&#125;//标准库 errors.New 和 fmt.Errorf 函数用于创建实现 error 接口的错误对象。通过判断错误对象实例来确定具体错误类型。package mainimport ( &quot;errors&quot; &quot;fmt&quot;)var ErrDivByZero = errors.New(&quot;division by zero&quot;)func div(x, y int) (int, error) &#123; if y == 0 &#123; return 0, ErrDivByZero &#125; return x / y, nil&#125;func main() &#123; defer func() &#123; fmt.Println(recover()) &#125;() switch z, err := div(10, 0); err &#123; case nil: println(z) case ErrDivByZero: panic(err) &#125;&#125;//outdivision by zero Go实现类似Java try-Catch的异常处理 1234567891011121314151617181920package mainimport &quot;fmt&quot;func Try(fun func(), handler func(interface&#123;&#125;)) &#123; defer func() &#123; if err := recover(); err != nil &#123; handler(err) &#125; &#125;() fun()&#125;func main() &#123; Try(func() &#123; panic(&quot;test panic&quot;) &#125;, func(err interface&#123;&#125;) &#123; fmt.Println(err) &#125;)&#125; panic和error两种方式的使用区别:导致关键流程出现不可修复性错误的使用 panic，其他使用 error。","categories":[],"tags":[{"name":"go语言基础","slug":"go语言基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"}]},{"title":"go语言基础 - 流程控制","slug":"goyu","date":"2021-11-24T17:06:47.000Z","updated":"2021-11-24T18:11:19.634Z","comments":true,"path":"2021/11/25/goyu/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/25/goyu/","excerpt":"","text":"流程控制条件语句if不支持三元运算操作符 a &gt; b ? a : b 语法： 1234567• 可省略条件表达式括号。 • 持初始化语句，可定义代码块局部变量。 • 代码块左 括号必须在条件表达式尾部。 if 布尔表达式 &#123; /* 在布尔表达式为 true 时执行 */ &#125; 使用: 1234567if n := &quot;abc&quot;; x &gt; 0 &#123; // 初始化语句未必就是定义变量， 如 println(&quot;init&quot;) 也是可以的。 println(n[2])&#125; else if x &lt; 0 &#123; // 注意 else if 和 else 左大括号位置。 println(n[1])&#125; else &#123; println(n[0])&#125; 条件语句switch语法: 可省略break 123456789101112131415/* Go的switch非常灵活，表达式不必是常量或整数，执行的过程从上至下，直到找到匹配项； 而如果switch没有表达式，它会匹配true。 Go里面switch默认相当于每个case最后带有break， 匹配成功后不会自动向下执行其他case，而是跳出整个switch, 但是可以使用fallthrough强制执行后面的case代码。 */switch var1 &#123; case val1: ... case val2: ... default: ...&#125; Type Switch使用：switch 语句还可以被用于 type-switch 来判断某个 interface 变量中实际存储的变量类型 123456789switch x.(type)&#123; case type: statement(s) case type: statement(s) /* 你可以定义任意个数的case */ default: /* 可选 */ statement(s)&#125; 使用： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374var x interface&#123;&#125; //写法一： switch i := x.(type) &#123; // 带初始化语句 case nil: fmt.Printf(&quot; x 的类型 :%T\\r\\n&quot;, i) case int: fmt.Printf(&quot;x 是 int 型&quot;) case float64: fmt.Printf(&quot;x 是 float64 型&quot;) case func(int) float64: fmt.Printf(&quot;x 是 func(int) 型&quot;) case bool, string: fmt.Printf(&quot;x 是 bool 或 string 型&quot;) default: fmt.Printf(&quot;未知型&quot;) &#125; //写法二 var j = 0 switch j &#123; case 0: case 1: fmt.Println(&quot;1&quot;) case 2: fmt.Println(&quot;2&quot;) default: fmt.Println(&quot;def&quot;) &#125; //写法三 var k = 0 switch k &#123; case 0: println(&quot;fallthrough&quot;) fallthrough /* Go的switch非常灵活，表达式不必是常量或整数，执行的过程从上至下，直到找到匹配项； 而如果switch没有表达式，它会匹配true。 Go里面switch默认相当于每个case最后带有break， 匹配成功后不会自动向下执行其他case，而是跳出整个switch, 但是可以使用fallthrough强制执行后面的case代码。 */ case 1: fmt.Println(&quot;1&quot;) case 2: fmt.Println(&quot;2&quot;) default: fmt.Println(&quot;def&quot;) &#125; //写法三 var m = 0 switch m &#123; case 0, 1: fmt.Println(&quot;1&quot;) case 2: fmt.Println(&quot;2&quot;) default: fmt.Println(&quot;def&quot;) &#125; //写法四 var n = 0 switch &#123; //省略条件表达式，可当 if...else if...else case n &gt; 0 &amp;&amp; n &lt; 10: fmt.Println(&quot;i &gt; 0 and i &lt; 10&quot;) case n &gt; 10 &amp;&amp; n &lt; 20: fmt.Println(&quot;i &gt; 10 and i &lt; 20&quot;) default: fmt.Println(&quot;def&quot;) &#125; //outx 的类型 :&lt;nil&gt;fallthrough11def 条件语句selectselect 语句类似于 switch 语句，但是select会随机执行一个可运行的case。如果没有case可运行，它将阻塞，直到有case可运行。 select 是Go中的一个控制结构，类似于用于通信的switch语句。每个case必须是一个通信操作，要么是发送要么是接收。 select 随机执行一个可运行的case。如果没有case可运行，它将阻塞，直到有case可运行。一个默认的子句应该总是可运行的。 语法： 123456789101112131415161718每个case都必须是一个通信所有channel表达式都会被求值所有被发送的表达式都会被求值如果任意某个通信可以进行，它就执行；其他被忽略。如果有多个case都可以运行，Select会随机公平地选出一个执行。其他不会执行。否则：如果有default子句，则执行该语句。如果没有default字句，select将阻塞，直到某个通信可以运行；Go不会重新对channel或值进行求值。select &#123; case communication clause : statement(s); case communication clause : statement(s); /* 你可以定义任意数量的 case */ default : /* 可选 */ statement(s);&#125; 使用和典型用法： select是Go中的一个控制结构，类似于switch语句，用于处理异步IO操作。select会监听case语句中channel的读写操作，当case中channel读写操作为非阻塞状态（即能读写）时，将会触发相应的动作。 select中的case语句必须是一个channel操作 select中的default子句总是可运行的。 如果有多个case都可以运行，select会随机公平地选出一个执行，其他不会执行。 如果没有可运行的case语句，且有default语句，那么就会执行default的动作。 如果没有可运行的case语句，且没有default语句，select将阻塞，直到某个case通信可以运行 正常使用 123456789101112131415161718192021222324package mainimport &quot;fmt&quot;func main() &#123; var c1, c2, c3 chan int var i1, i2 int select &#123; case i1 = &lt;-c1: fmt.Printf(&quot;received &quot;, i1, &quot; from c1\\n&quot;) case c2 &lt;- i2: fmt.Printf(&quot;sent &quot;, i2, &quot; to c2\\n&quot;) case i3, ok := (&lt;-c3): // same as: i3, ok := &lt;-c3 if ok &#123; fmt.Printf(&quot;received &quot;, i3, &quot; from c3\\n&quot;) &#125; else &#123; fmt.Printf(&quot;c3 is closed\\n&quot;) &#125; default: fmt.Printf(&quot;no communication\\n&quot;) &#125; &#125;//输出：no communication 超时判断 123456789101112131415//比如在下面的场景中，使用全局resChan来接受response，如果时间超过3S,resChan中还没有数据返回，则第二条case将执行var resChan = make(chan int)// do requestfunc test() &#123; select &#123; case data := &lt;-resChan: doData(data) case &lt;-time.After(time.Second * 3): fmt.Println(&quot;request time out&quot;) &#125;&#125;func doData(data int) &#123; //...&#125; 退出 123456789101112131415161718//主线程（协程）中如下：var shouldQuit=make(chan struct&#123;&#125;)fun main()&#123; &#123; //loop &#125; //...out of the loop select &#123; case &lt;-c.shouldQuit: cleanUp() return default: &#125; //...&#125;//再另外一个协程中，如果运行遇到非法操作或不可处理的错误，就向shouldQuit发送数据通知程序停止运行close(shouldQuit) 判断channel是否阻塞 123456789//在某些情况下是存在不希望channel缓存满了的需求的，可以用如下方法判断ch := make (chan int, 5)//...data：=0select &#123;case ch &lt;- data:default: //做相应操作，比如丢弃data。视需求而定&#125; 循环语句for语法：没有while，go的for同时承担for和while的职责 123456789for init; condition; post &#123; &#125;for condition &#123; &#125;for &#123; &#125;init： 一般为赋值表达式，给控制变量赋初值；condition： 关系表达式或逻辑表达式，循环控制条件；post： 一般为赋值表达式，给控制变量增量或减量。for语句执行过程如下：①先对表达式 init 赋初值；②判别赋值表达式 init 是否满足给定 condition 条件，若其值为真，满足循环条件，则执行循环体内语句，然后执行 post，进入第二次循环，再判别 condition；否则判断 condition 的值为假，不满足条件，就终止for循环，执行循环体外语句。 使用： 123456789101112131415s := &quot;abc&quot;for i, n := 0, len(s); i &lt; n; i++ &#123; // 常见的 for 循环，支持初始化语句。 println(s[i])&#125;n := len(s)for n &gt; 0 &#123; // 替代 while (n &gt; 0) &#123;&#125; println(s[n]) // 替代 for (; n &gt; 0;) &#123;&#125; n-- &#125;for &#123; // 替代 while (true) &#123;&#125; println(s) // 替代 for (;;) &#123;&#125;&#125; 注意点：在初始化语句中计算出全部结果比较合适，编译器不一定能优化到 1234567891011121314151617181920func forTest2() &#123; s := &quot;abcd&quot; for i, n := 0, length(s); i &lt; n; i++ &#123; // 避免多次调用 length 函数。 //println(i, s[i]) &#125; fmt.Println(&quot;next out&quot;) for i := 0; i &lt; length(s); i++ &#123; //println(i, s[i]) &#125;&#125;//outcall length.next outcall length.call length.call length.call length.call length. 使用： 12345678910111213141516171819202122var b int = 15var a intnumbers := [6]int&#123;1, 2, 3, 5&#125;/* for 循环 */for a := 0; a &lt; 10; a++ &#123; fmt.Printf(&quot;a 的值为: %d\\n&quot;, a)&#125;for a &lt; b &#123; a++ fmt.Printf(&quot;a 的值为: %d\\n&quot;, a)&#125;for i,x:= range numbers &#123; fmt.Printf(&quot;第 %d 位 x 的值 = %d\\n&quot;, i,x)&#125;for true &#123; fmt.Printf(&quot;这是无限循环。\\n&quot;);&#125; 循环语句range语法： Golang range类似迭代器操作，返回 (索引, 值) 或 (键, 值)。 for 循环的 range 格式可以对 slice、map、数组、字符串等进行迭代循环。格式如下： 123for key, value := range oldMap &#123; newMap[key] = value&#125; 使用: 12345678910111213141516171819s := &quot;abc&quot;// 忽略 2nd value，支持 string/array/slice/map。for i := range s &#123; println(s[i])&#125;// 忽略 index。for _, c := range s &#123; println(c)&#125;// 忽略全部返回值，仅迭代。for range s &#123;&#125;m := map[string]int&#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125;// 返回 (key, value)。for k, v := range m &#123; println(k, v)&#125; 特点：range遍历时会拷贝对象 123456789101112131415161718192021222324package mainimport &quot;fmt&quot;func main() &#123; a := [3]int&#123;0, 1, 2&#125; for i, v := range a &#123; // index、value 都是从复制品中取出。 if i == 0 &#123; // 在修改前，我们先修改原数组。 a[1], a[2] = 999, 999 fmt.Println(a) // 确认修改有效，输出 [0, 999, 999]。 &#125; a[i] = v + 100 // 使用复制品中取出的 value 修改原数组。 &#125; fmt.Println(a) // 输出 [100, 101, 102]。&#125;//out[0 999 999][100 101 102]修改时，使用a[index]来修改 for和for range的区别： for可以 遍历array和slice 遍历key为整型递增的map 遍历string for range可以完成所有for可以做的事情，却能做到for不能做的，包括 遍历key为string类型的map并同时获取key和value 遍历channel 循环控制Goto,Break,Continue 三个语句都可以配合标签（label）使用 标签名区分大小写，定以后不使用会造成编译错误 Continue, Break可以配合标签（label）用于多层循环的跳出 Goto是调整执行的位置","categories":[],"tags":[]},{"title":"go语言基础 - 结构体","slug":"go语言基础-结构体","date":"2021-11-23T16:43:48.000Z","updated":"2021-11-23T18:23:31.521Z","comments":true,"path":"2021/11/24/go语言基础-结构体/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/24/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80-%E7%BB%93%E6%9E%84%E4%BD%93/","excerpt":"","text":"结构体Go语言中没有“类”的概念，也不支持“类”的继承等面向对象的概念。Go语言中通过结构体的内嵌再配合接口实现类似面向对象的效果 类型别名和自定义类型自定义类型Go语言中可以使用type关键字来定义自定义类型。 自定义类型是定义了一个全新的类型。我们可以基于内置的基本类型定义，也可以通过struct定义。 1type MyInt int 通过Type关键字的定义，MyInt就是一种新的类型，它具有int的特性。 类型别名类型别名规定：TypeAlias只是Type的别名，本质上TypeAlias与Type是同一个类型。就像一个孩子小时候有小名、乳名，上学后用学名，英语老师又会给他起英文名，但这些名字都指的是他本人。 12345type TypeAlias = Type//基本类型rune和byte就是类型别名type byte = uint8type rune = int32 自定义类型与类型别名的区别自定义类型是真正的类型，类型别名之后再代码中存在，编译完成不会再有 12345678910111213//类型定义type NewInt int//类型别名type MyInt = intfunc main() &#123; var a NewInt var b MyInt fmt.Printf(&quot;type of a:%T\\n&quot;, a) //type of a:main.NewInt fmt.Printf(&quot;type of b:%T\\n&quot;, b) //type of b:int&#125; 结构体定义1234567891011121314151617181920type 类型名 struct &#123; 字段名 字段类型 字段名 字段类型 … &#125;1.类型名：标识自定义结构体的名称，在同一个包内不能重复。2.字段名：表示结构体字段名。结构体中的字段名必须唯一。3.字段类型：表示结构体字段的具体类型。//使用type person struct &#123; name string city string age int8&#125;//同种类型可以写在同一行type person1 struct &#123; name, city string age int8&#125; 实例化只有当结构体实例化时，才会真正地分配内存。也就是必须实例化后才能使用结构体的字段。 声明 12var 结构体实例 结构体类型结构体本身也是一种类型，我们可以像声明内置类型一样使用var关键字声明结构体类型 基本实例化 12345678910111213141516type person struct &#123; name string city string age int8&#125;func main() &#123; var p1 person p1.name = &quot;pprof.cn&quot; p1.city = &quot;北京&quot; p1.age = 18 fmt.Printf(&quot;p1=%v\\n&quot;, p1) //p1=&#123;pprof.cn 北京 18&#125; fmt.Printf(&quot;p1=%#v\\n&quot;, p1) //p1=main.person&#123;name:&quot;pprof.cn&quot;, city:&quot;北京&quot;, age:18&#125;&#125;//可以通过.来访问结构体字段 匿名结构体在定义一些临时的数据结构场景下可以使用匿名结构体 123var user struct&#123;Name string; Age int&#125;user.Name = &quot;pprof.cn&quot;user.Age = 18 实例化和初始化 创建指针类型结构体 123456789101112//使用new关键字对结构体进行实例化，得到结构体的地址var p2 = new(person)fmt.Printf(&quot;%T\\n&quot;, p2) //*main.personfmt.Printf(&quot;p2=%#v\\n&quot;, p2) //p2=&amp;main.person&#123;name:&quot;&quot;, city:&quot;&quot;, age:0&#125;//Go语言中支持对结构体指针直接使用.来访问结构体的成员//p2.name = &quot;测试&quot; 在底层实现为(*p2).name = &quot;测试&quot;，这里是Go实现的语法糖var p2 = new(person)p2.name = &quot;测试&quot;p2.age = 18p2.city = &quot;北京&quot;fmt.Printf(&quot;p2=%#v\\n&quot;, p2) //p2=&amp;main.person&#123;name:&quot;测试&quot;, city:&quot;北京&quot;, age:18&#125; 取结构体的地址实例化 12345678//&amp;对结构体进行取地址操作相当于对该结构体类型进行了一次new实例化操作p3 := &amp;person&#123;&#125;fmt.Printf(&quot;%T\\n&quot;, p3) //*main.personfmt.Printf(&quot;p3=%#v\\n&quot;, p3) //p3=&amp;main.person&#123;name:&quot;&quot;, city:&quot;&quot;, age:0&#125;p3.name = &quot;博客&quot;p3.age = 30p3.city = &quot;成都&quot;fmt.Printf(&quot;p3=%#v\\n&quot;, p3) //p3=&amp;main.person&#123;name:&quot;博客&quot;, city:&quot;成都&quot;, age:30&#125; 初始化 1234567891011121314151617181920212223242526272829303132结构体初始化：type person struct &#123; name string city string age int8&#125;var p4 person //什么后初始化值默认为各类型的0fmt.Printf(&quot;p4=%#v\\n&quot;, p4) //p4=main.person&#123;name:&quot;&quot;, city:&quot;&quot;, age:0&#125;键值对初始化：p5 := person&#123; //结构体键值对初始化 name: &quot;pprof.cn&quot;, city: &quot;北京&quot;, age: 18,&#125;p6 := &amp;person&#123; //结构体指针键值对初始化 name: &quot;pprof.cn&quot;, city: &quot;北京&quot;, age: 18,&#125;p7 := &amp;person&#123; //只对指定key初始化，其他字段默认0值 city: &quot;北京&quot;,&#125;使用值的列表初始化：注意：1. 必须初始化结构体的所有字段。2. 初始值的填充顺序必须与字段在结构体中的声明顺序一致。3. 该方式不能和键值初始化方式混用。p8 := &amp;person&#123; &quot;pprof.cn&quot;, &quot;北京&quot;, 18,&#125; 结构体内存布局： 123456789101112131415161718192021type test struct &#123; a int8 b int8 c int8 d int8&#125;n := test&#123; 1, 2, 3, 4,&#125;fmt.Printf(&quot;n.a %p\\n&quot;, &amp;n.a)fmt.Printf(&quot;n.b %p\\n&quot;, &amp;n.b)fmt.Printf(&quot;n.c %p\\n&quot;, &amp;n.c)fmt.Printf(&quot;n.d %p\\n&quot;, &amp;n.d)//outn.a 0xc0000a0060n.b 0xc0000a0061n.c 0xc0000a0062n.d 0xc0000a0063为连续的内存地址 构造函数: Go语言的结构体没有构造函数，我们可以自己实现。 例如，下方的代码就实现了一个person的构造函数。 因为struct是值类型，如果结构体比较复杂的话，值拷贝性能开销会比较大，所以该构造函数返回的是结构体指针类型。 12345678910func newPerson(name, city string, age int8) *person &#123; return &amp;person&#123; name: name, city: city, age: age, &#125;&#125;//usep9 := newPerson(&quot;pprof.cn&quot;, &quot;测试&quot;, 90) 使用的问题 123456789101112131415161718192021222324252627282930func structInit( ) &#123; type student struct &#123; name string age int &#125; m := make(map[string]*student) studs := []student&#123; &#123;name: &quot;a&quot;,age: 18&#125;, &#123;name: &quot;b&quot;,age: 19&#125;, &#123;name: &quot;c&quot;,age: 20&#125;, &#125; for _, stu := range studs &#123; //因为stu是值拷贝的形式，所有最终的value都是拷贝的地址，即最后的value m[stu.name] = &amp;stu &#125; fmt.Println(m) for k, v := range m &#123; fmt.Println(k,&quot;=&gt;&quot;,v.name) &#125;&#125;//outmap[a:0xc00000c060 b:0xc00000c060 c:0xc00000c060]a =&gt; cb =&gt; cc =&gt; c//正确使用for i, stu := range studs &#123; //因为stu是值拷贝的形式，所有最终的value都是拷贝的地址，即最后的value m[stu.name] = &amp;studs[i] &#125; 方法和接受者Go语言中的方法（Method）是一种作用于特定类型变量的函数。这种特定类型变量叫做接收者（Receiver）。接收者的概念就类似于其他语言中的this或者 self。 方法与函数的区别：函数不属于任何类型，方法属于特定的类型 基本定义和使用： 123456789101112131415161718192021222324252627282930313233//定义func (接收者变量 接收者类型) 方法名(参数列表) (返回参数) &#123; 函数体 &#125;//注意事项1.接收者变量：接收者中的参数变量名在命名时，官方建议使用接收者类型名的第一个小写字母，而不是self、this之类的命名。例如，Person类型的接收者变量应该命名为 p，Connector类型的接收者变量应该命名为c等。2.接收者类型：接收者类型和参数类似，可以是指针类型和非指针类型。3.方法名、参数列表、返回参数：具体格式与函数定义相同。//eg://Person 结构体type Person struct &#123; name string age int8&#125;//NewPerson 构造函数func NewPerson(name string, age int8) *Person &#123; return &amp;Person&#123; name: name, age: age, &#125;&#125;//Dream Person做梦的方法func (p Person) Dream() &#123; fmt.Printf(&quot;%s的梦想是学好Go语言！\\n&quot;, p.name)&#125;func main() &#123; p1 := NewPerson(&quot;测试&quot;, 25) p1.Dream()&#125; 指针类型的接受者和值类型的接受者 区别： 指针类型：指针类型的接收者由一个结构体的指针组成，由于指针的特性，调用方法时修改接收者指针的任意成员变量，在方法结束后，修改都是有效的。这种方式就十分接近于其他语言中面向对象中的this或者self。 值类型：当方法作用于值类型接收者时，Go语言会在代码运行时将接收者的值复制一份。在值类型接收者的方法中可以获取接收者的成员值，但修改操作只是针对副本，无法修改接收者变量本身。 1234567891011121314//指针类型接受者func (p *Person) SetAge(newAge int8) &#123; p.age = newAge &#125;//值类型接受者func (p Person) SetAge2(newAge int8) &#123; p.age = newAge&#125;什么时候选择指针类型接收者: 1.需要修改接收者中的值 2.接收者是拷贝代价比较大的大对象 3.保证一致性，如果有某个方法使用了指针接收者，那么其他的方法也应该使用指针接收者。 任意类型添加方法： 在Go语言中，接收者的类型可以是任何类型，不仅仅是结构体，任何类型都可以拥有方法。 注意事项： 非本地类型不能定义方法，也就是说我们不能给别的包的类型定义方法。 12345678910111213//MyInt 将int定义为自定义MyInt类型type MyInt int//SayHello 为MyInt添加一个SayHello的方法func (m MyInt) SayHello() &#123; fmt.Println(&quot;Hello, 我是一个int。&quot;)&#125;func main() &#123; var m1 MyInt m1.SayHello() //Hello, 我是一个int。 m1 = 100 fmt.Printf(&quot;%#v %T\\n&quot;, m1, m1) //100 main.MyInt&#125; 结构体其他特性匿名字段结构体允许其成员字段在声明时没有字段名而只有类型，这种没有名字的字段就称为匿名字段。 匿名字段默认采用类型名作为字段名，结构体要求字段名称必须唯一，因此一个结构体中同种类型的匿名字段只能有一个。 123456789101112//Person 结构体Person类型type Person struct &#123; string int&#125;p1 := Person&#123; &quot;pprof.cn&quot;, 18,&#125;fmt.Printf(&quot;%#v\\n&quot;, p1) //main.Person&#123;string:&quot;pprof.cn&quot;, int:18&#125;fmt.Println(p1.string, p1.int) //pprof.cn 18 嵌套结构体一个结构体中可以嵌套包含另一个结构体或结构体指针。 123456789101112131415161718192021222324//Address 地址结构体type Address struct &#123; Province string City string&#125;//User 用户结构体type User struct &#123; Name string Gender string Address Address&#125;func main() &#123; user1 := User&#123; Name: &quot;pprof&quot;, Gender: &quot;女&quot;, Address: Address&#123; Province: &quot;黑龙江&quot;, City: &quot;哈尔滨&quot;, &#125;, &#125; fmt.Printf(&quot;user1=%#v\\n&quot;, user1)//user1=main.User&#123;Name:&quot;pprof&quot;, Gender:&quot;女&quot;, Address:main.Address&#123;Province:&quot;黑龙江&quot;, City:&quot;哈尔滨&quot;&#125;&#125;&#125; 12345678910111213141516171819202122232425//嵌套匿名结构体//Address 地址结构体type Address struct &#123; Province string City string&#125;//User 用户结构体type User struct &#123; Name string Gender string Address //匿名结构体&#125;func main() &#123; var user2 User user2.Name = &quot;pprof&quot; user2.Gender = &quot;女&quot; user2.Address.Province = &quot;黑龙江&quot; //通过匿名结构体.字段名访问 user2.City = &quot;哈尔滨&quot; //直接访问匿名结构体的字段名 fmt.Printf(&quot;user2=%#v\\n&quot;, user2) //user2=main.User&#123;Name:&quot;pprof&quot;, Gender:&quot;女&quot;, Address:main.Address&#123;Province:&quot;黑龙江&quot;, City:&quot;哈尔滨&quot;&#125;&#125; //当访问结构体成员时会先在结构体中查找该字段，找不到再去匿名结构体中查找。&#125; 嵌套结构体的字段名冲突嵌套结构体内部可能存在相同的字段名。这个时候为了避免歧义需要指定具体的内嵌结构体的字段。 1234567891011121314151617181920212223242526272829//Address 地址结构体type Address struct &#123; Province string City string CreateTime string&#125;//Email 邮箱结构体type Email struct &#123; Account string CreateTime string&#125;//User 用户结构体type User struct &#123; Name string Gender string Address Email&#125;func main() &#123; var user3 User user3.Name = &quot;pprof&quot; user3.Gender = &quot;女&quot; // user3.CreateTime = &quot;2019&quot; //ambiguous selector user3.CreateTime user3.Address.CreateTime = &quot;2000&quot; //指定Address结构体中的CreateTime user3.Email.CreateTime = &quot;2000&quot; //指定Email结构体中的CreateTime&#125; 结构体中的“继承”1234567891011121314151617181920212223242526272829//Animal 动物type Animal struct &#123; name string&#125;func (a *Animal) move() &#123; fmt.Printf(&quot;%s会动！\\n&quot;, a.name)&#125;//Dog 狗type Dog struct &#123; Feet int8 *Animal //通过嵌套匿名结构体实现继承&#125;func (d *Dog) wang() &#123; fmt.Printf(&quot;%s会汪汪汪~\\n&quot;, d.name)&#125;func main() &#123; d1 := &amp;Dog&#123; Feet: 4, Animal: &amp;Animal&#123; //注意嵌套的是结构体指针 name: &quot;乐乐&quot;, &#125;, &#125; d1.wang() //乐乐会汪汪汪~ d1.move() //乐乐会动！&#125; 结构体的可见性结构体中字段大写开头表示可公开访问，小写表示私有（仅在定义当前结构体的包中可访问）。 结构体与JSON序列化12345678910111213141516171819202122232425262728293031323334353637383940414243//Student 学生type Student struct &#123; ID int Gender string Name string&#125;//Class 班级type Class struct &#123; Title string Students []*Student&#125;func main() &#123; c := &amp;Class&#123; Title: &quot;101&quot;, Students: make([]*Student, 0, 200), &#125; for i := 0; i &lt; 10; i++ &#123; stu := &amp;Student&#123; Name: fmt.Sprintf(&quot;stu%02d&quot;, i), Gender: &quot;男&quot;, ID: i, &#125; c.Students = append(c.Students, stu) &#125; //JSON序列化：结构体--&gt;JSON格式的字符串 data, err := json.Marshal(c) if err != nil &#123; fmt.Println(&quot;json marshal failed&quot;) return &#125; fmt.Printf(&quot;json:%s\\n&quot;, data) //JSON反序列化：JSON格式的字符串--&gt;结构体 str := `&#123;&quot;Title&quot;:&quot;101&quot;,&quot;Students&quot;:[&#123;&quot;ID&quot;:0,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu00&quot;&#125;,&#123;&quot;ID&quot;:1,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu01&quot;&#125;,&#123;&quot;ID&quot;:2,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu02&quot;&#125;,&#123;&quot;ID&quot;:3,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu03&quot;&#125;,&#123;&quot;ID&quot;:4,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu04&quot;&#125;,&#123;&quot;ID&quot;:5,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu05&quot;&#125;,&#123;&quot;ID&quot;:6,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu06&quot;&#125;,&#123;&quot;ID&quot;:7,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu07&quot;&#125;,&#123;&quot;ID&quot;:8,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu08&quot;&#125;,&#123;&quot;ID&quot;:9,&quot;Gender&quot;:&quot;男&quot;,&quot;Name&quot;:&quot;stu09&quot;&#125;]&#125;` c1 := &amp;Class&#123;&#125; err = json.Unmarshal([]byte(str), c1) if err != nil &#123; fmt.Println(&quot;json unmarshal failed!&quot;) return &#125; fmt.Printf(&quot;%#v\\n&quot;, c1)&#125; 结构体TagTag是结构体的元信息，可以在运行的时候通过反射的机制读取出来。 Tag在结构体字段的后方定义，由一对反引号包裹起来，具体的格式如下： 1`key1:&quot;value1&quot; key2:&quot;value2&quot;` 结构体标签由一个或多个键值对组成。键与值使用冒号分隔，值用双引号括起来。键值对之间使用一个空格分隔。 注意事项： 为结构体编写Tag时，必须严格遵守键值对的规则。结构体标签的解析代码的容错能力很差，一旦格式写错，编译和运行时都不会提示任何错误，通过反射也无法正确取值。例如不要在key和value之间添加空格。 1234567891011121314151617181920//Student 学生type Student struct &#123; ID int `json:&quot;id&quot;` //通过指定tag实现json序列化该字段时的key Gender string //json序列化是默认使用字段名作为key name string //私有不能被json包访问&#125;func main() &#123; s1 := Student&#123; ID: 1, Gender: &quot;女&quot;, name: &quot;pprof&quot;, &#125; data, err := json.Marshal(s1) if err != nil &#123; fmt.Println(&quot;json marshal failed!&quot;) return &#125; fmt.Printf(&quot;json str:%s\\n&quot;, data) //json str:&#123;&quot;id&quot;:1,&quot;Gender&quot;:&quot;女&quot;&#125;&#125;","categories":[],"tags":[{"name":"go语言基础","slug":"go语言基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"}]},{"title":"go基础 - Map","slug":"go基础-Map","date":"2021-11-21T17:26:01.000Z","updated":"2022-01-11T12:31:32.954Z","comments":true,"path":"2021/11/22/go基础-Map/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/22/go%E5%9F%BA%E7%A1%80-Map/","excerpt":"","text":"Map及其底层实现map是一种无序的基于key-value的数据结构，Go语言中的map是引用类型，必须初始化才能使用。 实现是一种hashmap。 map定义：123456789map[KeyType]ValueTypeKeyType:表示键的类型。ValueType:表示键对应的值的类型。map类型的变量默认初始值为nil，需要使用make()函数来分配内存。make(map[KeyType]ValueType, [cap]) map基本使用：12345678scoreMap := make(map[string]int, 8)scoreMap[&quot;张三&quot;] = 90scoreMap[&quot;小明&quot;] = 100userInfo := map[string]string&#123; &quot;username&quot;: &quot;pprof.cn&quot;, &quot;password&quot;: &quot;123456&quot;, &#125; 判断某个key是否存在12345678910111213value, ok := map[key]scoreMap := make(map[string]int)scoreMap[&quot;张三&quot;] = 90scoreMap[&quot;小明&quot;] = 100// 如果key存在ok为true,v为对应的值；不存在ok为false,v为值类型的零值v, ok := scoreMap[&quot;张三&quot;]if ok &#123; fmt.Println(v)&#125; else &#123; fmt.Println(&quot;查无此人&quot;)&#125; map的遍历123for k, v := range scoreMap &#123; fmt.Println(k, v) &#125; 删除键值对1delete(map, key) Go中Map的实现原理：map是通过数组存储，数组下标出存储的是一个bucket,每个bucket可以存储8个kv对，当存满8个以后，会通过overflow指针指向一个新的bucket，形成一个链表 tophash用于快速查找key值是否在该bucket，存储结构为kkk vvv是因为，比如map[int64]int8，由于kv的长度不同，如果按照kv存储，考虑到内存对齐，v也需要int64，但是按照kkkvvv，则8个v刚好占用一个int64 overflow是链表法解决key的hash冲突问题 具体情况： 当往map存储一个kv对时，通过k获取hash值，hash值的低八位与bucket数组长度取余，定位到数组的下标，hash值的高八位存储在bucket的tophash中，快速判断是否存在key，kv的具体值则是通过指针运算存储，当bucket满时会自动通过overflow链接到下一个bucket 补充：在运行期间，runtime.bmap 结构体其实不止包含 tophash 字段，因为哈希表中可能存储不同类型的键值对，而且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导。runtime.bmap 中的其他字段在运行时也都是通过计算内存地址的方式访问的，所以它的定义中就不包含这些字段，不过我们能根据编译期间的 cmd/compile/internal/gc.bmap 函数重建它的结构： 1234567type bmap struct &#123; topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr&#125; 随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用额外的桶存储溢出的数据，不会让单个桶中的数据超过 8 个，不过溢出桶只是临时的解决方案，创建过多的溢出桶最终也会导致哈希的扩容。 go的map源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer &#123; //获取hash算法 alg := t.key.alg //计算hash值 hash := alg.hash(key, uintptr(h.hash0)) //如果bucket数组一开始为空，则初始化 if h.buckets == nil &#123; h.buckets = newobject(t.bucket) // newarray(t.bucket, 1) &#125;again: // 定位存储在哪一个bucket中 bucket := hash &amp; bucketMask(h.B) //得到bucket的结构体 b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) +bucket*uintptr(t.bucketsize))) //获取高八位hash值 top := tophash(hash) var inserti *uint8 var insertk unsafe.Pointer var val unsafe.Pointerbucketloop: //死循环 for &#123; //循环bucket中的tophash数组 for i := uintptr(0); i &lt; bucketCnt; i++ &#123; //如果hash不相等 if b.tophash[i] != top &#123; //判断是否为空，为空则插入 if isEmpty(b.tophash[i]) &amp;&amp; inserti == nil &#123; inserti = &amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) val = add( unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize) ) &#125; //插入成功，终止最外层循环 if b.tophash[i] == emptyRest &#123; break bucketloop &#125; continue &#125; //到这里说明高八位hash一样，获取已存在的key k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if t.indirectkey() &#123; k = *((*unsafe.Pointer)(k)) &#125; //判断两个key是否相等，不相等就循环下一个 if !alg.equal(key, k) &#123; continue &#125; // 如果相等则更新 if t.needkeyupdate() &#123; typedmemmove(t.key, k, key) &#125; //获取已存在的value val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) goto done &#125; //如果上一个bucket没能插入，则通过overflow获取链表上的下一个bucket ovf := b.overflow(t) if ovf == nil &#123; break &#125; b = ovf &#125; if inserti == nil &#123; // all current buckets are full, allocate a new one. newb := h.newoverflow(t, b) inserti = &amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) val = add(insertk, bucketCnt*uintptr(t.keysize)) &#125; // store new key/value at insert position if t.indirectkey() &#123; kmem := newobject(t.key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem &#125; if t.indirectvalue() &#123; vmem := newobject(t.elem) *(*unsafe.Pointer)(val) = vmem &#125; typedmemmove(t.key, insertk, key) //将高八位hash值存储 *inserti = top h.count++ return val&#125;","categories":[],"tags":[{"name":"go语言基础","slug":"go语言基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"}]},{"title":"go基础 - 指针","slug":"go基础-指针","date":"2021-11-21T17:07:25.000Z","updated":"2021-11-21T17:25:16.180Z","comments":true,"path":"2021/11/22/go基础-指针/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/22/go%E5%9F%BA%E7%A1%80-%E6%8C%87%E9%92%88/","excerpt":"","text":"指针Go中的指针类似Java中的指针，不能进行偏移和运算。 使用：&amp;（取地址）和 *（根据地址取值） 取变量指针：1234ptr := &amp;v // v的类型为Tv:代表被取地址的变量，类型为Tptr:用于接收地址的变量，ptr的类型就为*T，称做T的指针类型。*代表指针。 指针取值123456789101112131415func main() &#123; //指针取值 a := 10 b := &amp;a // 取变量a的地址，将指针保存到b中 fmt.Printf(&quot;type of b:%T\\n&quot;, b) c := *b // 指针取值（根据指针去内存取值） fmt.Printf(&quot;type of c:%T\\n&quot;, c) fmt.Printf(&quot;value of c:%v\\n&quot;, c)&#125;//outtype of b:*inttype of c:intvalue of c:10 123456789101112131415161718191.对变量进行取地址（&amp;）操作，可以获得这个变量的指针变量。2.指针变量的值是指针地址。3.对指针变量进行取值（*）操作，可以获得指针变量指向的原变量的值。func modify1(x int) &#123; x = 100&#125;func modify2(x *int) &#123; *x = 100&#125;func main() &#123; a := 10 modify1(a) fmt.Println(a) // 10 modify2(&amp;a) fmt.Println(a) // 100&#125; 空指针 当一个指针被定义后没有分配到任何变量时，它的值为 nil 空指针的判断 p == nil new和make new - 用于分配内存 1234567891011121314func new(Type) *Type1.Type表示类型，new函数只接受一个参数，这个参数是一个类型2.*Type表示类型指针，new函数返回一个指向该类型内存地址的指针。new函数不太常用，使用new函数得到的是一个类型的指针，并且该指针对应的值为该类型的零值。func main() &#123; a := new(int) b := new(bool) fmt.Printf(&quot;%T\\n&quot;, a) // *int fmt.Printf(&quot;%T\\n&quot;, b) // *bool fmt.Println(*a) // 0 fmt.Println(*b) // false&#125; Make - 用于分配内存 make也是用于内存分配的，区别于new，它只用于slice、map以及chan的内存创建，而且它返回的类型就是这三个类型本身，而不是他们的指针类型，因为这三种类型就是引用类型。 12345678func make(t Type, size ...IntegerType) Typefunc main() &#123; var b map[string]int b = make(map[string]int, 10) b[&quot;测试&quot;] = 100 fmt.Println(b)&#125; 对比： 1231.二者都是用来做内存分配的。2.make只用于slice、map以及channel的初始化，返回的还是这三个引用类型本身；3.而new用于类型的内存分配，并且内存对应的值为类型零值，返回的是指向类型的指针。","categories":[],"tags":[{"name":"go语言基础","slug":"go语言基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"}]},{"title":"go基础 - Slice实现","slug":"go基础-Slice实现","date":"2021-11-21T14:09:57.000Z","updated":"2021-11-21T17:06:51.904Z","comments":true,"path":"2021/11/21/go基础-Slice实现/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/21/go%E5%9F%BA%E7%A1%80-Slice%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"Slice底层实现切片与数组的对比切片是引用类型，数组是值类型，大数组的传递会消耗较多的内存，且性能差，这种场景下使用切片更合适。 反例： 因为切片底层数组可能会在堆上分配内存，小数组在栈上拷贝的消耗不一定比make大 123456789101112131415161718192021222324252627282930313233// go test -bench . -benchmem -gcflags &quot;-N -l&quot;// 禁用内联和优化package mainimport &quot;testing&quot;func array() [1024]int &#123; var x [1024]int for i := 0; i &lt; len(x); i++ &#123; x[i] = i &#125; return x&#125;func slice() []int &#123; x := make([]int, 1024) for i := 0; i &lt; len(x); i++ &#123; x[i] = i &#125; return x&#125;func BenchmarkArray(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; array() &#125;&#125;func BenchmarkSlice(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; slice() &#125;&#125; 1234结果：在测试 Array 的时候，用的是4核，循环次数是500000，平均每次执行时间是3637 ns，每次执行堆上分配内存总量是0，分配次数也是0 。而切片的结果就“差”一点，同样也是用的是4核，循环次数是300000，平均每次执行时间是4055 ns，但是每次执行一次，堆上分配内存总量是8192，分配次数也是1 。 切片的数据结构123456//切片是对数组的一个连续片段的引用type slice struct &#123; array unsafe.Pointer //指向一个数组的指针 len int //当前切片长度 cap int //当前切片容量 cap &gt;= len&#125; 1234567891011121314151617181920212223s := make([]byte, 200) ptr := unsafe.Pointer(&amp;s[0]) //从slice获取到一块内存地址 fmt.Println(ptr) //从go的内存地址构造一个slice var ptr1 unsafe.Pointer length := 10 var s1 = struct &#123; addr unsafe.Pointer len int cap int &#125;&#123;ptr1, length,length&#125; s2 := *(*[]byte)(unsafe.Pointer(&amp;s1)) fmt.Println(s2) //使用反射构造一个slice a := [...]int&#123;1,2,3&#125; var o []byte sliceHeader := (*reflect.SliceHeader)(unsafe.Pointer(&amp;o)) sliceHeader.Cap = length sliceHeader.Len = length sliceHeader.Data = uintptr(o) fmt.Println(sliceHeader) 切片创建make和切片字面量创建切片 12345678910111213141516func makeslice(et *_type, len, cap int) slice &#123; // 根据切片的数据类型，获取切片的最大容量 maxElements := maxSliceCap(et.size) // 比较切片的长度，长度值域应该在[0,maxElements]之间 if len &lt; 0 || uintptr(len) &gt; maxElements &#123; panic(errorString(&quot;makeslice: len out of range&quot;)) &#125; // 比较切片的容量，容量值域应该在[len,maxElements]之间 if cap &lt; len || uintptr(cap) &gt; maxElements &#123; panic(errorString(&quot;makeslice: cap out of range&quot;)) &#125; // 根据切片的容量申请内存 p := mallocgc(et.size*uintptr(cap), et, true) // 返回申请好内存的切片的首地址 return slice&#123;p, len, cap&#125;&#125; nil和空切片nil 切片被用在很多标准库和内置函数中，描述一个不存在的切片的时候，就需要用到 nil 切片。比如函数在发生异常的时候，返回的切片就是 nil 切片。nil 切片的指针指向 nil。 空切片一般会用来表示一个空的集合。比如数据库查询，一条结果也没有查到，那么就可以返回一个空切片。 区别：空切片指向的地址不是nil，而是指向一个内存地址，但是没有分配内存空间 但是无法nil还是空切片，使用append，len，cap的效果是一样的 切片的扩容策略： 切片如果容量小于1024个元素，会在扩容是翻倍增加容量，超过1024个时，会每次增加1/4。 扩容都是对当前容量来说。 新数组还是老数组：如果原数组还有容量可以扩容，执行append以后会直接在原数组执行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485func growslice(et *_type, old slice, cap int) slice &#123; if raceenabled &#123; callerpc := getcallerpc(unsafe.Pointer(&amp;et)) racereadrangepc(old.array, uintptr(old.len*int(et.size)), callerpc, funcPC(growslice)) &#125; if msanenabled &#123; msanread(old.array, uintptr(old.len*int(et.size))) &#125; if et.size == 0 &#123; // 如果新要扩容的容量比原来的容量还要小，这代表要缩容了，那么可以直接报panic了。 if cap &lt; old.cap &#123; panic(errorString(&quot;growslice: cap out of range&quot;)) &#125; // 如果当前切片的大小为0，还调用了扩容方法，那么就新生成一个新的容量的切片返回。 return slice&#123;unsafe.Pointer(&amp;zerobase), old.len, cap&#125; &#125; // 这里就是扩容的策略 newcap := old.cap doublecap := newcap + newcap if cap &gt; doublecap &#123; newcap = cap &#125; else &#123; if old.len &lt; 1024 &#123; newcap = doublecap &#125; else &#123; for newcap &lt; cap &#123; newcap += newcap / 4 &#125; &#125; &#125; // 计算新的切片的容量，长度。 var lenmem, newlenmem, capmem uintptr const ptrSize = unsafe.Sizeof((*byte)(nil)) switch et.size &#123; case 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) newcap = int(capmem) case ptrSize: lenmem = uintptr(old.len) * ptrSize newlenmem = uintptr(cap) * ptrSize capmem = roundupsize(uintptr(newcap) * ptrSize) newcap = int(capmem / ptrSize) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem = roundupsize(uintptr(newcap) * et.size) newcap = int(capmem / et.size) &#125; // 判断非法的值，保证容量是在增加，并且容量不超过最大容量 if cap &lt; old.cap || uintptr(newcap) &gt; maxSliceCap(et.size) &#123; panic(errorString(&quot;growslice: cap out of range&quot;)) &#125; var p unsafe.Pointer if et.kind&amp;kindNoPointers != 0 &#123; // 在老的切片后面继续扩充容量 p = mallocgc(capmem, nil, false) // 将 lenmem 这个多个 bytes 从 old.array地址 拷贝到 p 的地址处 memmove(p, old.array, lenmem) // 先将 P 地址加上新的容量得到新切片容量的地址，然后将新切片容量地址后面的 capmem-newlenmem 个 bytes 这块内存初始化。为之后继续 append() 操作腾出空间。 memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) &#125; else &#123; // 重新申请新的数组给新切片 // 重新申请 capmen 这个大的内存地址，并且初始化为0值 p = mallocgc(capmem, et, true) if !writeBarrier.enabled &#123; // 如果还不能打开写锁，那么只能把 lenmem 大小的 bytes 字节从 old.array 拷贝到 p 的地址处 memmove(p, old.array, lenmem) &#125; else &#123; // 循环拷贝老的切片的值 for i := uintptr(0); i &lt; lenmem; i += et.size &#123; typedmemmove(et, add(p, i), add(old.array, i)) &#125; &#125; &#125; // 返回最终新切片，容量更新为最新扩容之后的容量 return slice&#123;p, old.len, newcap&#125;&#125; 字面常量创建切片时，cap不等于执行数组的总容量时，通常可能会发生在原数组上扩容的情况： 在这种情况下，扩容以后并没有新建一个新的数组，扩容前后的数组都是同一个，这也就导致了新的切片修改了一个值，也影响到了老的切片了。并且 append() 操作也改变了原来数组里面的值。 切片拷贝：Slice的拷贝方法有两个： 在slicecopy中，会把源切片值中的元素复制到目标切片，并返回复制的元素个数，copy类型必须一致，长度取决于较短的那个。 1234567891011121314151617181920212223242526272829303132333435363738func slicecopy(to, fm slice, width uintptr) int &#123; // 如果源切片或者目标切片有一个长度为0，那么就不需要拷贝，直接 return if fm.len == 0 || to.len == 0 &#123; return 0 &#125; // n 记录下源切片或者目标切片较短的那一个的长度 n := fm.len if to.len &lt; n &#123; n = to.len &#125; // 如果入参 width = 0，也不需要拷贝了，返回较短的切片的长度 if width == 0 &#123; return n &#125; // 如果开启了竞争检测 if raceenabled &#123; callerpc := getcallerpc(unsafe.Pointer(&amp;to)) pc := funcPC(slicecopy) racewriterangepc(to.array, uintptr(n*int(width)), callerpc, pc) racereadrangepc(fm.array, uintptr(n*int(width)), callerpc, pc) &#125; // 如果开启了 The memory sanitizer (msan) if msanenabled &#123; msanwrite(to.array, uintptr(n*int(width))) msanread(fm.array, uintptr(n*int(width))) &#125; size := uintptr(n) * width if size == 1 &#123; // TODO: is this still worth it with new memmove impl? // 如果只有一个元素，那么指针直接转换即可 *(*byte)(to.array) = *(*byte)(fm.array) // known to be a byte pointer &#125; else &#123; // 如果不止一个元素，那么就把 size 个 bytes 从 fm.array 地址开始，拷贝到 to.array 地址之后 memmove(to.array, fm.array, size) &#125; return n&#125; Slicestringcopy 123456789101112131415161718192021222324func slicestringcopy(to []byte, fm string) int &#123; // 如果源切片或者目标切片有一个长度为0，那么就不需要拷贝，直接 return if len(fm) == 0 || len(to) == 0 &#123; return 0 &#125; // n 记录下源切片或者目标切片较短的那一个的长度 n := len(fm) if len(to) &lt; n &#123; n = len(to) &#125; // 如果开启了竞争检测 if raceenabled &#123; callerpc := getcallerpc(unsafe.Pointer(&amp;to)) pc := funcPC(slicestringcopy) racewriterangepc(unsafe.Pointer(&amp;to[0]), uintptr(n), callerpc, pc) &#125; // 如果开启了 The memory sanitizer (msan) if msanenabled &#123; msanwrite(unsafe.Pointer(&amp;to[0]), uintptr(n)) &#125; // 拷贝字符串至字节数组 memmove(unsafe.Pointer(&amp;to[0]), stringStructOf(&amp;fm).str, uintptr(n)) return n&#125; 使用range去遍历一个切片时如果用 range 的方式去遍历一个切片，拿到的 Value 其实是切片里面的值拷贝。所以每次打印 Value 的地址都不变。由于 Value 是值拷贝的，并非引用传递，所以直接改 Value 是达不到更改原切片值的目的的，需要通过 &amp;slice[index] 获取真实的地址。 123456789101112func main() &#123; slice := []int&#123;10, 20, 30, 40&#125; for index, value := range slice &#123; fmt.Printf(&quot;value = %d , value-addr = %x , slice-addr = %x\\n&quot;, value, &amp;value, &amp;slice[index]) &#125;&#125;//out value = 10 , value-addr = c4200aedf8 , slice-addr = c4200b0320 value = 20 , value-addr = c4200aedf8 , slice-addr = c4200b0328 value = 30 , value-addr = c4200aedf8 , slice-addr = c4200b0330 value = 40 , value-addr = c4200aedf8 , slice-addr = c4200b0338","categories":[],"tags":[{"name":"go语言基础","slug":"go语言基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"}]},{"title":"go基础 - 数组与切片","slug":"go基础-容器类型与结构体","date":"2021-11-04T16:50:31.000Z","updated":"2021-11-21T14:10:42.188Z","comments":true,"path":"2021/11/05/go基础-容器类型与结构体/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/11/05/go%E5%9F%BA%E7%A1%80-%E5%AE%B9%E5%99%A8%E7%B1%BB%E5%9E%8B%E4%B8%8E%E7%BB%93%E6%9E%84%E4%BD%93/","excerpt":"","text":"数组:1234561. 数组：定长的同一类型的序列2. 数组定义：var a [len]int 数组长度必须为常量，且是类型的组成部分，定义以后就不能修改。3. 长度是数组类型的一部分，var a[5] int和var a[6]int是不同类型（做参数和返回值都不通用）4. 数组是值类型，赋值和传参都会复制整个数组。5. 支持 == 和 != 操作符6. 指针数组 [n]*T 数组指针 *[n]T 数组初始化：12345678910111213141516171819202122232425262728import &quot;fmt&quot;//全局初始化var arr0 [5]int = [5]int&#123;1,2,3,4&#125;var arr1 = [5]int&#123;1,2,3,4,5&#125;var arr2 = [...]int&#123;1,2,3,4,5,6&#125;var str = [5]string&#123;3:&quot;hello world&quot;,4:&quot;tom&quot;&#125;func main() &#123; //局部 a := [3]int&#123;1,2&#125; //未初始化的元素为 default值（0） b := [...]int&#123;1,2,3,4&#125; //[...] 通过初始化值确定数组长度，只有这种使用手法 c := [5]int&#123;2:100,3:2&#125; // loc:值的方式可以初始化指定元素 d := [...]struct&#123; name string age uint8 &#125; &#123; &#123;&quot;user1&quot;,10&#125;, &#123;&quot;user2&quot;,20&#125;,//struct数组最后一行需要 , &#125; fmt.Println(arr0,arr1,arr2,str) fmt.Println(a,b,c,d)&#125;//out[1 2 3 4 0] [1 2 3 4 5] [1 2 3 4 5 6] [ hello world tom][1 2 0] [1 2 3 4] [0 0 100 2 0] [&#123;user1 10&#125; &#123;user2 20&#125;] 值拷贝1234567891011121314151617181920212223242526272829//全局var array0 [5][3]intvar array1 [2][3]int = [...][3]int&#123;&#123;1,2,3&#125;,&#123;4,5,6&#125;&#125;//值类型func testArray(x [2]int) &#123; fmt.Printf(&quot;x : %p\\n&quot;,&amp;x) x[1] = 1000&#125;func main() &#123; //局部 a := [2][3]int&#123;&#123;6,5,4&#125;,&#123;3,2,1&#125;&#125; b := [...][2]int&#123;&#123;1,1&#125;,&#123;2,2&#125;,&#123;3,3&#125;&#125; //第二纬不能使用 [...] fmt.Println(array0,&quot; : &quot;,array1) fmt.Println(a,&quot; : &quot;,b) num := [2]int&#123;1,2&#125; fmt.Printf(&quot;num: %p\\n&quot;,&amp;num) testArray(num) fmt.Println(num)&#125;//out[[0 0 0] [0 0 0] [0 0 0] [0 0 0] [0 0 0]] : [[1 2 3] [4 5 6]][[6 5 4] [3 2 1]] : [[1 1] [2 2] [3 3]]num: 0xc00018c020x : 0xc00018c030 使用数组指针：注意长度不同的数组也是不同的类型，即长度不同的数组指针不是同一类型 1234567891011121314151617181920212223242526272829func testArray2(arr *[5]int) &#123; arr[0] = 10 for i, v := range arr &#123; fmt.Println(i, v) &#125;&#125;func main() &#123; var arrayj [5]int; testArray2(&amp;arrayj) fmt.Println(arrayj) arrj2 := [...]int&#123;2, 4, 6, 8, 10&#125; testArray2(&amp;arrj2) fmt.Println(arrj2)&#125;//out0 101 02 03 04 0[10 0 0 0 0]0 101 42 63 84 10[10 4 6 8 10] len和cap都返回数组长度Slice切片：12341. 切片：切片是数组的一个引用，因此切片是引用类型。但是自身是结构体，为值拷贝传递2. 切片是可变数组，长度可以改变3. len为当前Slice的长度，cap为当前Slice的容量4. 对于一个slice == nil，len和cap的结果都为0 创建Slice的各种方式:123456789101112131415161718192021222324252627282930//声明切片 var s1 []int //指针类型，未初始化为nil if s1 == nil &#123; fmt.Println(&quot;空s1&quot;) &#125; else &#123; fmt.Println(&quot;s1不为空&quot;) &#125; //:= s2 := []int&#123;&#125; //make var s3 []int = make([]int,0) fmt.Println(s1,s2,s3) //len为0是nil //初始化赋值 var s4 []int = make([]int,0,0) fmt.Println(s4) s5 := []int&#123;1,2,3&#125; fmt.Println(s5) array5 := [5]int&#123;1,2,3,4,5&#125; s6 := array5[1:4] s7 := s6[:2] fmt.Println(s6,&quot; &quot;,s7)//out空s1[] [] [][][1 2 3][2 3 4] [2 3] 切片初始化:12345678910111213slice := s[low:high:max] //从切片low的索引位置到high索引的序列（左闭右开），//len = hight-low,cap=max-low//使用//没有填的话，参数默认为0/len(s)-1s[:]s[low:]s[:high]s[low:high]s[low:high:max]len(s)cap(s) 使用make来创建切片123var slice []type = make([]type, len)slice := make([]type, len)slice := make([]type, len, cap) 切片的内存布局： 读写操作的目标都是底层数组, x,y都是指向的同一个底层数组，本身是一个结构体，所以Slice本身直接使用是值类型，但是底层容器数组是指针指向。 1234567891011data := [...]int&#123;0,1,2,3,4,5&#125;s := data[2:4]s[0] += 100s[1] +=200fmt.Println(s)fmt.Println(data)//out[102 203][0 1 102 203 4 5] 创建Slice对象:直接创建Slice对象，自动分配底层数组123456789101112131415func createSlice() &#123; s1 := []int&#123;0,1,2,3,8:100&#125; //使用初始化表达式构造，可以使用索引号 fmt.Println(s1,len(s1),cap(s1)) s2 := make([]int,6,8) //使用make，直接指定len和cap fmt.Println(s2, len(s2), cap(s2)) s3 := make([]int,6) //省略cap,cap=len fmt.Println(s3,len(s3),cap(s3))&#125;//out[0 1 2 3 0 0 0 0 100] 9 9[0 0 0 0 0 0] 6 8[0 0 0 0 0 0] 6 6 使用指针直接访问底层数组123456789func findArrInSlice() &#123; s := []int&#123;0,1,2,3&#125; p := &amp;s[2] //*int,获取底层数组元素的指针 *p += 10 fmt.Println(s)&#125;//out[0 1 12 3] 二维Slice123456789101112func SliceSlice() &#123; //[][]T,则元素类型为[]T data := [][]int &#123; []int&#123;1,2,3&#125;, []int&#123;1,2&#125;, []int&#123;1&#125;, &#125; fmt.Println(data)&#125;//out[[1 2 3] [1 2] [1]] append操作切片append: 向slice尾部添加数据，返回新的slice对象 1234567891011121314151617181920var a = []int&#123;1,2,3&#125;fmt.Println(a)var b = []int&#123;4,5,6&#125;fmt.Println(b)c := append(a,b...) //添加slice需要使用, name...的方式fmt.Println(c)d := append(c,7) //变长参数fmt.Println(d)e := append(d, 8, 9 ,10)fmt.Println(e)fmt.Printf(&quot;c:%p d:%p&quot;,&amp;c,&amp;d)//out[1 2 3][4 5 6][1 2 3 4 5 6][1 2 3 4 5 6 7][1 2 3 4 5 6 7 8 9 10]c:0xc00019c040 d:0xc00019c080% //返回一个新的slice对象 超出slice.cap，会重写分配底层数组当超出cap后，append的Slice重新分配了底层数组，并复制数据。通常以两倍容量重新分配底层数组。在大批量添加数据时，一次性分配足够大的空间，可以减少内存分配和数据拷贝的开销。 123456789101112131415func SliceAppend() &#123; data := [...]int&#123;0,1,2,3,4,5,6, 10: 0&#125; s := data[:2:3] fmt.Println(s) s = append(s,100,200)//超出cap fmt.Println(s,data) fmt.Println(&amp;s[0],&amp;data[0]) fmt.Println(cap(s))&#125;//out[0 1][0 1 100 200] [0 1 2 3 4 5 6 0 0 0 0]0xc00001a180 0xc00006a0606 12345678910111213141516171819202122//底层数组分配func capAppend() &#123; s := make([]int,0,1) c := cap(s) for i := 0; i &lt; 150; i++ &#123; s = append(s, i) if n := cap(s);n&gt;c &#123; fmt.Printf(&quot;cap:%d -&gt; %d\\n&quot;,c,n) c = n &#125; &#125;&#125;//outcap:1 -&gt; 2cap:2 -&gt; 4cap:4 -&gt; 8cap:8 -&gt; 16cap:16 -&gt; 32cap:32 -&gt; 64cap:64 -&gt; 128cap:128 -&gt; 256 切片拷贝copy(s2,s1): 把s1拷贝到s2, 在两个slice间复制数据，复制长度以len小的为准，两个slice可以指向同一底层数组，允许元素区间重叠。及时将数据copy到小的slice，以便于及时释放超大号的底层数组内存。 123456789101112131415161718192021//copy(s2,s1) 把s1拷贝到s2,len=min(len(s1),len(s2))，从s2的0下标开始func SliceCopy() &#123; data := [...]int&#123;0,1,2,3,4,5,6,7,8,9&#125; fmt.Println(&quot;array data&quot;,data) s1 := data[8:] s2 := data[:5] fmt.Println(&quot;slice s1&quot;,s1) fmt.Println(&quot;slice s2&quot;,s2) copy(s2,s1) fmt.Println(&quot;copyed s1&quot;,s1) fmt.Println(&quot;copyed s2&quot;,s2) fmt.Println(&quot;array data&quot;,data)&#125;//outarray data [0 1 2 3 4 5 6 7 8 9]slice s1 [8 9]slice s2 [0 1 2 3 4]copyed s1 [8 9]copyed s2 [8 9 2 3 4]array data [8 9 2 3 4 5 6 7 8 9] 遍历使用forr或者fori 切片resize直接操作的底层数组 12345678910111213func resizeSlice() &#123; var a = []int&#123;1, 3, 4, 5&#125; b := a[1:2] c := b[0:3] fmt.Printf(&quot;slice a:%v,len(a):%v\\n&quot;,a, len(a)) fmt.Printf(&quot;slice b:%v,len(a):%v\\n&quot;,b, len(b)) fmt.Printf(&quot;slice c:%v,len(a):%v\\n&quot;,c, len(c))&#125;//outslice a:[1 3 4 5],len(a):4slice b:[3],len(a):1slice c:[3 4 5],len(a):3 字符串与切片string底层是一个byte数组，因此，可以进行切片操作，string本身是不可变的，所以要改变字符需要修改底层的数组（对于英文使用[]byte,中文使用[]rune） 123456789101112131415161718192021222324func stringOperation() &#123; str := &quot;hello stringO&quot; s1 := str[0:5] fmt.Println(s1) //修改英文字符string，通过一个byte的切片更改以后赋值回来 s := []byte(str) s[6] = &#x27;S&#x27; fmt.Println(s) fmt.Println(str) str = string(s) fmt.Println(str) //修改中文字符串 str1 := &quot;你好，中文字符&quot; var runeStr = []rune(str1) runeStr[0] = &#x27;我&#x27; str1 = string(runeStr) fmt.Println(str1)&#125;//outhello[104 101 108 108 111 32 83 116 114 105 110 103 79]hello stringOhello StringO我好，中文字符 切片使用: a[x:y:z] 切片内容[x:y] 切片长度:y-x 切片容量:z-x 123456789101112func SliceOperation( ) &#123; slice := []int&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; d1 := slice[6:8] fmt.Println(d1, len(d1), cap(d1)) d2 := slice[:6:8] fmt.Println(d2, len(d2), cap(d2))&#125;//out[6 7] 2 4[0 1 2 3 4 5] 6 8常规slice , data[6:8]，从第6位到第8位（返回6， 7），长度len为2， 最大可扩充长度cap为4（6-9）另一种写法： data[:6:8] 每个数字前都有个冒号， slice内容为data从0到第6位，长度len为6，最大扩充项cap设置为8","categories":[],"tags":[{"name":"go语言基础","slug":"go语言基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"}]},{"title":"小点集合","slug":"小点集合","date":"2021-10-31T11:47:27.000Z","updated":"2022-02-10T12:57:45.405Z","comments":true,"path":"2021/10/31/小点集合/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/10/31/%E5%B0%8F%E7%82%B9%E9%9B%86%E5%90%88/","excerpt":"","text":"小Tips集合 二维数组理解: 123456Matrix &#123;&#123;a,b,c,d&#125;,&#123;a,b,c,d&#125;&#125;matrix[行][列数] len(matrix) = 2 行数=2 len(matrix[0])=4 列数=4(0,1)(1,1)(2,1)(3,1) matrix[1][0] matrix[1][1] matrix[1][2] matrix[1][3](0,0)(1,0)(2,0)(3,0) matrix[0][0] matrix[0][1] matrix[0][2] matrix[0][3] ASCII, UniCode和UTF-8ASCII码对于英语字符与二进制之间的关系，做了统一的规定，即ASCII码。共128个字符 Unicode由于不同的语言使用了不同的编码，存在多套编码体系，所以有Unicode码包含所有的符号。 Unicode作为一个符号集，规定了所有符号的二进制代码， 问题：Unicode编码规定了符号的二进制代码，但是没有规定其如何存储，对于具体不同的符号如何存储存在多种存储方式。 UTF-8UTF-8是互联网上使用最广的Unicode实现方式，还有UTF-16(字符用2/4字节存储)和UTF-32（4字节存储）。 UTF-8是一种变长的编码方式，用1~4个字节表示一个符号，不同的符号长度不同。","categories":[],"tags":[{"name":"others","slug":"others","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/others/"}]},{"title":"go 语言基础部分","slug":"go-语言基础部分","date":"2021-10-28T15:47:13.000Z","updated":"2021-11-04T16:52:05.125Z","comments":true,"path":"2021/10/28/go-语言基础部分/","link":"","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/2021/10/28/go-%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80%E9%83%A8%E5%88%86/","excerpt":"","text":"Go 语法文档https://studygolang.com/pkgdoc https://www.topgoer.com/ https://go-zh.org/doc/ Go语言特征1234567891.自动垃圾回收。2.更丰富的内置类型。3.函数多返回值。4.错误处理。5.匿名函数和闭包。6.类型和接口。7.并发编程。8.反射。9.语言交互性。 关键字12345break default func interface selectcase defer go map structchan else goto package switchconst fallthrough if range typecontinue for import return var 保留字12345678910Constants: true false iota nilTypes: int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr float32 float64 complex128 complex64 bool byte rune string errorFunctions: make len cap new append copy close delete complex real imag panic recover 可见性1231. 声明在函数内部，类似private2. 声明在函数外部，为包可见，类似protect3. 声明在函数外部，且首字母大写，全局可见，类似public 声明1var (声明变量), const(声明常量), type(声明类型), func(声明函数) Init函数和main函数Init函数：用于包的初始化（早于main，由runtime进行初始化）顺序：1. 初始化导入的包（解析包依赖关系，没有依赖的最先初始化）2. 初始化包作用域的变量（解析变量的依赖关系，没有依赖的最先初始化）3. 执行包的Init函数（可以并发Init） 特征： 12345678910111 init函数是用于程序执行前做包的初始化的函数，比如初始化包里的变量等2 每个包可以拥有多个init函数3 包的每个源文件也可以拥有多个init函数4 同一个包中多个init函数的执行顺序go语言没有明确的定义(说明)，测试为安卓5 不同包的init函数按照包导入的依赖关系决定该初始化函数的执行顺序6 init函数不能被其他函数调用，而是在main函数执行之前，自动被调用 Main函数:程序的默认入口函数123func main() &#123;&#125; 对同一个go文件的init()调用顺序是从上到下的。 对同一个package中不同文件是按文件名字符串比较“从小到大”顺序调用各文件中的init()函数。 对于不同的package，如果不相互依赖的话，按照main包中”先import的后调用”的顺序调用其包中的init()，如果package存在依赖，则先调用最早被依赖的package中的init()，最后调用main函数。 下划线：“_”作为特殊标识符，用于忽略结果 在import中 用【import _ 包路径】引用该包，仅仅是为了调用init()函数，无法通过包名来调用包中的其他函数 在变量中 作为匿名变量，用于忽略变量 变量，常量变量 声明： 1234567var 变量名 变量类型//批量声明var ( a string b int) 变量初始化 12345678var 变量名 类型 = 表达式var name string = &quot;abc&quot;var name, sex string = &quot;abc&quot;,&quot;female&quot;类型推导: 编译器处理推导var name = &quot;abc&quot;a := 10 //短变量声明（类型推导，只在函数内部）函数外的语句必须以关键字开始(var,const,func等) 123456789101112package mainimport &quot;fmt&quot;//全局变量var m = 100func main() &#123; n := 10 m1 := 20//&quot;abc&quot; //局部变量 fmt.Println(m1,n,m)&#125; 匿名变量 在多次赋值时，可以使用匿名变量( _ )来忽略某个值 匿名变量不占用命名空间，不会分配内存，不会存在重复声明 常量123456789101112const pi = 3.14const ( a = 1 b = 2)const ( n1 = 100 n2 n3) iotaiota是go语言的常量计数器，只能在常量的表达式中使用。 iota在const关键字出现时将被重置为0。const中每新增一行常量声明将使iota计数一次(iota可理解为const语句块中的行索引)。常用于枚举的声明。 12345678910111213141516171819202122232425262728293031323334353637//使用_跳过某些值const ( n1 = iota n2 _ n4)//0 1 3//iota声明中间插队const ( a1 = iota a2 = 100 a3 = iota a4)const a5 = iota//0 100 2 3 0//定义数量级const ( _ = iota KB = 1 &lt;&lt; (10 * iota) MB = 1 &lt;&lt; (10 * iota) GB = 1 &lt;&lt; (10 * iota))//1024 1048576 1073741824//多个iota定义在一行，一行的iota为一个值const ( i1, i2 = iota + 1, iota + 2 i3, i4 i5, i6)//1 2 2 3 3 4 基本类型 类型 长度（byte） 默认值 说明 bool 1 false 只有ture和false.不能用其他类型强转和参与数值运算。 byte 1 0 uint8 rune 4 0 Unicode Code, int32 int,uint 4或8 0 32位或者64位 int8,uint8 1 0 -128127,0255,byte就是uint8 int16,uint16 2 0 -3276832767,065536 int32,uint32 4 0 -21亿21亿,042亿,rune int64,uint64 8 0 float32 4 0.0 3.4e38,math.MaxFloat32 float64 8 0.0 1.8e308,math.MaxFloat64 complex64 8 实部32，虚部32 complex128 16 实部64，虚部64 uintptr 4/8 存储指针的uint32或uint64 array 值类型 struct 值类型 string “” 值类型,UTF8字符串 slice nil 引用类型 map nil 引用类型 channel nil 引用类型 interface nil 接口 function nil 函数 注： 支持八进制，十六进制，科学计数法 math库有定义取值范围 1234a := 071b := 0x1Fc := 1e9d := math.MinInt16 空指针类型为nil 字符串 字符串转义符：\\r 回车 \\n 换行 \\t 制表 \\ ‘单引 \\ &quot;双引 \\反斜杠 1fmt.Println(&quot;str :=\\&quot;c:\\\\a\\\\main.exe\\&quot;&quot;) 多行字符串 12345678910s1 := `第一行第二行第三行 `fmt.Println(s1)//out第一行第二行第三行 字符串常用操作: 方法 作用 len(str) + / fmt.Sprintf 拼接字符串 strings.Split 分割 strings.Contains 是否包含 strings.HasPrefix,strings.HasSuffix 前缀/后缀判断 strings.Index(),strings.LastIndex() 子串出现的位置 strings.Join(a[] string,sep string) join byte和rune 12unit8/byte -&gt; ASCII码字符rune -&gt; UTF8字符 12345678910111213s := &quot;abc123我的博客&quot; for i := 0; i &lt; len(s); i++ &#123; fmt.Printf(&quot;%c&quot;,s[i]) &#125; fmt.Println() for _, r := range s &#123; fmt.Printf(&quot;%c&quot;,r) &#125; fmt.Println() //outabc123æ\u0000\u0000ç\u0000\u0000å\u0000\u0000å®¢abc123我的博客 字符串底层是一个byte数组，可以和[]byte相互转换。字符串是不可修改的。这里由于底层是byte数组，所有长度是byte数组的长度，如果是用len变量UTF8字符串就会乱码，使用forr形式就OK 修改字符串 先将其转换为[]rune或者[]byte，完成以后再转换为string,但是都需要重写分配内存和复制字节数组。 123456789101112131415161718s1 := &quot;hello&quot;//强制类型转换byteS1 := []byte(s1)byteS1[0] = &#x27;H&#x27;fmt.Println(string(byteS1), len(byteS1))fmt.Println(byteS1)s2:=&quot;博客&quot;runeS2 := []rune(s2)runeS2[1] = &#x27;击&#x27;fmt.Println(string(runeS2), len(runeS2))fmt.Println(runeS2)//outHello 5[72 101 108 108 111]博击 2[21338 20987] 类型转换Go只支持强制类型转换，没有隐式转换 1T(表达式) 容器类型List12345678910111213141516171819202122232425262728293031323334353637383940414243type Element struct &#123; next, prev *Element // The list to which this element belongs. list *List // The value stored with this element. Value interface&#123;&#125;&#125;//两个方法，获取上一个或下一个元素func (e *Element) Next() *Elementfunc (e *Element) Prev() *Elementtype List struct &#123; root Element len int &#125;func (l *List) Init() *Listfunc New() *List //alloc + Initfunc (l *List) Front() *Element//返回列表头func (l *List) Back() *Element //返回列表尾//at后插入e,返回efunc (l *List) insert(e, at *Element) *Elementfunc (l *List) insertValue(v interface&#123;&#125;, at *Element) *Elementfunc (l *List) remove(e *Element) *Element//移除e，返回efunc (l *List) move(e, at *Element) *Element //e放到at后面，返回efunc (l *List) PushFront(v interface&#123;&#125;) *Elementfunc (l *List) PushBack(v interface&#123;&#125;) *Elementfunc (l *List) InsertBefore(v interface&#123;&#125;, mark *Element) *Elementfunc (l *List) InsertAfter(v interface&#123;&#125;, mark *Element) *Elementfunc (l *List) MoveToFront(e *Element)func (l *List) MoveToBack(e *Element)func (l *List) MoveBefore(e, mark *Element)func (l *List) MoveAfter(e, mark *Element)func (l *List) PushBackList(other *List)func (l *List) PushFrontList(other *List)","categories":[],"tags":[{"name":"go语言基础","slug":"go语言基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"}]}],"categories":[{"name":"MQ","slug":"MQ","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/MQ/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/Zookeeper/"},{"name":"微服务","slug":"微服务","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Netty","slug":"Netty","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/Netty/"},{"name":"内存管理","slug":"内存管理","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"name":"序列化","slug":"序列化","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/%E5%BA%8F%E5%88%97%E5%8C%96/"},{"name":"MySQL","slug":"MySQL","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/MySQL/"},{"name":"RPC","slug":"RPC","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/RPC/"},{"name":"Redis","slug":"Redis","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/categories/Redis/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/MQ/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/Zookeeper/"},{"name":"微服务","slug":"微服务","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Netty","slug":"Netty","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/Netty/"},{"name":"内存管理","slug":"内存管理","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"},{"name":"序列化","slug":"序列化","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%BA%8F%E5%88%97%E5%8C%96/"},{"name":"MySQL","slug":"MySQL","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/MySQL/"},{"name":"RPC","slug":"RPC","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/RPC/"},{"name":"Redis","slug":"Redis","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/Redis/"},{"name":"Go基础","slug":"Go基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/Go%E5%9F%BA%E7%A1%80/"},{"name":"MySql","slug":"MySql","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/MySql/"},{"name":"其他","slug":"其他","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%85%B6%E4%BB%96/"},{"name":"编译原理","slug":"编译原理","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"},{"name":"并发编程","slug":"并发编程","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"go多线程编程","slug":"go多线程编程","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/"},{"name":"go语言基础","slug":"go语言基础","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/"},{"name":"others","slug":"others","permalink":"https://zhongsongzhi.github.io/zhongsongzhi97.github.io/tags/others/"}]}